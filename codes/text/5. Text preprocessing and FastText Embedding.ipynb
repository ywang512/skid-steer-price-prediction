{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import fasttext\n",
    "import collections\n",
    "import string\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import csv\n",
    "import re\n",
    "import os\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8172, 20)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../../data/SkidSteer_2019-08.csv')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLUMN_NAMES = ['Unique_ID', 'Winning Bid', 'Hours Final', 'Age at Sale (bin)',\n",
    "                'Bucket', 'Engine', 'Tires', 'Transmission', 'details remaining']\n",
    "RENAME_SCHEMA = {\n",
    "    'Unique_ID': \"unique_id\",\n",
    "    'Hours Final': \"hours_final\",\n",
    "    'Winning Bid': \"winning_bid\",\n",
    "    'Age at Sale (bin)': \"age_at_sale\",\n",
    "    'Bucket': \"bucket\",\n",
    "    'Engine': \"engine\",\n",
    "    'Tires': \"tires\",\n",
    "    'Transmission': \"transmission\",\n",
    "    'details remaining': \"details_remaining\",\n",
    "    'socre': \"colorfulness_score\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_root = \"../../data/images/\"\n",
    "score_df = pd.read_csv(\"../colorfulness/skid_steer_color_score.csv\")\n",
    "\n",
    "processed_df = df.copy()\n",
    "processed_df['Unique_ID'] = processed_df[['Source', 'item#']].apply(lambda x: '_'.join(x), axis=1)\n",
    "processed_df = processed_df.filter(COLUMN_NAMES, axis=1)\n",
    "processed_df = pd.merge(processed_df, score_df, on='Unique_ID', how='inner')\n",
    "processed_df = processed_df.rename(columns=RENAME_SCHEMA)\n",
    "\n",
    "duplicated_item = [item for item, count in Counter(processed_df[\"unique_id\"]).items() if count > 1]\n",
    "processed_df = processed_df[~processed_df['unique_id'].isin(duplicated_item)]\n",
    "\n",
    "image_item = [img_name.strip(\".jpg\") for img_name in os.listdir(image_root)]\n",
    "processed_df = processed_df[processed_df[\"unique_id\"].isin(image_item)]\n",
    "\n",
    "processed_df = processed_df[processed_df['unique_id'] != \"rbauction_10525632\"]\n",
    "\n",
    "processed_df[\"winning_bid\"] = processed_df[\"winning_bid\"].str.replace(',', '').astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6168, 10)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = processed_df\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_id</th>\n",
       "      <th>winning_bid</th>\n",
       "      <th>hours_final</th>\n",
       "      <th>age_at_sale</th>\n",
       "      <th>bucket</th>\n",
       "      <th>engine</th>\n",
       "      <th>tires</th>\n",
       "      <th>transmission</th>\n",
       "      <th>details_remaining</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6177</th>\n",
       "      <td>rbauction_10471129</td>\n",
       "      <td>5000</td>\n",
       "      <td>9,016</td>\n",
       "      <td>18.0</td>\n",
       "      <td>bkt</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>aux hyd, canopy</td>\n",
       "      <td>30.589238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6178</th>\n",
       "      <td>rbauction_11251937</td>\n",
       "      <td>11000</td>\n",
       "      <td>2,396</td>\n",
       "      <td>12.0</td>\n",
       "      <td>bkt</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>canopy</td>\n",
       "      <td>36.586281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6179</th>\n",
       "      <td>ironplanet_1963734</td>\n",
       "      <td>8300</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Manual Coupler The engine started and ran. The...</td>\n",
       "      <td>Cushion Tires</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Auxiliary Hydraulic Plumbing, Open Operator St...</td>\n",
       "      <td>16.456728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6180</th>\n",
       "      <td>ironplanet_1864149</td>\n",
       "      <td>14200</td>\n",
       "      <td>322</td>\n",
       "      <td>3.0</td>\n",
       "      <td>66\" Wide General Purpose Smooth Edge Bucket</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cushion Tires</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Heater, Hydraulic Coupler, Enclosed Cab</td>\n",
       "      <td>26.860051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6181</th>\n",
       "      <td>ironplanet_1686964</td>\n",
       "      <td>8500</td>\n",
       "      <td>2</td>\n",
       "      <td>9.0</td>\n",
       "      <td>68\" General Purpose Smooth Edge Bucket The eng...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Auxiliary Hydraulic Plumbing, Manual Coupler, ...</td>\n",
       "      <td>27.659484</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               unique_id  winning_bid hours_final  age_at_sale  \\\n",
       "6177  rbauction_10471129         5000       9,016         18.0   \n",
       "6178  rbauction_11251937        11000       2,396         12.0   \n",
       "6179  ironplanet_1963734         8300           1          NaN   \n",
       "6180  ironplanet_1864149        14200         322          3.0   \n",
       "6181  ironplanet_1686964         8500           2          9.0   \n",
       "\n",
       "                                                 bucket  \\\n",
       "6177                                                bkt   \n",
       "6178                                                bkt   \n",
       "6179                                                NaN   \n",
       "6180        66\" Wide General Purpose Smooth Edge Bucket   \n",
       "6181  68\" General Purpose Smooth Edge Bucket The eng...   \n",
       "\n",
       "                                                 engine          tires  \\\n",
       "6177                                                NaN            NaN   \n",
       "6178                                                NaN            NaN   \n",
       "6179  Manual Coupler The engine started and ran. The...  Cushion Tires   \n",
       "6180                                                NaN  Cushion Tires   \n",
       "6181                                                NaN            NaN   \n",
       "\n",
       "     transmission                                  details_remaining  \\\n",
       "6177          NaN                                    aux hyd, canopy   \n",
       "6178          NaN                                             canopy   \n",
       "6179          NaN  Auxiliary Hydraulic Plumbing, Open Operator St...   \n",
       "6180          NaN            Heater, Hydraulic Coupler, Enclosed Cab   \n",
       "6181          NaN  Auxiliary Hydraulic Plumbing, Manual Coupler, ...   \n",
       "\n",
       "          score  \n",
       "6177  30.589238  \n",
       "6178  36.586281  \n",
       "6179  16.456728  \n",
       "6180  26.860051  \n",
       "6181  27.659484  "
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Two ways to preprocess 'detail_remaining' column\n",
    "1. Basic: with every punctuation removed, each word has its own embedding\n",
    "2. Another: each phrase separated by a comma has its own embedding\n",
    "\n",
    "### Two approches to treat embedding coming from 4 different sources\n",
    "1. Treat them as coming from one source, only deal with text\n",
    "2. Train one fasttext embedding for each source, i.e. rbauction, PW,et."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Basic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNonfloat(textSeries, textIndex):\n",
    "    subtext = []\n",
    "    subindex = []\n",
    "    for sentence, index in zip(textSeries, textIndex):\n",
    "        if type(sentence) != float:\n",
    "            subtext.append(sentence)\n",
    "            subindex.append(index)\n",
    "    return subtext,subindex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getIndexText(df,source):\n",
    "    details_text = df[df['unique_id'].str.startswith(source)]['details_remaining'].str.strip().str.lower().str.replace('[{}]'.format(string.punctuation), '')\n",
    "    details_index = list(details_text.index)\n",
    "    text, index = getNonfloat(details_text, details_index)\n",
    "    return text, index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Run it only once to \n",
    "1) save the textdf csv\n",
    "2) get the fasttext model saved\n",
    "\"\"\"\n",
    "def getEmbedModel(df, source):\n",
    "    text, index = getIndexText(df,source)\n",
    "    textdf = pd.DataFrame(text)\n",
    "    textdf.to_csv(\"data/{}_text.csv\".format(source), sep='\\t', index=False)\n",
    "    \n",
    "    # train fasttext embedding --> this is slow\n",
    "    model = fasttext.train_unsupervised(\"./data/{}_text.csv\".format(source), model='skipgram')\n",
    "    model.save_model('./models/{}_skipgram_model.bin'.format(source))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Read embeddings from fasttext model\n",
    "return: 1) embeddings for source\n",
    "        2) index for embeddings in the original df\n",
    "\"\"\"\n",
    "def getEmbed(df, source):\n",
    "    text, index = getIndexText(df,source)\n",
    "    model = fasttext.load_model('./models/{}_skipgram_model.bin'.format(source))\n",
    "    sentence_embedding = []\n",
    "    for i in range(len(text)):\n",
    "        sentence_embedding.append(model.get_sentence_vector(text[i]))\n",
    "    return sentence_embedding, index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4 [00:00<?, ?it/s]Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
      " 25%|██▌       | 1/4 [00:01<00:05,  1.70s/it]Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
      " 50%|█████     | 2/4 [00:03<00:03,  1.68s/it]Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
      " 75%|███████▌  | 3/4 [00:05<00:01,  1.69s/it]Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
      "100%|██████████| 4/4 [00:06<00:00,  1.69s/it]\n"
     ]
    }
   ],
   "source": [
    "## main execution\n",
    "sources = ['rbauct','big','iron','PW']\n",
    "list_embed = []\n",
    "list_index = []\n",
    "for source in tqdm(sources):\n",
    "    getEmbedModel(df, source)\n",
    "    sentence_embedding, index = getEmbed(df, source)\n",
    "    list_embed += sentence_embedding\n",
    "    list_index += index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6155, 6155)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list_embed), len(list_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_df = pd.DataFrame(np.vstack(list_embed))\n",
    "embed_df.insert(0, column=\"index\", value=list_index) # the index are not sorted yet\n",
    "embed_df = embed_df.sort_values(embed_df.columns[0], ascending = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6155, 101)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(embed_df, open(\"models/embed.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the row number of each source\n",
    "# 4 different sources: rbauct, bigiron, ironplanet, PW\n",
    "rbauct_text, rbauct_index = getIndexText(df, 'rbauct')\n",
    "big_text, big_index = getIndexText(df, 'big')\n",
    "iron_text, iron_index = getIndexText(df, 'iron')\n",
    "PW_text, PW_index = getIndexText(df, 'PW')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3930, 3930, 423, 423, 501, 501, 1301, 1301)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rbauct_text), len(rbauct_index), len(big_text), len(big_index), len(iron_text), len(iron_index), len(PW_text), len(PW_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{300, 379, 393, 422, 1241, 3790, 4781, 4790, 4802, 4935, 5188, 5371, 6052}"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(df.index) - set(list_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[300, 379, 393, 422, 1241, 3776, 4767, 4776, 4788, 4921, 5174, 5357, 6038]"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(np.where(df.details_remaining.isna())[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "unique_id            ironplanet_1830435\n",
       "winning_bid                       12000\n",
       "hours_final                         NaN\n",
       "age_at_sale                           6\n",
       "bucket                              NaN\n",
       "engine                              NaN\n",
       "tires                               NaN\n",
       "transmission                        NaN\n",
       "details_remaining                   NaN\n",
       "score                           39.2404\n",
       "Name: 5371, dtype: object"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[5371]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Another -- actually don't quite make sense except for text from 'rbauction'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNonfloat2(textSeries, textIndex):\n",
    "    text_list = []\n",
    "    index_list = []\n",
    "    for sentence, index in zip(textSeries, textIndex):\n",
    "        subtext = ''\n",
    "        if type(sentence)!= float:\n",
    "            for phrase in sentence:\n",
    "                word_concat = '_'.join(phrase.strip().split(' '))\n",
    "                subtext += word_concat + ' '\n",
    "            text_list.append(subtext.strip())\n",
    "            index_list.append(index)\n",
    "    return text_list,index_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getIndexText2(df,source):\n",
    "    details_text = df[df['unique_id'].str.startswith(source)]['details_remaining'].str.strip().str.lower().str.replace('[^,\\w\\s]','').str.split(',')\n",
    "    details_index = list(details_text.index)\n",
    "    text, index = getNonfloat2(details_text, details_index)\n",
    "    return text, index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Run it only once to \n",
    "1) save the textdf csv\n",
    "2) get the fasttext model saved\n",
    "\"\"\"\n",
    "def getEmbedModel2(df, source):\n",
    "    text, index = getIndexText2(df,source)\n",
    "    textdf = pd.DataFrame(text)\n",
    "    textdf.to_csv(\"data2/{}_text.csv\".format(source), sep='\\t', index=False)\n",
    "    \n",
    "    # train fasttext embedding --> this is slow\n",
    "    model = fasttext.train_unsupervised(\"data2/{}_text.csv\".format(source), model='skipgram')\n",
    "    model.save_model('./models2/{}_skipgram_model.bin'.format(source))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Read embeddings from fasttext model\n",
    "return: 1) embeddings for source\n",
    "        2) index for embeddings in the original df\n",
    "\"\"\"\n",
    "def getEmbed2(df, source):\n",
    "    text, index = getIndexText2(df,source)\n",
    "    model = fasttext.load_model('./models2/{}_skipgram_model.bin'.format(source))\n",
    "    sentence_embedding = []\n",
    "    for i in range(len(text)):\n",
    "        sentence_embedding.append(model.get_sentence_vector(text[i]))\n",
    "    return sentence_embedding, index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4 [00:00<?, ?it/s]Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
      " 25%|██▌       | 1/4 [00:01<00:05,  1.68s/it]Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
      " 50%|█████     | 2/4 [00:03<00:03,  1.67s/it]Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
      " 75%|███████▌  | 3/4 [00:04<00:01,  1.66s/it]Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
      "100%|██████████| 4/4 [00:06<00:00,  1.67s/it]\n"
     ]
    }
   ],
   "source": [
    "## main execution\n",
    "sources = ['rbauct','big','iron','PW']\n",
    "list_embed = []\n",
    "list_index = []\n",
    "for source in tqdm(sources):\n",
    "    getEmbedModel2(df, source)\n",
    "    sentence_embedding, index = getEmbed2(df, source)\n",
    "    list_embed += sentence_embedding\n",
    "    list_index += index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_temp",
   "language": "python",
   "name": "torch_temp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
