{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models, utils\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from PIL import Image\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabular_data = \"../../data/SkidSteer_2019-08.csv\"\n",
    "\n",
    "df = pd.read_csv(tabular_data, index_col=1)\n",
    "df['Unique_ID'] = df[['Source','item#']].apply(lambda x: '_'.join(x),axis = 1)\n",
    "df = df.filter(['Unique_ID','Winning Bid','Hours Final','Age at Sale (bin)','Bucket','Engine','Tires','Transmission'], axis = 1)\n",
    "df = df.rename(columns={\n",
    "    'Unique_ID': \"unique_id\",\n",
    "    'Hours Final': \"hours_final\",\n",
    "    'Winning Bid': \"winning_bid\",\n",
    "    'Age at Sale (bin)': \"age_at_sale\",\n",
    "    'Bucket': \"bucket\",\n",
    "    'Engine': \"engine\",\n",
    "    'Tires': \"tires\",\n",
    "    'Transmission': \"transmission\"\n",
    "})\n",
    "# color = pd.read_csv('skid_steer_color_score.csv')\n",
    "# final_df = pd.merge(new_df, color,on='Unique_ID',how='inner')\n",
    "\n",
    "\n",
    "### removal\n",
    "# remove duplicant\n",
    "duplicated_item = [item for item, count in Counter(df[\"unique_id\"]).items() if count > 1]\n",
    "df = df[~df['unique_id'].isin(duplicated_item)]\n",
    "\n",
    "# remove not matched rows\n",
    "image_item = [img_name.strip(\".jpg\") for img_name in os.listdir(\"../../data/images/\")]\n",
    "df = df[df[\"unique_id\"].isin(image_item)]\n",
    "\n",
    "# remove comma\n",
    "df[\"winning_bid\"] = df[\"winning_bid\"].str.replace(',', '').astype(int)\n",
    "\n",
    "# remove special image\n",
    "df = df[df['unique_id'] != \"rbauction_10525632\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### winning_bid\n",
    "\n",
    "# log-transform\n",
    "df[\"winning_bid\"] = np.log(df[\"winning_bid\"])\n",
    "\n",
    "# min max scale\n",
    "mm_scaler_price = preprocessing.MinMaxScaler((-1, 1))\n",
    "df[\"winning_bid\"] = mm_scaler_price.fit_transform(df[\"winning_bid\"].to_numpy().reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### hours_final\n",
    "\n",
    "# impute nan with median and new binary indicator\n",
    "df[\"hours_final\"] = df[\"hours_final\"].str.replace(\",\", \"\")\n",
    "df[\"hours_final\"] = df[\"hours_final\"].astype(float)\n",
    "df.insert(3, column=\"hours_final_nan\", value=df[\"hours_final\"].isna().astype(int))\n",
    "df.loc[df[\"hours_final\"].isna(), \"hours_final\"] = df[\"hours_final\"].median(skipna=True)\n",
    "\n",
    "# log transform\n",
    "df[\"hours_final\"] = np.log(df[\"hours_final\"])\n",
    "\n",
    "# normalize\n",
    "rb_scaler_hour = preprocessing.RobustScaler()\n",
    "df[\"hours_final\"] = rb_scaler_hour.fit_transform(np.array(df[\"hours_final\"]).reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### age_at_sale\n",
    "\n",
    "# impute nan with median and new binary indicator\n",
    "df[\"age_at_sale\"] = df[\"age_at_sale\"].astype(float)\n",
    "df.insert(5, column=\"age_at_sale_nan\", value=df[\"age_at_sale\"].isna().astype(int))\n",
    "df.loc[df[\"age_at_sale\"].isna(), \"age_at_sale\"] = df[\"age_at_sale\"].median(skipna=True)\n",
    "\n",
    "# normalize\n",
    "rb_scaler_age = preprocessing.RobustScaler()\n",
    "df[\"age_at_sale\"] = rb_scaler_age.fit_transform(np.array(df[\"age_at_sale\"]).reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "### bucket\n",
    "df.insert(7, column=\"bucket_bin\", value=0)\n",
    "df.loc[\n",
    "    ~df[\"bucket\"].isna() & \n",
    "    df[\"bucket\"].str.contains(\"bucket\", case=False) | \n",
    "    df[\"bucket\"].str.contains(\"bkt\", case=False), \"bucket_bin\"\n",
    "] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle and split\n",
    "np.random.seed(1)\n",
    "split = [0.7, 0.3]\n",
    "split0 = round(df.shape[0] * split[0])\n",
    "# split1 = round(df.shape[0] * (split[0] + split[1]))\n",
    "df = df.sample(frac=1)\n",
    "df_train = df.iloc[:split0]\n",
    "df_val = df.iloc[split0:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_id</th>\n",
       "      <th>winning_bid</th>\n",
       "      <th>hours_final</th>\n",
       "      <th>hours_final_nan</th>\n",
       "      <th>age_at_sale</th>\n",
       "      <th>age_at_sale_nan</th>\n",
       "      <th>bucket</th>\n",
       "      <th>bucket_bin</th>\n",
       "      <th>engine</th>\n",
       "      <th>tires</th>\n",
       "      <th>transmission</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Item Id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ec1907ce-5c12-5ab8-b42d-39eb481e6049</th>\n",
       "      <td>ironplanet_1703726</td>\n",
       "      <td>0.105406</td>\n",
       "      <td>-6.732824</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.666667</td>\n",
       "      <td>0</td>\n",
       "      <td>74\" Wide General Purpose Smooth Edge Bucket</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cushion Tires</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>529071</th>\n",
       "      <td>PW_DD1289</td>\n",
       "      <td>0.172815</td>\n",
       "      <td>-1.629216</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>Kubota 68\"W bucket</td>\n",
       "      <td>1</td>\n",
       "      <td>Kubota V3307-CR four cylinder turbo diesel engine</td>\n",
       "      <td>Titan 12-16.5 NHS tires</td>\n",
       "      <td>Two speed hydrostatic transmission</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eff85cf8-4988-8990-b317-39e91a64ec3a</th>\n",
       "      <td>rbauction_10239624</td>\n",
       "      <td>0.219707</td>\n",
       "      <td>-0.164164</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.666667</td>\n",
       "      <td>0</td>\n",
       "      <td>hyd Q/C bkt</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386158</th>\n",
       "      <td>PW_H1380</td>\n",
       "      <td>-0.072566</td>\n",
       "      <td>-0.769452</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>80\"W bucket</td>\n",
       "      <td>1</td>\n",
       "      <td>81 HP, Case 3.2L four cylinder turbo diesel en...</td>\n",
       "      <td>12-16.5 tires</td>\n",
       "      <td>Hydrostatic transmission</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>460813</th>\n",
       "      <td>PW_J8873</td>\n",
       "      <td>-0.305592</td>\n",
       "      <td>-0.416323</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>John Deere 5030TT001 3.0L turbo diesel engine</td>\n",
       "      <td>12-16.5 tires</td>\n",
       "      <td>Two speed hydrostatic transmission</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               unique_id  winning_bid  \\\n",
       "Item Id                                                                 \n",
       "ec1907ce-5c12-5ab8-b42d-39eb481e6049  ironplanet_1703726     0.105406   \n",
       "529071                                         PW_DD1289     0.172815   \n",
       "eff85cf8-4988-8990-b317-39e91a64ec3a  rbauction_10239624     0.219707   \n",
       "386158                                          PW_H1380    -0.072566   \n",
       "460813                                          PW_J8873    -0.305592   \n",
       "\n",
       "                                      hours_final  hours_final_nan  \\\n",
       "Item Id                                                              \n",
       "ec1907ce-5c12-5ab8-b42d-39eb481e6049    -6.732824                0   \n",
       "529071                                  -1.629216                0   \n",
       "eff85cf8-4988-8990-b317-39e91a64ec3a    -0.164164                0   \n",
       "386158                                  -0.769452                0   \n",
       "460813                                  -0.416323                0   \n",
       "\n",
       "                                      age_at_sale  age_at_sale_nan  \\\n",
       "Item Id                                                              \n",
       "ec1907ce-5c12-5ab8-b42d-39eb481e6049    -0.666667                0   \n",
       "529071                                  -1.000000                0   \n",
       "eff85cf8-4988-8990-b317-39e91a64ec3a    -0.666667                0   \n",
       "386158                                  -0.333333                0   \n",
       "460813                                  -0.333333                0   \n",
       "\n",
       "                                                                           bucket  \\\n",
       "Item Id                                                                             \n",
       "ec1907ce-5c12-5ab8-b42d-39eb481e6049  74\" Wide General Purpose Smooth Edge Bucket   \n",
       "529071                                                         Kubota 68\"W bucket   \n",
       "eff85cf8-4988-8990-b317-39e91a64ec3a                                  hyd Q/C bkt   \n",
       "386158                                                                80\"W bucket   \n",
       "460813                                                                        NaN   \n",
       "\n",
       "                                      bucket_bin  \\\n",
       "Item Id                                            \n",
       "ec1907ce-5c12-5ab8-b42d-39eb481e6049           1   \n",
       "529071                                         1   \n",
       "eff85cf8-4988-8990-b317-39e91a64ec3a           1   \n",
       "386158                                         1   \n",
       "460813                                         0   \n",
       "\n",
       "                                                                                 engine  \\\n",
       "Item Id                                                                                   \n",
       "ec1907ce-5c12-5ab8-b42d-39eb481e6049                                                NaN   \n",
       "529071                                Kubota V3307-CR four cylinder turbo diesel engine   \n",
       "eff85cf8-4988-8990-b317-39e91a64ec3a                                                NaN   \n",
       "386158                                81 HP, Case 3.2L four cylinder turbo diesel en...   \n",
       "460813                                    John Deere 5030TT001 3.0L turbo diesel engine   \n",
       "\n",
       "                                                        tires  \\\n",
       "Item Id                                                         \n",
       "ec1907ce-5c12-5ab8-b42d-39eb481e6049            Cushion Tires   \n",
       "529071                                Titan 12-16.5 NHS tires   \n",
       "eff85cf8-4988-8990-b317-39e91a64ec3a                      NaN   \n",
       "386158                                          12-16.5 tires   \n",
       "460813                                          12-16.5 tires   \n",
       "\n",
       "                                                            transmission  \n",
       "Item Id                                                                   \n",
       "ec1907ce-5c12-5ab8-b42d-39eb481e6049                                 NaN  \n",
       "529071                                Two speed hydrostatic transmission  \n",
       "eff85cf8-4988-8990-b317-39e91a64ec3a                                 NaN  \n",
       "386158                                          Hydrostatic transmission  \n",
       "460813                                Two speed hydrostatic transmission  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_id</th>\n",
       "      <th>winning_bid</th>\n",
       "      <th>hours_final</th>\n",
       "      <th>hours_final_nan</th>\n",
       "      <th>age_at_sale</th>\n",
       "      <th>age_at_sale_nan</th>\n",
       "      <th>bucket</th>\n",
       "      <th>bucket_bin</th>\n",
       "      <th>engine</th>\n",
       "      <th>tires</th>\n",
       "      <th>transmission</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Item Id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>cdf26f3a-f792-7a0f-350e-39e9461c54c9</th>\n",
       "      <td>bigiron_EN9531</td>\n",
       "      <td>0.164709</td>\n",
       "      <td>-0.503074</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>84\" Bucket</td>\n",
       "      <td>1</td>\n",
       "      <td>4-Cyl Turbo Diesel Engine, 84 Hp</td>\n",
       "      <td>Some Tires Have Cuts (Pictured), Tires- 14-17....</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14c666d4-512a-8962-6072-39e918e5b2f7</th>\n",
       "      <td>rbauction_10693873</td>\n",
       "      <td>-0.861828</td>\n",
       "      <td>-0.443163</td>\n",
       "      <td>0</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>bkt</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dc20ac44-7c35-11a7-2dfa-39e8cc01c274</th>\n",
       "      <td>bigiron_BO0203</td>\n",
       "      <td>-0.180158</td>\n",
       "      <td>-0.226316</td>\n",
       "      <td>0</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>Buckets 12\", 64\" Bucket</td>\n",
       "      <td>1</td>\n",
       "      <td>58 Horse Power Isuzu Diesel Engine</td>\n",
       "      <td>12-16.5 Tires, Spare Tire And Rim</td>\n",
       "      <td>Hydrostat Transmission</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ebfb5935-40e0-4488-2e6c-39ea98658096</th>\n",
       "      <td>ironplanet_1891010</td>\n",
       "      <td>-0.402470</td>\n",
       "      <td>-6.732824</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>72\" Wide General Purpose Smooth Edge Bucket</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>446849</th>\n",
       "      <td>PW_J2936</td>\n",
       "      <td>-0.402470</td>\n",
       "      <td>-1.926828</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Case four cylinder turbo diesel engine, Non-op...</td>\n",
       "      <td>12-16.5 tires</td>\n",
       "      <td>Hydrostatic transmission</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               unique_id  winning_bid  \\\n",
       "Item Id                                                                 \n",
       "cdf26f3a-f792-7a0f-350e-39e9461c54c9      bigiron_EN9531     0.164709   \n",
       "14c666d4-512a-8962-6072-39e918e5b2f7  rbauction_10693873    -0.861828   \n",
       "dc20ac44-7c35-11a7-2dfa-39e8cc01c274      bigiron_BO0203    -0.180158   \n",
       "ebfb5935-40e0-4488-2e6c-39ea98658096  ironplanet_1891010    -0.402470   \n",
       "446849                                          PW_J2936    -0.402470   \n",
       "\n",
       "                                      hours_final  hours_final_nan  \\\n",
       "Item Id                                                              \n",
       "cdf26f3a-f792-7a0f-350e-39e9461c54c9    -0.503074                0   \n",
       "14c666d4-512a-8962-6072-39e918e5b2f7    -0.443163                0   \n",
       "dc20ac44-7c35-11a7-2dfa-39e8cc01c274    -0.226316                0   \n",
       "ebfb5935-40e0-4488-2e6c-39ea98658096    -6.732824                0   \n",
       "446849                                  -1.926828                0   \n",
       "\n",
       "                                      age_at_sale  age_at_sale_nan  \\\n",
       "Item Id                                                              \n",
       "cdf26f3a-f792-7a0f-350e-39e9461c54c9    -0.333333                0   \n",
       "14c666d4-512a-8962-6072-39e918e5b2f7     1.333333                0   \n",
       "dc20ac44-7c35-11a7-2dfa-39e8cc01c274     1.333333                0   \n",
       "ebfb5935-40e0-4488-2e6c-39ea98658096    -0.333333                0   \n",
       "446849                                  -0.333333                0   \n",
       "\n",
       "                                                                           bucket  \\\n",
       "Item Id                                                                             \n",
       "cdf26f3a-f792-7a0f-350e-39e9461c54c9                                   84\" Bucket   \n",
       "14c666d4-512a-8962-6072-39e918e5b2f7                                          bkt   \n",
       "dc20ac44-7c35-11a7-2dfa-39e8cc01c274                      Buckets 12\", 64\" Bucket   \n",
       "ebfb5935-40e0-4488-2e6c-39ea98658096  72\" Wide General Purpose Smooth Edge Bucket   \n",
       "446849                                                                        NaN   \n",
       "\n",
       "                                      bucket_bin  \\\n",
       "Item Id                                            \n",
       "cdf26f3a-f792-7a0f-350e-39e9461c54c9           1   \n",
       "14c666d4-512a-8962-6072-39e918e5b2f7           1   \n",
       "dc20ac44-7c35-11a7-2dfa-39e8cc01c274           1   \n",
       "ebfb5935-40e0-4488-2e6c-39ea98658096           1   \n",
       "446849                                         0   \n",
       "\n",
       "                                                                                 engine  \\\n",
       "Item Id                                                                                   \n",
       "cdf26f3a-f792-7a0f-350e-39e9461c54c9                   4-Cyl Turbo Diesel Engine, 84 Hp   \n",
       "14c666d4-512a-8962-6072-39e918e5b2f7                                                NaN   \n",
       "dc20ac44-7c35-11a7-2dfa-39e8cc01c274                 58 Horse Power Isuzu Diesel Engine   \n",
       "ebfb5935-40e0-4488-2e6c-39ea98658096                                                NaN   \n",
       "446849                                Case four cylinder turbo diesel engine, Non-op...   \n",
       "\n",
       "                                                                                  tires  \\\n",
       "Item Id                                                                                   \n",
       "cdf26f3a-f792-7a0f-350e-39e9461c54c9  Some Tires Have Cuts (Pictured), Tires- 14-17....   \n",
       "14c666d4-512a-8962-6072-39e918e5b2f7                                                NaN   \n",
       "dc20ac44-7c35-11a7-2dfa-39e8cc01c274                  12-16.5 Tires, Spare Tire And Rim   \n",
       "ebfb5935-40e0-4488-2e6c-39ea98658096                                                NaN   \n",
       "446849                                                                    12-16.5 tires   \n",
       "\n",
       "                                                  transmission  \n",
       "Item Id                                                         \n",
       "cdf26f3a-f792-7a0f-350e-39e9461c54c9                       NaN  \n",
       "14c666d4-512a-8962-6072-39e918e5b2f7                       NaN  \n",
       "dc20ac44-7c35-11a7-2dfa-39e8cc01c274    Hydrostat Transmission  \n",
       "ebfb5935-40e0-4488-2e6c-39ea98658096                       NaN  \n",
       "446849                                Hydrostatic transmission  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_val.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.to_csv(\"./SkidSteer_2019-08_clean_train.csv\")\n",
    "df_val.to_csv(\"./SkidSteer_2019-08_clean_val.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class skidsteer_dataset(Dataset):\n",
    "    \"\"\"Corrosion Detection dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, \n",
    "                 csv_file, \n",
    "                 img_root, \n",
    "                 transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the csv file with annotations.\n",
    "            img_root (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied on a sample (including augmentation).\n",
    "        \"\"\"\n",
    "        self.csv_file = pd.read_csv(csv_file, index_col=0)\n",
    "        self.img_root = img_root\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.csv_file)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        '''Return one data point with a PIL image and its label.'''\n",
    "        img_dir = os.path.join(self.img_root, self.csv_file[\"unique_id\"][idx]) + \".jpg\"\n",
    "        price = self.csv_file[\"winning_bid\"][idx]\n",
    "        image = Image.open(img_dir)\n",
    "        others = torch.tensor(self.csv_file.iloc[idx, [2, 3, 4, 5, 7]])\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        sample = {'image': image, 'price': price, \"others\": others}\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm2price(tensor, min_max_scaler):\n",
    "    array2d = tensor.to(\"cpu\").data.numpy().reshape(-1, 1)\n",
    "    return np.exp(min_max_scaler.inverse_transform(array2d))\n",
    "\n",
    "def price_MAE(outputs, prices, min_max_scaler):\n",
    "    outputs = norm2price(outputs, min_max_scaler)\n",
    "    prices = norm2price(prices, min_max_scaler)\n",
    "    mae = np.abs(outputs - prices)\n",
    "    return mae.mean(), mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, model_LU, criterion, optimizer, scheduler, num_epochs=25):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_epoch = None\n",
    "    best_loss = float(\"Inf\")\n",
    "    best_mae = float(\"Inf\")\n",
    "    best_mae_list = None\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch + 1, num_epochs))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "            running_loss = 0.0\n",
    "            running_mae = 0.0\n",
    "            running_mae_list = []\n",
    "            \n",
    "            # Iterate over data.\n",
    "            for items in dataloaders[phase]:\n",
    "                images = items[\"image\"].to(device)\n",
    "                prices = items[\"price\"].to(device)\n",
    "                others = items[\"others\"].to(device)\n",
    "                optimizer.zero_grad()\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = cat_net(model, model_LU, images, others).squeeze()\n",
    "                    loss = criterion(outputs, prices)\n",
    "                    mae, mae_np = price_MAE(outputs, prices, mm_scaler_price)\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                running_loss += loss.item() * images.size(0)\n",
    "                running_mae += mae * images.size(0)\n",
    "                running_mae_list += list(mae_np.flatten())\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_mae = running_mae / dataset_sizes[phase]\n",
    "            print('{} Loss: {:.4f}'.format(phase, epoch_loss))\n",
    "            print('{} MAE: {:.4f}'.format(phase, epoch_mae))\n",
    "            \n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_loss < best_loss:\n",
    "                best_epoch = epoch + 1\n",
    "                best_loss = epoch_loss\n",
    "                best_mae = epoch_mae\n",
    "                best_mae_list = running_mae_list\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Loss: {:4f} at epoch {}'.format(best_loss, best_epoch))\n",
    "    print('Best val MAE: {:4f} at epoch {}'.format(best_mae, best_epoch))\n",
    "\n",
    "    # load best model weights\n",
    "    print(\"\\nLoad the model weights at the best epoch\")\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, best_mae_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV_FILE = {\"train\": \"./SkidSteer_2019-08_clean_train.csv\",\n",
    "            \"val\": \"./SkidSteer_2019-08_clean_val.csv\"}\n",
    "IMG_ROOT = \"../../data/images/\"\n",
    "TRANSFORM = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "datasets = {x: skidsteer_dataset(csv_file=CSV_FILE[x],\n",
    "                                 img_root=IMG_ROOT,\n",
    "                                 transform=TRANSFORM[x])\n",
    "            for x in [\"train\", \"val\"]}\n",
    "dataloaders = {x: DataLoader(datasets[x], \n",
    "                             batch_size=16, \n",
    "                             shuffle=True, \n",
    "                             num_workers=4)\n",
    "               for x in [\"train\", \"val\"]}\n",
    "dataset_sizes = {x: len(datasets[x]) for x in [\"train\", \"val\"]}\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cat_net(model, model_LU, images, others):\n",
    "    z = torch.cat((model(images), others), dim=1)\n",
    "    return model_LU(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (2053, 1) + CB3+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "### ResNet18\n",
    "model_ft = models.resnet152(pretrained=True)\n",
    "num_ftrs = model_ft.fc.in_features\n",
    "model_ft.fc = nn.Identity()\n",
    "\n",
    "### Freeze and Fine Tuning\n",
    "for param in model_ft.parameters():\n",
    "    param.requires_grad = False\n",
    "for param in model_ft.layer3.parameters():\n",
    "    param.requires_grad = True\n",
    "for param in model_ft.layer4.parameters():\n",
    "    param.requires_grad = True\n",
    "assert [param.requires_grad for param in model_ft.parameters()][-1]\n",
    "\n",
    "### LU\n",
    "model_LU = nn.Sequential(\n",
    "    nn.Linear(num_ftrs + 5, 1)\n",
    ")\n",
    "\n",
    "### model setup\n",
    "model_ft = model_ft.to(device)\n",
    "model_LU = model_LU.to(device)\n",
    "criterion = nn.MSELoss()\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.SGD(list(model_ft.parameters())+list(model_LU.parameters()), lr=0.001, momentum=0.9)\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=20, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "----------\n",
      "train Loss: 0.1017\n",
      "train MAE: 4810.7604\n",
      "val Loss: 0.0563\n",
      "val MAE: 3410.0144\n",
      "\n",
      "Epoch 2/100\n",
      "----------\n",
      "train Loss: 0.0703\n",
      "train MAE: 3965.6556\n",
      "val Loss: 0.0551\n",
      "val MAE: 3485.2092\n",
      "\n",
      "Epoch 3/100\n",
      "----------\n",
      "train Loss: 0.0878\n",
      "train MAE: 4527.2749\n",
      "val Loss: 0.2787\n",
      "val MAE: 12098.5497\n",
      "\n",
      "Epoch 4/100\n",
      "----------\n",
      "train Loss: 0.0680\n",
      "train MAE: 3939.6814\n",
      "val Loss: 0.0526\n",
      "val MAE: 3458.2348\n",
      "\n",
      "Epoch 5/100\n",
      "----------\n",
      "train Loss: 0.0780\n",
      "train MAE: 4222.8610\n",
      "val Loss: 0.0537\n",
      "val MAE: 3397.6450\n",
      "\n",
      "Epoch 6/100\n",
      "----------\n",
      "train Loss: 0.0599\n",
      "train MAE: 3691.8909\n",
      "val Loss: 0.0431\n",
      "val MAE: 2962.5277\n",
      "\n",
      "Epoch 7/100\n",
      "----------\n",
      "train Loss: 0.0593\n",
      "train MAE: 3677.7435\n",
      "val Loss: 0.0449\n",
      "val MAE: 2995.4634\n",
      "\n",
      "Epoch 8/100\n",
      "----------\n",
      "train Loss: 0.0624\n",
      "train MAE: 3789.3490\n",
      "val Loss: 0.0396\n",
      "val MAE: 2867.0919\n",
      "\n",
      "Epoch 9/100\n",
      "----------\n",
      "train Loss: 0.0656\n",
      "train MAE: 3922.9481\n",
      "val Loss: 0.0581\n",
      "val MAE: 3817.4006\n",
      "\n",
      "Epoch 10/100\n",
      "----------\n",
      "train Loss: 0.0539\n",
      "train MAE: 3480.5385\n",
      "val Loss: 0.0585\n",
      "val MAE: 3741.6139\n",
      "\n",
      "Epoch 11/100\n",
      "----------\n",
      "train Loss: 0.0585\n",
      "train MAE: 3634.4177\n",
      "val Loss: 0.1297\n",
      "val MAE: 6699.3937\n",
      "\n",
      "Epoch 12/100\n",
      "----------\n",
      "train Loss: 0.0598\n",
      "train MAE: 3697.2806\n",
      "val Loss: 0.0400\n",
      "val MAE: 2889.2217\n",
      "\n",
      "Epoch 13/100\n",
      "----------\n",
      "train Loss: 0.0546\n",
      "train MAE: 3530.3520\n",
      "val Loss: 0.0398\n",
      "val MAE: 2901.2808\n",
      "\n",
      "Epoch 14/100\n",
      "----------\n",
      "train Loss: 0.0520\n",
      "train MAE: 3456.6340\n",
      "val Loss: 0.0465\n",
      "val MAE: 3027.9272\n",
      "\n",
      "Epoch 15/100\n",
      "----------\n",
      "train Loss: 0.0524\n",
      "train MAE: 3440.5504\n",
      "val Loss: 0.0529\n",
      "val MAE: 3415.5840\n",
      "\n",
      "Epoch 16/100\n",
      "----------\n",
      "train Loss: 0.0531\n",
      "train MAE: 3461.8053\n",
      "val Loss: 0.0460\n",
      "val MAE: 2984.2872\n",
      "\n",
      "Epoch 17/100\n",
      "----------\n",
      "train Loss: 0.0465\n",
      "train MAE: 3276.9189\n",
      "val Loss: 0.0666\n",
      "val MAE: 3509.2343\n",
      "\n",
      "Epoch 18/100\n",
      "----------\n",
      "train Loss: 0.0518\n",
      "train MAE: 3408.4082\n",
      "val Loss: 0.0500\n",
      "val MAE: 3203.5927\n",
      "\n",
      "Epoch 19/100\n",
      "----------\n",
      "train Loss: 0.0463\n",
      "train MAE: 3255.8510\n",
      "val Loss: 0.1031\n",
      "val MAE: 4219.0370\n",
      "\n",
      "Epoch 20/100\n",
      "----------\n",
      "train Loss: 0.0508\n",
      "train MAE: 3354.5636\n",
      "val Loss: 0.0463\n",
      "val MAE: 3061.0460\n",
      "\n",
      "Epoch 21/100\n",
      "----------\n",
      "train Loss: 0.0333\n",
      "train MAE: 2704.0356\n",
      "val Loss: 0.0379\n",
      "val MAE: 2776.8468\n",
      "\n",
      "Epoch 22/100\n",
      "----------\n",
      "train Loss: 0.0321\n",
      "train MAE: 2683.1899\n",
      "val Loss: 0.0373\n",
      "val MAE: 2776.8069\n",
      "\n",
      "Epoch 23/100\n",
      "----------\n",
      "train Loss: 0.0312\n",
      "train MAE: 2659.0173\n",
      "val Loss: 0.0369\n",
      "val MAE: 2760.2815\n",
      "\n",
      "Epoch 24/100\n",
      "----------\n",
      "train Loss: 0.0315\n",
      "train MAE: 2640.2947\n",
      "val Loss: 0.0405\n",
      "val MAE: 2957.4104\n",
      "\n",
      "Epoch 25/100\n",
      "----------\n",
      "train Loss: 0.0324\n",
      "train MAE: 2704.4998\n",
      "val Loss: 0.0376\n",
      "val MAE: 2752.5693\n",
      "\n",
      "Epoch 26/100\n",
      "----------\n",
      "train Loss: 0.0319\n",
      "train MAE: 2664.9241\n",
      "val Loss: 0.0369\n",
      "val MAE: 2760.3053\n",
      "\n",
      "Epoch 27/100\n",
      "----------\n",
      "train Loss: 0.0303\n",
      "train MAE: 2587.9605\n",
      "val Loss: 0.0371\n",
      "val MAE: 2730.0650\n",
      "\n",
      "Epoch 28/100\n",
      "----------\n",
      "train Loss: 0.0307\n",
      "train MAE: 2588.1479\n",
      "val Loss: 0.0368\n",
      "val MAE: 2759.6509\n",
      "\n",
      "Epoch 29/100\n",
      "----------\n",
      "train Loss: 0.0314\n",
      "train MAE: 2634.5929\n",
      "val Loss: 0.0369\n",
      "val MAE: 2777.5325\n",
      "\n",
      "Epoch 30/100\n",
      "----------\n",
      "train Loss: 0.0320\n",
      "train MAE: 2650.9330\n",
      "val Loss: 0.0378\n",
      "val MAE: 2745.6931\n",
      "\n",
      "Epoch 31/100\n",
      "----------\n",
      "train Loss: 0.0315\n",
      "train MAE: 2678.1543\n",
      "val Loss: 0.0366\n",
      "val MAE: 2723.8479\n",
      "\n",
      "Epoch 32/100\n",
      "----------\n",
      "train Loss: 0.0319\n",
      "train MAE: 2649.0998\n",
      "val Loss: 0.0359\n",
      "val MAE: 2706.8544\n",
      "\n",
      "Epoch 33/100\n",
      "----------\n",
      "train Loss: 0.0299\n",
      "train MAE: 2590.2690\n",
      "val Loss: 0.0382\n",
      "val MAE: 2761.9499\n",
      "\n",
      "Epoch 34/100\n",
      "----------\n",
      "train Loss: 0.0312\n",
      "train MAE: 2629.2802\n",
      "val Loss: 0.0358\n",
      "val MAE: 2700.0460\n",
      "\n",
      "Epoch 35/100\n",
      "----------\n",
      "train Loss: 0.0304\n",
      "train MAE: 2569.4487\n",
      "val Loss: 0.0364\n",
      "val MAE: 2707.8124\n",
      "\n",
      "Epoch 36/100\n",
      "----------\n",
      "train Loss: 0.0309\n",
      "train MAE: 2617.9100\n",
      "val Loss: 0.0360\n",
      "val MAE: 2719.4879\n",
      "\n",
      "Epoch 37/100\n",
      "----------\n",
      "train Loss: 0.0305\n",
      "train MAE: 2600.4190\n",
      "val Loss: 0.0408\n",
      "val MAE: 2970.3944\n",
      "\n",
      "Epoch 38/100\n",
      "----------\n",
      "train Loss: 0.0300\n",
      "train MAE: 2549.7183\n",
      "val Loss: 0.0368\n",
      "val MAE: 2726.4391\n",
      "\n",
      "Epoch 39/100\n",
      "----------\n",
      "train Loss: 0.0308\n",
      "train MAE: 2620.3328\n",
      "val Loss: 0.0363\n",
      "val MAE: 2733.2556\n",
      "\n",
      "Epoch 40/100\n",
      "----------\n",
      "train Loss: 0.0312\n",
      "train MAE: 2639.8168\n",
      "val Loss: 0.0360\n",
      "val MAE: 2713.2771\n",
      "\n",
      "Epoch 41/100\n",
      "----------\n",
      "train Loss: 0.0289\n",
      "train MAE: 2527.0528\n",
      "val Loss: 0.0359\n",
      "val MAE: 2725.2322\n",
      "\n",
      "Epoch 42/100\n",
      "----------\n",
      "train Loss: 0.0296\n",
      "train MAE: 2517.3307\n",
      "val Loss: 0.0357\n",
      "val MAE: 2703.8331\n",
      "\n",
      "Epoch 43/100\n",
      "----------\n",
      "train Loss: 0.0290\n",
      "train MAE: 2521.3234\n",
      "val Loss: 0.0366\n",
      "val MAE: 2764.1749\n",
      "\n",
      "Epoch 44/100\n",
      "----------\n",
      "train Loss: 0.0299\n",
      "train MAE: 2578.3908\n",
      "val Loss: 0.0355\n",
      "val MAE: 2700.0405\n",
      "\n",
      "Epoch 45/100\n",
      "----------\n",
      "train Loss: 0.0289\n",
      "train MAE: 2537.0805\n",
      "val Loss: 0.0357\n",
      "val MAE: 2705.9788\n",
      "\n",
      "Epoch 46/100\n",
      "----------\n",
      "train Loss: 0.0289\n",
      "train MAE: 2510.5325\n",
      "val Loss: 0.0364\n",
      "val MAE: 2749.9683\n",
      "\n",
      "Epoch 47/100\n",
      "----------\n",
      "train Loss: 0.0296\n",
      "train MAE: 2540.5341\n",
      "val Loss: 0.0361\n",
      "val MAE: 2727.1726\n",
      "\n",
      "Epoch 48/100\n",
      "----------\n",
      "train Loss: 0.0298\n",
      "train MAE: 2563.0010\n",
      "val Loss: 0.0359\n",
      "val MAE: 2712.9722\n",
      "\n",
      "Epoch 49/100\n",
      "----------\n",
      "train Loss: 0.0294\n",
      "train MAE: 2565.0519\n",
      "val Loss: 0.0356\n",
      "val MAE: 2696.8546\n",
      "\n",
      "Epoch 50/100\n",
      "----------\n",
      "train Loss: 0.0294\n",
      "train MAE: 2552.8278\n",
      "val Loss: 0.0358\n",
      "val MAE: 2709.4572\n",
      "\n",
      "Epoch 51/100\n",
      "----------\n",
      "train Loss: 0.0299\n",
      "train MAE: 2546.0666\n",
      "val Loss: 0.0358\n",
      "val MAE: 2708.7438\n",
      "\n",
      "Epoch 52/100\n",
      "----------\n",
      "train Loss: 0.0290\n",
      "train MAE: 2531.3757\n",
      "val Loss: 0.0356\n",
      "val MAE: 2705.4263\n",
      "\n",
      "Epoch 53/100\n",
      "----------\n",
      "train Loss: 0.0301\n",
      "train MAE: 2594.0458\n",
      "val Loss: 0.0360\n",
      "val MAE: 2724.3843\n",
      "\n",
      "Epoch 54/100\n",
      "----------\n",
      "train Loss: 0.0293\n",
      "train MAE: 2543.0062\n",
      "val Loss: 0.0355\n",
      "val MAE: 2697.5636\n",
      "\n",
      "Epoch 55/100\n",
      "----------\n",
      "train Loss: 0.0297\n",
      "train MAE: 2565.4359\n",
      "val Loss: 0.0361\n",
      "val MAE: 2733.7744\n",
      "\n",
      "Epoch 56/100\n",
      "----------\n",
      "train Loss: 0.0283\n",
      "train MAE: 2481.7655\n",
      "val Loss: 0.0356\n",
      "val MAE: 2702.4542\n",
      "\n",
      "Epoch 57/100\n",
      "----------\n",
      "train Loss: 0.0294\n",
      "train MAE: 2567.1054\n",
      "val Loss: 0.0359\n",
      "val MAE: 2723.9442\n",
      "\n",
      "Epoch 58/100\n",
      "----------\n",
      "train Loss: 0.0281\n",
      "train MAE: 2501.3921\n",
      "val Loss: 0.0355\n",
      "val MAE: 2682.2086\n",
      "\n",
      "Epoch 59/100\n",
      "----------\n",
      "train Loss: 0.0288\n",
      "train MAE: 2533.1249\n",
      "val Loss: 0.0356\n",
      "val MAE: 2707.8289\n",
      "\n",
      "Epoch 60/100\n",
      "----------\n",
      "train Loss: 0.0291\n",
      "train MAE: 2549.9379\n",
      "val Loss: 0.0357\n",
      "val MAE: 2698.3750\n",
      "\n",
      "Epoch 61/100\n",
      "----------\n",
      "train Loss: 0.0287\n",
      "train MAE: 2532.3693\n",
      "val Loss: 0.0359\n",
      "val MAE: 2699.1319\n",
      "\n",
      "Epoch 62/100\n",
      "----------\n",
      "train Loss: 0.0290\n",
      "train MAE: 2555.6588\n",
      "val Loss: 0.0356\n",
      "val MAE: 2692.7014\n",
      "\n",
      "Epoch 63/100\n",
      "----------\n",
      "train Loss: 0.0288\n",
      "train MAE: 2519.5296\n",
      "val Loss: 0.0354\n",
      "val MAE: 2691.3875\n",
      "\n",
      "Epoch 64/100\n",
      "----------\n",
      "train Loss: 0.0286\n",
      "train MAE: 2510.9489\n",
      "val Loss: 0.0355\n",
      "val MAE: 2702.3769\n",
      "\n",
      "Epoch 65/100\n",
      "----------\n",
      "train Loss: 0.0301\n",
      "train MAE: 2571.3495\n",
      "val Loss: 0.0356\n",
      "val MAE: 2703.6924\n",
      "\n",
      "Epoch 66/100\n",
      "----------\n",
      "train Loss: 0.0289\n",
      "train MAE: 2512.9776\n",
      "val Loss: 0.0356\n",
      "val MAE: 2707.4807\n",
      "\n",
      "Epoch 67/100\n",
      "----------\n",
      "train Loss: 0.0291\n",
      "train MAE: 2535.0025\n",
      "val Loss: 0.0357\n",
      "val MAE: 2712.0651\n",
      "\n",
      "Epoch 68/100\n",
      "----------\n",
      "train Loss: 0.0287\n",
      "train MAE: 2519.7902\n",
      "val Loss: 0.0361\n",
      "val MAE: 2694.0777\n",
      "\n",
      "Epoch 69/100\n",
      "----------\n",
      "train Loss: 0.0292\n",
      "train MAE: 2535.4713\n",
      "val Loss: 0.0356\n",
      "val MAE: 2690.1021\n",
      "\n",
      "Epoch 70/100\n",
      "----------\n",
      "train Loss: 0.0285\n",
      "train MAE: 2546.8051\n",
      "val Loss: 0.0355\n",
      "val MAE: 2680.3156\n",
      "\n",
      "Epoch 71/100\n",
      "----------\n",
      "train Loss: 0.0293\n",
      "train MAE: 2551.8545\n",
      "val Loss: 0.0359\n",
      "val MAE: 2714.7172\n",
      "\n",
      "Epoch 72/100\n",
      "----------\n",
      "train Loss: 0.0281\n",
      "train MAE: 2485.2005\n",
      "val Loss: 0.0358\n",
      "val MAE: 2717.8143\n",
      "\n",
      "Epoch 73/100\n",
      "----------\n",
      "train Loss: 0.0290\n",
      "train MAE: 2544.1588\n",
      "val Loss: 0.0358\n",
      "val MAE: 2703.1023\n",
      "\n",
      "Epoch 74/100\n",
      "----------\n",
      "train Loss: 0.0278\n",
      "train MAE: 2470.4947\n",
      "val Loss: 0.0355\n",
      "val MAE: 2696.8404\n",
      "\n",
      "Epoch 75/100\n",
      "----------\n",
      "train Loss: 0.0276\n",
      "train MAE: 2459.7336\n",
      "val Loss: 0.0355\n",
      "val MAE: 2691.2878\n",
      "\n",
      "Epoch 76/100\n",
      "----------\n",
      "train Loss: 0.0291\n",
      "train MAE: 2538.8308\n",
      "val Loss: 0.0358\n",
      "val MAE: 2705.3624\n",
      "\n",
      "Epoch 77/100\n",
      "----------\n",
      "train Loss: 0.0288\n",
      "train MAE: 2522.7288\n",
      "val Loss: 0.0356\n",
      "val MAE: 2696.3223\n",
      "\n",
      "Epoch 78/100\n",
      "----------\n",
      "train Loss: 0.0285\n",
      "train MAE: 2510.6589\n",
      "val Loss: 0.0356\n",
      "val MAE: 2695.9852\n",
      "\n",
      "Epoch 79/100\n",
      "----------\n",
      "train Loss: 0.0293\n",
      "train MAE: 2531.4635\n",
      "val Loss: 0.0359\n",
      "val MAE: 2726.5636\n",
      "\n",
      "Epoch 80/100\n",
      "----------\n",
      "train Loss: 0.0290\n",
      "train MAE: 2555.4881\n",
      "val Loss: 0.0358\n",
      "val MAE: 2705.7120\n",
      "\n",
      "Epoch 81/100\n",
      "----------\n",
      "train Loss: 0.0290\n",
      "train MAE: 2524.4832\n",
      "val Loss: 0.0356\n",
      "val MAE: 2698.9471\n",
      "\n",
      "Epoch 82/100\n",
      "----------\n",
      "train Loss: 0.0294\n",
      "train MAE: 2568.3337\n",
      "val Loss: 0.0352\n",
      "val MAE: 2682.2953\n",
      "\n",
      "Epoch 83/100\n",
      "----------\n",
      "train Loss: 0.0296\n",
      "train MAE: 2570.0682\n",
      "val Loss: 0.0359\n",
      "val MAE: 2702.3486\n",
      "\n",
      "Epoch 84/100\n",
      "----------\n",
      "train Loss: 0.0280\n",
      "train MAE: 2512.8442\n",
      "val Loss: 0.0361\n",
      "val MAE: 2732.7233\n",
      "\n",
      "Epoch 85/100\n",
      "----------\n",
      "train Loss: 0.0297\n",
      "train MAE: 2554.9792\n",
      "val Loss: 0.0359\n",
      "val MAE: 2723.3212\n",
      "\n",
      "Epoch 86/100\n",
      "----------\n",
      "train Loss: 0.0288\n",
      "train MAE: 2513.4290\n",
      "val Loss: 0.0354\n",
      "val MAE: 2691.3659\n",
      "\n",
      "Epoch 87/100\n",
      "----------\n",
      "train Loss: 0.0284\n",
      "train MAE: 2518.2007\n",
      "val Loss: 0.0358\n",
      "val MAE: 2707.1131\n",
      "\n",
      "Epoch 88/100\n",
      "----------\n",
      "train Loss: 0.0290\n",
      "train MAE: 2527.4383\n",
      "val Loss: 0.0356\n",
      "val MAE: 2690.9233\n",
      "\n",
      "Epoch 89/100\n",
      "----------\n",
      "train Loss: 0.0288\n",
      "train MAE: 2552.5475\n",
      "val Loss: 0.0355\n",
      "val MAE: 2690.1500\n",
      "\n",
      "Epoch 90/100\n",
      "----------\n",
      "train Loss: 0.0296\n",
      "train MAE: 2527.4322\n",
      "val Loss: 0.0359\n",
      "val MAE: 2723.0007\n",
      "\n",
      "Epoch 91/100\n",
      "----------\n",
      "train Loss: 0.0290\n",
      "train MAE: 2498.7440\n",
      "val Loss: 0.0358\n",
      "val MAE: 2719.7907\n",
      "\n",
      "Epoch 92/100\n",
      "----------\n",
      "train Loss: 0.0290\n",
      "train MAE: 2507.5412\n",
      "val Loss: 0.0358\n",
      "val MAE: 2721.8049\n",
      "\n",
      "Epoch 93/100\n",
      "----------\n",
      "train Loss: 0.0287\n",
      "train MAE: 2507.7728\n",
      "val Loss: 0.0355\n",
      "val MAE: 2678.1235\n",
      "\n",
      "Epoch 94/100\n",
      "----------\n",
      "train Loss: 0.0290\n",
      "train MAE: 2537.2908\n",
      "val Loss: 0.0356\n",
      "val MAE: 2703.3788\n",
      "\n",
      "Epoch 95/100\n",
      "----------\n",
      "train Loss: 0.0300\n",
      "train MAE: 2616.6117\n",
      "val Loss: 0.0358\n",
      "val MAE: 2712.8562\n",
      "\n",
      "Epoch 96/100\n",
      "----------\n",
      "train Loss: 0.0284\n",
      "train MAE: 2506.6381\n",
      "val Loss: 0.0357\n",
      "val MAE: 2706.0263\n",
      "\n",
      "Epoch 97/100\n",
      "----------\n",
      "train Loss: 0.0289\n",
      "train MAE: 2546.0694\n",
      "val Loss: 0.0358\n",
      "val MAE: 2715.6865\n",
      "\n",
      "Epoch 98/100\n",
      "----------\n",
      "train Loss: 0.0280\n",
      "train MAE: 2478.8154\n",
      "val Loss: 0.0357\n",
      "val MAE: 2689.7318\n",
      "\n",
      "Epoch 99/100\n",
      "----------\n",
      "train Loss: 0.0289\n",
      "train MAE: 2540.5377\n",
      "val Loss: 0.0357\n",
      "val MAE: 2710.4109\n",
      "\n",
      "Epoch 100/100\n",
      "----------\n",
      "train Loss: 0.0297\n",
      "train MAE: 2555.5270\n",
      "val Loss: 0.0358\n",
      "val MAE: 2717.9129\n",
      "\n",
      "Training complete in 131m 2s\n",
      "Best val Loss: 0.035242 at epoch 82\n",
      "Best val MAE: 2682.295287 at epoch 82\n",
      "\n",
      "Load the model weights at the best epoch\n"
     ]
    }
   ],
   "source": [
    "model_res152, mae_list_0 = train_model(model_ft, model_LU, criterion, optimizer_ft, exp_lr_scheduler, num_epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (2053, 32, 1) + CB3+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "### ResNet18\n",
    "model_ft = models.resnet152(pretrained=True)\n",
    "num_ftrs = model_ft.fc.in_features\n",
    "model_ft.fc = nn.Identity()\n",
    "\n",
    "### Freeze and Fine Tuning\n",
    "for param in model_ft.parameters():\n",
    "    param.requires_grad = False\n",
    "for param in model_ft.layer3.parameters():\n",
    "    param.requires_grad = True\n",
    "for param in model_ft.layer4.parameters():\n",
    "    param.requires_grad = True\n",
    "assert [param.requires_grad for param in model_ft.parameters()][-1]\n",
    "\n",
    "### LU\n",
    "model_LU = nn.Sequential(\n",
    "    nn.Linear(num_ftrs + 5, 32),\n",
    "    nn.Tanh(), \n",
    "    nn.Linear(32, 1)\n",
    ")\n",
    "\n",
    "### model setup\n",
    "model_ft = model_ft.to(device)\n",
    "model_LU = model_LU.to(device)\n",
    "criterion = nn.MSELoss()\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.SGD(list(model_ft.parameters())+list(model_LU.parameters()), lr=0.001, momentum=0.9)\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=20, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "----------\n",
      "train Loss: 0.0817\n",
      "train MAE: 4303.2025\n",
      "val Loss: 0.0491\n",
      "val MAE: 3253.5203\n",
      "\n",
      "Epoch 2/100\n",
      "----------\n",
      "train Loss: 0.0575\n",
      "train MAE: 3599.3650\n",
      "val Loss: 0.0438\n",
      "val MAE: 3051.9073\n",
      "\n",
      "Epoch 3/100\n",
      "----------\n",
      "train Loss: 0.0521\n",
      "train MAE: 3432.8679\n",
      "val Loss: 0.0416\n",
      "val MAE: 2959.5806\n",
      "\n",
      "Epoch 4/100\n",
      "----------\n",
      "train Loss: 0.0495\n",
      "train MAE: 3323.0131\n",
      "val Loss: 0.0401\n",
      "val MAE: 2916.4873\n",
      "\n",
      "Epoch 5/100\n",
      "----------\n",
      "train Loss: 0.0462\n",
      "train MAE: 3195.9595\n",
      "val Loss: 0.0412\n",
      "val MAE: 2934.3668\n",
      "\n",
      "Epoch 6/100\n",
      "----------\n",
      "train Loss: 0.0479\n",
      "train MAE: 3240.5021\n",
      "val Loss: 0.0464\n",
      "val MAE: 3173.1066\n",
      "\n",
      "Epoch 7/100\n",
      "----------\n",
      "train Loss: 0.0428\n",
      "train MAE: 3102.8771\n",
      "val Loss: 0.0372\n",
      "val MAE: 2810.6604\n",
      "\n",
      "Epoch 8/100\n",
      "----------\n",
      "train Loss: 0.0434\n",
      "train MAE: 3094.2295\n",
      "val Loss: 0.0399\n",
      "val MAE: 2903.9555\n",
      "\n",
      "Epoch 9/100\n",
      "----------\n",
      "train Loss: 0.0404\n",
      "train MAE: 2982.6758\n",
      "val Loss: 0.0366\n",
      "val MAE: 2747.8979\n",
      "\n",
      "Epoch 10/100\n",
      "----------\n",
      "train Loss: 0.0410\n",
      "train MAE: 3027.5436\n",
      "val Loss: 0.0362\n",
      "val MAE: 2736.8537\n",
      "\n",
      "Epoch 11/100\n",
      "----------\n",
      "train Loss: 0.0394\n",
      "train MAE: 2968.9816\n",
      "val Loss: 0.0385\n",
      "val MAE: 2848.5045\n",
      "\n",
      "Epoch 12/100\n",
      "----------\n",
      "train Loss: 0.0394\n",
      "train MAE: 2932.8668\n",
      "val Loss: 0.0350\n",
      "val MAE: 2699.1967\n",
      "\n",
      "Epoch 13/100\n",
      "----------\n",
      "train Loss: 0.0362\n",
      "train MAE: 2820.2023\n",
      "val Loss: 0.0348\n",
      "val MAE: 2694.0256\n",
      "\n",
      "Epoch 14/100\n",
      "----------\n",
      "train Loss: 0.0367\n",
      "train MAE: 2854.5530\n",
      "val Loss: 0.0342\n",
      "val MAE: 2666.5313\n",
      "\n",
      "Epoch 15/100\n",
      "----------\n",
      "train Loss: 0.0369\n",
      "train MAE: 2862.2745\n",
      "val Loss: 0.0351\n",
      "val MAE: 2679.0428\n",
      "\n",
      "Epoch 16/100\n",
      "----------\n",
      "train Loss: 0.0372\n",
      "train MAE: 2865.8314\n",
      "val Loss: 0.0340\n",
      "val MAE: 2651.8779\n",
      "\n",
      "Epoch 17/100\n",
      "----------\n",
      "train Loss: 0.0345\n",
      "train MAE: 2763.7744\n",
      "val Loss: 0.0374\n",
      "val MAE: 2800.3344\n",
      "\n",
      "Epoch 18/100\n",
      "----------\n",
      "train Loss: 0.0341\n",
      "train MAE: 2729.2047\n",
      "val Loss: 0.0364\n",
      "val MAE: 2731.9610\n",
      "\n",
      "Epoch 19/100\n",
      "----------\n",
      "train Loss: 0.0347\n",
      "train MAE: 2781.4041\n",
      "val Loss: 0.0339\n",
      "val MAE: 2644.1154\n",
      "\n",
      "Epoch 20/100\n",
      "----------\n",
      "train Loss: 0.0327\n",
      "train MAE: 2683.0389\n",
      "val Loss: 0.0428\n",
      "val MAE: 3058.2520\n",
      "\n",
      "Epoch 21/100\n",
      "----------\n",
      "train Loss: 0.0306\n",
      "train MAE: 2600.7701\n",
      "val Loss: 0.0334\n",
      "val MAE: 2617.1599\n",
      "\n",
      "Epoch 22/100\n",
      "----------\n",
      "train Loss: 0.0310\n",
      "train MAE: 2612.7170\n",
      "val Loss: 0.0340\n",
      "val MAE: 2638.0911\n",
      "\n",
      "Epoch 23/100\n",
      "----------\n",
      "train Loss: 0.0305\n",
      "train MAE: 2579.9279\n",
      "val Loss: 0.0336\n",
      "val MAE: 2621.9664\n",
      "\n",
      "Epoch 24/100\n",
      "----------\n",
      "train Loss: 0.0306\n",
      "train MAE: 2587.9831\n",
      "val Loss: 0.0327\n",
      "val MAE: 2586.2665\n",
      "\n",
      "Epoch 25/100\n",
      "----------\n",
      "train Loss: 0.0294\n",
      "train MAE: 2538.6202\n",
      "val Loss: 0.0337\n",
      "val MAE: 2622.6332\n",
      "\n",
      "Epoch 26/100\n",
      "----------\n",
      "train Loss: 0.0303\n",
      "train MAE: 2582.8751\n",
      "val Loss: 0.0333\n",
      "val MAE: 2609.7816\n",
      "\n",
      "Epoch 27/100\n",
      "----------\n",
      "train Loss: 0.0298\n",
      "train MAE: 2570.5100\n",
      "val Loss: 0.0327\n",
      "val MAE: 2585.7297\n",
      "\n",
      "Epoch 28/100\n",
      "----------\n",
      "train Loss: 0.0289\n",
      "train MAE: 2515.7108\n",
      "val Loss: 0.0333\n",
      "val MAE: 2607.3957\n",
      "\n",
      "Epoch 29/100\n",
      "----------\n",
      "train Loss: 0.0296\n",
      "train MAE: 2559.4928\n",
      "val Loss: 0.0338\n",
      "val MAE: 2629.6379\n",
      "\n",
      "Epoch 30/100\n",
      "----------\n",
      "train Loss: 0.0298\n",
      "train MAE: 2549.2166\n",
      "val Loss: 0.0336\n",
      "val MAE: 2623.0502\n",
      "\n",
      "Epoch 31/100\n",
      "----------\n",
      "train Loss: 0.0295\n",
      "train MAE: 2529.2730\n",
      "val Loss: 0.0328\n",
      "val MAE: 2593.6884\n",
      "\n",
      "Epoch 32/100\n",
      "----------\n",
      "train Loss: 0.0293\n",
      "train MAE: 2548.3085\n",
      "val Loss: 0.0339\n",
      "val MAE: 2636.3438\n",
      "\n",
      "Epoch 33/100\n",
      "----------\n",
      "train Loss: 0.0298\n",
      "train MAE: 2564.1866\n",
      "val Loss: 0.0330\n",
      "val MAE: 2594.6444\n",
      "\n",
      "Epoch 34/100\n",
      "----------\n",
      "train Loss: 0.0295\n",
      "train MAE: 2527.1389\n",
      "val Loss: 0.0328\n",
      "val MAE: 2587.4345\n",
      "\n",
      "Epoch 35/100\n",
      "----------\n",
      "train Loss: 0.0292\n",
      "train MAE: 2535.6394\n",
      "val Loss: 0.0329\n",
      "val MAE: 2595.1399\n",
      "\n",
      "Epoch 36/100\n",
      "----------\n",
      "train Loss: 0.0294\n",
      "train MAE: 2527.7355\n",
      "val Loss: 0.0328\n",
      "val MAE: 2591.8111\n",
      "\n",
      "Epoch 37/100\n",
      "----------\n",
      "train Loss: 0.0288\n",
      "train MAE: 2540.4103\n",
      "val Loss: 0.0337\n",
      "val MAE: 2618.3374\n",
      "\n",
      "Epoch 38/100\n",
      "----------\n",
      "train Loss: 0.0287\n",
      "train MAE: 2502.0525\n",
      "val Loss: 0.0336\n",
      "val MAE: 2621.2019\n",
      "\n",
      "Epoch 39/100\n",
      "----------\n",
      "train Loss: 0.0290\n",
      "train MAE: 2495.4252\n",
      "val Loss: 0.0330\n",
      "val MAE: 2594.3181\n",
      "\n",
      "Epoch 40/100\n",
      "----------\n",
      "train Loss: 0.0283\n",
      "train MAE: 2475.2491\n",
      "val Loss: 0.0343\n",
      "val MAE: 2659.6277\n",
      "\n",
      "Epoch 41/100\n",
      "----------\n",
      "train Loss: 0.0299\n",
      "train MAE: 2535.6023\n",
      "val Loss: 0.0347\n",
      "val MAE: 2667.3626\n",
      "\n",
      "Epoch 42/100\n",
      "----------\n",
      "train Loss: 0.0293\n",
      "train MAE: 2550.5721\n",
      "val Loss: 0.0329\n",
      "val MAE: 2590.6419\n",
      "\n",
      "Epoch 43/100\n",
      "----------\n",
      "train Loss: 0.0288\n",
      "train MAE: 2517.5286\n",
      "val Loss: 0.0330\n",
      "val MAE: 2592.0213\n",
      "\n",
      "Epoch 44/100\n",
      "----------\n",
      "train Loss: 0.0290\n",
      "train MAE: 2531.4085\n",
      "val Loss: 0.0334\n",
      "val MAE: 2610.8481\n",
      "\n",
      "Epoch 45/100\n",
      "----------\n",
      "train Loss: 0.0286\n",
      "train MAE: 2508.0741\n",
      "val Loss: 0.0327\n",
      "val MAE: 2585.2057\n",
      "\n",
      "Epoch 46/100\n",
      "----------\n",
      "train Loss: 0.0272\n",
      "train MAE: 2433.9591\n",
      "val Loss: 0.0330\n",
      "val MAE: 2606.2363\n",
      "\n",
      "Epoch 47/100\n",
      "----------\n",
      "train Loss: 0.0278\n",
      "train MAE: 2473.4552\n",
      "val Loss: 0.0329\n",
      "val MAE: 2597.4960\n",
      "\n",
      "Epoch 48/100\n",
      "----------\n",
      "train Loss: 0.0286\n",
      "train MAE: 2502.5468\n",
      "val Loss: 0.0328\n",
      "val MAE: 2583.3263\n",
      "\n",
      "Epoch 49/100\n",
      "----------\n",
      "train Loss: 0.0294\n",
      "train MAE: 2554.0543\n",
      "val Loss: 0.0332\n",
      "val MAE: 2609.2101\n",
      "\n",
      "Epoch 50/100\n",
      "----------\n",
      "train Loss: 0.0286\n",
      "train MAE: 2489.4828\n",
      "val Loss: 0.0327\n",
      "val MAE: 2580.8169\n",
      "\n",
      "Epoch 51/100\n",
      "----------\n",
      "train Loss: 0.0298\n",
      "train MAE: 2531.7726\n",
      "val Loss: 0.0341\n",
      "val MAE: 2640.7995\n",
      "\n",
      "Epoch 52/100\n",
      "----------\n",
      "train Loss: 0.0284\n",
      "train MAE: 2500.3102\n",
      "val Loss: 0.0326\n",
      "val MAE: 2578.1340\n",
      "\n",
      "Epoch 53/100\n",
      "----------\n",
      "train Loss: 0.0294\n",
      "train MAE: 2539.6398\n",
      "val Loss: 0.0331\n",
      "val MAE: 2603.4893\n",
      "\n",
      "Epoch 54/100\n",
      "----------\n",
      "train Loss: 0.0291\n",
      "train MAE: 2539.7590\n",
      "val Loss: 0.0329\n",
      "val MAE: 2594.3533\n",
      "\n",
      "Epoch 55/100\n",
      "----------\n",
      "train Loss: 0.0279\n",
      "train MAE: 2466.3630\n",
      "val Loss: 0.0331\n",
      "val MAE: 2596.0146\n",
      "\n",
      "Epoch 56/100\n",
      "----------\n",
      "train Loss: 0.0277\n",
      "train MAE: 2489.2944\n",
      "val Loss: 0.0327\n",
      "val MAE: 2584.8573\n",
      "\n",
      "Epoch 57/100\n",
      "----------\n",
      "train Loss: 0.0291\n",
      "train MAE: 2494.9272\n",
      "val Loss: 0.0342\n",
      "val MAE: 2642.8966\n",
      "\n",
      "Epoch 58/100\n",
      "----------\n",
      "train Loss: 0.0298\n",
      "train MAE: 2559.1435\n",
      "val Loss: 0.0339\n",
      "val MAE: 2629.4493\n",
      "\n",
      "Epoch 59/100\n",
      "----------\n",
      "train Loss: 0.0290\n",
      "train MAE: 2526.1078\n",
      "val Loss: 0.0333\n",
      "val MAE: 2609.3109\n",
      "\n",
      "Epoch 60/100\n",
      "----------\n",
      "train Loss: 0.0288\n",
      "train MAE: 2501.3859\n",
      "val Loss: 0.0337\n",
      "val MAE: 2620.7345\n",
      "\n",
      "Epoch 61/100\n",
      "----------\n",
      "train Loss: 0.0288\n",
      "train MAE: 2500.0750\n",
      "val Loss: 0.0336\n",
      "val MAE: 2615.4503\n",
      "\n",
      "Epoch 62/100\n",
      "----------\n",
      "train Loss: 0.0279\n",
      "train MAE: 2477.1755\n",
      "val Loss: 0.0339\n",
      "val MAE: 2630.7605\n",
      "\n",
      "Epoch 63/100\n",
      "----------\n",
      "train Loss: 0.0295\n",
      "train MAE: 2527.7780\n",
      "val Loss: 0.0337\n",
      "val MAE: 2620.5002\n",
      "\n",
      "Epoch 64/100\n",
      "----------\n",
      "train Loss: 0.0288\n",
      "train MAE: 2518.9146\n",
      "val Loss: 0.0333\n",
      "val MAE: 2604.7497\n",
      "\n",
      "Epoch 65/100\n",
      "----------\n",
      "train Loss: 0.0284\n",
      "train MAE: 2480.9429\n",
      "val Loss: 0.0336\n",
      "val MAE: 2624.6243\n",
      "\n",
      "Epoch 66/100\n",
      "----------\n",
      "train Loss: 0.0295\n",
      "train MAE: 2534.3691\n",
      "val Loss: 0.0325\n",
      "val MAE: 2569.4485\n",
      "\n",
      "Epoch 67/100\n",
      "----------\n",
      "train Loss: 0.0291\n",
      "train MAE: 2500.1951\n",
      "val Loss: 0.0328\n",
      "val MAE: 2585.2135\n",
      "\n",
      "Epoch 68/100\n",
      "----------\n",
      "train Loss: 0.0279\n",
      "train MAE: 2481.7212\n",
      "val Loss: 0.0344\n",
      "val MAE: 2652.1335\n",
      "\n",
      "Epoch 69/100\n",
      "----------\n",
      "train Loss: 0.0290\n",
      "train MAE: 2539.8793\n",
      "val Loss: 0.0328\n",
      "val MAE: 2585.9840\n",
      "\n",
      "Epoch 70/100\n",
      "----------\n",
      "train Loss: 0.0281\n",
      "train MAE: 2478.5610\n",
      "val Loss: 0.0325\n",
      "val MAE: 2575.7412\n",
      "\n",
      "Epoch 71/100\n",
      "----------\n",
      "train Loss: 0.0284\n",
      "train MAE: 2491.0290\n",
      "val Loss: 0.0330\n",
      "val MAE: 2600.9846\n",
      "\n",
      "Epoch 72/100\n",
      "----------\n",
      "train Loss: 0.0292\n",
      "train MAE: 2544.5713\n",
      "val Loss: 0.0329\n",
      "val MAE: 2588.3243\n",
      "\n",
      "Epoch 73/100\n",
      "----------\n",
      "train Loss: 0.0282\n",
      "train MAE: 2479.4486\n",
      "val Loss: 0.0327\n",
      "val MAE: 2593.2073\n",
      "\n",
      "Epoch 74/100\n",
      "----------\n",
      "train Loss: 0.0291\n",
      "train MAE: 2541.8615\n",
      "val Loss: 0.0341\n",
      "val MAE: 2645.5888\n",
      "\n",
      "Epoch 75/100\n",
      "----------\n",
      "train Loss: 0.0292\n",
      "train MAE: 2515.5072\n",
      "val Loss: 0.0328\n",
      "val MAE: 2583.0196\n",
      "\n",
      "Epoch 76/100\n",
      "----------\n",
      "train Loss: 0.0280\n",
      "train MAE: 2449.8468\n",
      "val Loss: 0.0335\n",
      "val MAE: 2616.6675\n",
      "\n",
      "Epoch 77/100\n",
      "----------\n",
      "train Loss: 0.0290\n",
      "train MAE: 2517.4068\n",
      "val Loss: 0.0324\n",
      "val MAE: 2570.1581\n",
      "\n",
      "Epoch 78/100\n",
      "----------\n",
      "train Loss: 0.0283\n",
      "train MAE: 2495.8751\n",
      "val Loss: 0.0330\n",
      "val MAE: 2601.3111\n",
      "\n",
      "Epoch 79/100\n",
      "----------\n",
      "train Loss: 0.0286\n",
      "train MAE: 2490.2647\n",
      "val Loss: 0.0330\n",
      "val MAE: 2588.2040\n",
      "\n",
      "Epoch 80/100\n",
      "----------\n",
      "train Loss: 0.0293\n",
      "train MAE: 2523.9768\n",
      "val Loss: 0.0333\n",
      "val MAE: 2605.1348\n",
      "\n",
      "Epoch 81/100\n",
      "----------\n",
      "train Loss: 0.0290\n",
      "train MAE: 2528.4565\n",
      "val Loss: 0.0325\n",
      "val MAE: 2577.0374\n",
      "\n",
      "Epoch 82/100\n",
      "----------\n",
      "train Loss: 0.0283\n",
      "train MAE: 2501.0179\n",
      "val Loss: 0.0328\n",
      "val MAE: 2585.2618\n",
      "\n",
      "Epoch 83/100\n",
      "----------\n",
      "train Loss: 0.0288\n",
      "train MAE: 2513.7679\n",
      "val Loss: 0.0342\n",
      "val MAE: 2647.2662\n",
      "\n",
      "Epoch 84/100\n",
      "----------\n",
      "train Loss: 0.0289\n",
      "train MAE: 2516.5191\n",
      "val Loss: 0.0332\n",
      "val MAE: 2599.2979\n",
      "\n",
      "Epoch 85/100\n",
      "----------\n",
      "train Loss: 0.0287\n",
      "train MAE: 2496.9356\n",
      "val Loss: 0.0327\n",
      "val MAE: 2582.1525\n",
      "\n",
      "Epoch 86/100\n",
      "----------\n",
      "train Loss: 0.0286\n",
      "train MAE: 2492.6733\n",
      "val Loss: 0.0327\n",
      "val MAE: 2588.1279\n",
      "\n",
      "Epoch 87/100\n",
      "----------\n",
      "train Loss: 0.0287\n",
      "train MAE: 2487.5843\n",
      "val Loss: 0.0326\n",
      "val MAE: 2578.5271\n",
      "\n",
      "Epoch 88/100\n",
      "----------\n",
      "train Loss: 0.0283\n",
      "train MAE: 2474.1399\n",
      "val Loss: 0.0326\n",
      "val MAE: 2574.6776\n",
      "\n",
      "Epoch 89/100\n",
      "----------\n",
      "train Loss: 0.0284\n",
      "train MAE: 2478.2874\n",
      "val Loss: 0.0329\n",
      "val MAE: 2585.5106\n",
      "\n",
      "Epoch 90/100\n",
      "----------\n",
      "train Loss: 0.0275\n",
      "train MAE: 2444.1662\n",
      "val Loss: 0.0333\n",
      "val MAE: 2605.7882\n",
      "\n",
      "Epoch 91/100\n",
      "----------\n",
      "train Loss: 0.0290\n",
      "train MAE: 2520.4164\n",
      "val Loss: 0.0327\n",
      "val MAE: 2584.2152\n",
      "\n",
      "Epoch 92/100\n",
      "----------\n",
      "train Loss: 0.0285\n",
      "train MAE: 2490.1649\n",
      "val Loss: 0.0330\n",
      "val MAE: 2591.8644\n",
      "\n",
      "Epoch 93/100\n",
      "----------\n",
      "train Loss: 0.0280\n",
      "train MAE: 2498.0769\n",
      "val Loss: 0.0326\n",
      "val MAE: 2579.6081\n",
      "\n",
      "Epoch 94/100\n",
      "----------\n",
      "train Loss: 0.0281\n",
      "train MAE: 2482.4588\n",
      "val Loss: 0.0331\n",
      "val MAE: 2600.6378\n",
      "\n",
      "Epoch 95/100\n",
      "----------\n",
      "train Loss: 0.0291\n",
      "train MAE: 2516.5585\n",
      "val Loss: 0.0334\n",
      "val MAE: 2613.8740\n",
      "\n",
      "Epoch 96/100\n",
      "----------\n",
      "train Loss: 0.0273\n",
      "train MAE: 2450.4461\n",
      "val Loss: 0.0337\n",
      "val MAE: 2620.9219\n",
      "\n",
      "Epoch 97/100\n",
      "----------\n",
      "train Loss: 0.0284\n",
      "train MAE: 2492.2260\n",
      "val Loss: 0.0331\n",
      "val MAE: 2607.8163\n",
      "\n",
      "Epoch 98/100\n",
      "----------\n",
      "train Loss: 0.0290\n",
      "train MAE: 2528.5600\n",
      "val Loss: 0.0327\n",
      "val MAE: 2580.3775\n",
      "\n",
      "Epoch 99/100\n",
      "----------\n",
      "train Loss: 0.0279\n",
      "train MAE: 2484.2239\n",
      "val Loss: 0.0326\n",
      "val MAE: 2575.8803\n",
      "\n",
      "Epoch 100/100\n",
      "----------\n",
      "train Loss: 0.0283\n",
      "train MAE: 2480.7482\n",
      "val Loss: 0.0330\n",
      "val MAE: 2589.2390\n",
      "\n",
      "Training complete in 127m 36s\n",
      "Best val Loss: 0.032363 at epoch 77\n",
      "Best val MAE: 2570.158077 at epoch 77\n",
      "\n",
      "Load the model weights at the best epoch\n"
     ]
    }
   ],
   "source": [
    "model_res152, mae_list_1 = train_model(model_ft, model_LU, criterion, optimizer_ft, exp_lr_scheduler, num_epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (2053, 64, 1) + CB3+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "### ResNet18\n",
    "model_ft = models.resnet152(pretrained=True)\n",
    "num_ftrs = model_ft.fc.in_features\n",
    "model_ft.fc = nn.Identity()\n",
    "\n",
    "### Freeze and Fine Tuning\n",
    "for param in model_ft.parameters():\n",
    "    param.requires_grad = False\n",
    "for param in model_ft.layer3.parameters():\n",
    "    param.requires_grad = True\n",
    "for param in model_ft.layer4.parameters():\n",
    "    param.requires_grad = True\n",
    "assert [param.requires_grad for param in model_ft.parameters()][-1]\n",
    "\n",
    "### LU\n",
    "model_LU = nn.Sequential(\n",
    "    nn.Linear(num_ftrs + 5, 64),\n",
    "    nn.Tanh(), \n",
    "    nn.Linear(64, 1)\n",
    ")\n",
    "\n",
    "### model setup\n",
    "model_ft = model_ft.to(device)\n",
    "model_LU = model_LU.to(device)\n",
    "criterion = nn.MSELoss()\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.SGD(list(model_ft.parameters())+list(model_LU.parameters()), lr=0.001, momentum=0.9)\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=20, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "----------\n",
      "train Loss: 0.0868\n",
      "train MAE: 4330.9425\n",
      "val Loss: 0.0525\n",
      "val MAE: 3390.0677\n",
      "\n",
      "Epoch 2/100\n",
      "----------\n",
      "train Loss: 0.0599\n",
      "train MAE: 3681.5374\n",
      "val Loss: 0.0506\n",
      "val MAE: 3322.0110\n",
      "\n",
      "Epoch 3/100\n",
      "----------\n",
      "train Loss: 0.0543\n",
      "train MAE: 3501.1198\n",
      "val Loss: 0.0422\n",
      "val MAE: 3008.1626\n",
      "\n",
      "Epoch 4/100\n",
      "----------\n",
      "train Loss: 0.0495\n",
      "train MAE: 3325.8292\n",
      "val Loss: 0.0434\n",
      "val MAE: 3025.7609\n",
      "\n",
      "Epoch 5/100\n",
      "----------\n",
      "train Loss: 0.0479\n",
      "train MAE: 3276.5011\n",
      "val Loss: 0.0417\n",
      "val MAE: 2998.6961\n",
      "\n",
      "Epoch 6/100\n",
      "----------\n",
      "train Loss: 0.0449\n",
      "train MAE: 3159.5737\n",
      "val Loss: 0.0423\n",
      "val MAE: 3035.4299\n",
      "\n",
      "Epoch 7/100\n",
      "----------\n",
      "train Loss: 0.0443\n",
      "train MAE: 3155.7754\n",
      "val Loss: 0.0392\n",
      "val MAE: 2887.9100\n",
      "\n",
      "Epoch 8/100\n",
      "----------\n",
      "train Loss: 0.0430\n",
      "train MAE: 3087.6443\n",
      "val Loss: 0.0364\n",
      "val MAE: 2769.4753\n",
      "\n",
      "Epoch 9/100\n",
      "----------\n",
      "train Loss: 0.0423\n",
      "train MAE: 3059.4740\n",
      "val Loss: 0.0353\n",
      "val MAE: 2729.5608\n",
      "\n",
      "Epoch 10/100\n",
      "----------\n",
      "train Loss: 0.0393\n",
      "train MAE: 2932.4462\n",
      "val Loss: 0.0476\n",
      "val MAE: 3144.5031\n",
      "\n",
      "Epoch 11/100\n",
      "----------\n",
      "train Loss: 0.0390\n",
      "train MAE: 2950.7685\n",
      "val Loss: 0.0354\n",
      "val MAE: 2731.6841\n",
      "\n",
      "Epoch 12/100\n",
      "----------\n",
      "train Loss: 0.0385\n",
      "train MAE: 2929.8033\n",
      "val Loss: 0.0348\n",
      "val MAE: 2694.9279\n",
      "\n",
      "Epoch 13/100\n",
      "----------\n",
      "train Loss: 0.0381\n",
      "train MAE: 2907.2628\n",
      "val Loss: 0.0341\n",
      "val MAE: 2665.4530\n",
      "\n",
      "Epoch 14/100\n",
      "----------\n",
      "train Loss: 0.0375\n",
      "train MAE: 2840.2331\n",
      "val Loss: 0.0358\n",
      "val MAE: 2721.8727\n",
      "\n",
      "Epoch 15/100\n",
      "----------\n",
      "train Loss: 0.0357\n",
      "train MAE: 2789.5872\n",
      "val Loss: 0.0347\n",
      "val MAE: 2682.8504\n",
      "\n",
      "Epoch 16/100\n",
      "----------\n",
      "train Loss: 0.0361\n",
      "train MAE: 2795.6579\n",
      "val Loss: 0.0360\n",
      "val MAE: 2747.7485\n",
      "\n",
      "Epoch 17/100\n",
      "----------\n",
      "train Loss: 0.0358\n",
      "train MAE: 2822.9592\n",
      "val Loss: 0.0392\n",
      "val MAE: 2846.1452\n",
      "\n",
      "Epoch 18/100\n",
      "----------\n",
      "train Loss: 0.0367\n",
      "train MAE: 2851.1078\n",
      "val Loss: 0.0340\n",
      "val MAE: 2658.4579\n",
      "\n",
      "Epoch 19/100\n",
      "----------\n",
      "train Loss: 0.0352\n",
      "train MAE: 2798.0162\n",
      "val Loss: 0.0337\n",
      "val MAE: 2666.5532\n",
      "\n",
      "Epoch 20/100\n",
      "----------\n",
      "train Loss: 0.0356\n",
      "train MAE: 2820.1313\n",
      "val Loss: 0.0340\n",
      "val MAE: 2695.2273\n",
      "\n",
      "Epoch 21/100\n",
      "----------\n",
      "train Loss: 0.0315\n",
      "train MAE: 2632.5912\n",
      "val Loss: 0.0337\n",
      "val MAE: 2630.6160\n",
      "\n",
      "Epoch 22/100\n",
      "----------\n",
      "train Loss: 0.0316\n",
      "train MAE: 2647.0226\n",
      "val Loss: 0.0330\n",
      "val MAE: 2605.4832\n",
      "\n",
      "Epoch 23/100\n",
      "----------\n",
      "train Loss: 0.0319\n",
      "train MAE: 2650.7001\n",
      "val Loss: 0.0346\n",
      "val MAE: 2674.6899\n",
      "\n",
      "Epoch 24/100\n",
      "----------\n",
      "train Loss: 0.0304\n",
      "train MAE: 2568.8334\n",
      "val Loss: 0.0330\n",
      "val MAE: 2602.3482\n",
      "\n",
      "Epoch 25/100\n",
      "----------\n",
      "train Loss: 0.0306\n",
      "train MAE: 2584.7894\n",
      "val Loss: 0.0328\n",
      "val MAE: 2586.3524\n",
      "\n",
      "Epoch 26/100\n",
      "----------\n",
      "train Loss: 0.0303\n",
      "train MAE: 2554.7909\n",
      "val Loss: 0.0347\n",
      "val MAE: 2682.4458\n",
      "\n",
      "Epoch 27/100\n",
      "----------\n",
      "train Loss: 0.0307\n",
      "train MAE: 2609.4366\n",
      "val Loss: 0.0328\n",
      "val MAE: 2597.0298\n",
      "\n",
      "Epoch 28/100\n",
      "----------\n",
      "train Loss: 0.0296\n",
      "train MAE: 2546.5183\n",
      "val Loss: 0.0329\n",
      "val MAE: 2600.9316\n",
      "\n",
      "Epoch 29/100\n",
      "----------\n",
      "train Loss: 0.0302\n",
      "train MAE: 2587.6939\n",
      "val Loss: 0.0330\n",
      "val MAE: 2600.0408\n",
      "\n",
      "Epoch 30/100\n",
      "----------\n",
      "train Loss: 0.0305\n",
      "train MAE: 2572.8964\n",
      "val Loss: 0.0329\n",
      "val MAE: 2604.1747\n",
      "\n",
      "Epoch 31/100\n",
      "----------\n",
      "train Loss: 0.0301\n",
      "train MAE: 2559.5140\n",
      "val Loss: 0.0331\n",
      "val MAE: 2610.7590\n",
      "\n",
      "Epoch 32/100\n",
      "----------\n",
      "train Loss: 0.0306\n",
      "train MAE: 2588.6908\n",
      "val Loss: 0.0328\n",
      "val MAE: 2595.5516\n",
      "\n",
      "Epoch 33/100\n",
      "----------\n",
      "train Loss: 0.0303\n",
      "train MAE: 2581.5497\n",
      "val Loss: 0.0334\n",
      "val MAE: 2618.8077\n",
      "\n",
      "Epoch 34/100\n",
      "----------\n",
      "train Loss: 0.0301\n",
      "train MAE: 2587.2928\n",
      "val Loss: 0.0331\n",
      "val MAE: 2607.7784\n",
      "\n",
      "Epoch 35/100\n",
      "----------\n",
      "train Loss: 0.0305\n",
      "train MAE: 2573.0867\n",
      "val Loss: 0.0329\n",
      "val MAE: 2608.7439\n",
      "\n",
      "Epoch 36/100\n",
      "----------\n",
      "train Loss: 0.0316\n",
      "train MAE: 2637.3990\n",
      "val Loss: 0.0332\n",
      "val MAE: 2608.2568\n",
      "\n",
      "Epoch 37/100\n",
      "----------\n",
      "train Loss: 0.0312\n",
      "train MAE: 2649.5348\n",
      "val Loss: 0.0336\n",
      "val MAE: 2625.8455\n",
      "\n",
      "Epoch 38/100\n",
      "----------\n",
      "train Loss: 0.0299\n",
      "train MAE: 2538.4705\n",
      "val Loss: 0.0326\n",
      "val MAE: 2585.9488\n",
      "\n",
      "Epoch 39/100\n",
      "----------\n",
      "train Loss: 0.0306\n",
      "train MAE: 2580.7495\n",
      "val Loss: 0.0328\n",
      "val MAE: 2595.4620\n",
      "\n",
      "Epoch 40/100\n",
      "----------\n",
      "train Loss: 0.0292\n",
      "train MAE: 2515.9136\n",
      "val Loss: 0.0327\n",
      "val MAE: 2589.9487\n",
      "\n",
      "Epoch 41/100\n",
      "----------\n",
      "train Loss: 0.0297\n",
      "train MAE: 2528.9162\n",
      "val Loss: 0.0329\n",
      "val MAE: 2592.8321\n",
      "\n",
      "Epoch 42/100\n",
      "----------\n",
      "train Loss: 0.0299\n",
      "train MAE: 2535.5363\n",
      "val Loss: 0.0327\n",
      "val MAE: 2586.2156\n",
      "\n",
      "Epoch 43/100\n",
      "----------\n",
      "train Loss: 0.0299\n",
      "train MAE: 2567.8290\n",
      "val Loss: 0.0341\n",
      "val MAE: 2646.2940\n",
      "\n",
      "Epoch 44/100\n",
      "----------\n",
      "train Loss: 0.0293\n",
      "train MAE: 2524.4639\n",
      "val Loss: 0.0330\n",
      "val MAE: 2593.2674\n",
      "\n",
      "Epoch 45/100\n",
      "----------\n",
      "train Loss: 0.0285\n",
      "train MAE: 2490.6263\n",
      "val Loss: 0.0330\n",
      "val MAE: 2595.1981\n",
      "\n",
      "Epoch 46/100\n",
      "----------\n",
      "train Loss: 0.0304\n",
      "train MAE: 2576.1772\n",
      "val Loss: 0.0336\n",
      "val MAE: 2627.0061\n",
      "\n",
      "Epoch 47/100\n",
      "----------\n",
      "train Loss: 0.0286\n",
      "train MAE: 2511.3741\n",
      "val Loss: 0.0330\n",
      "val MAE: 2605.1567\n",
      "\n",
      "Epoch 48/100\n",
      "----------\n",
      "train Loss: 0.0290\n",
      "train MAE: 2523.8944\n",
      "val Loss: 0.0333\n",
      "val MAE: 2611.8685\n",
      "\n",
      "Epoch 49/100\n",
      "----------\n",
      "train Loss: 0.0297\n",
      "train MAE: 2558.1559\n",
      "val Loss: 0.0328\n",
      "val MAE: 2592.0487\n",
      "\n",
      "Epoch 50/100\n",
      "----------\n",
      "train Loss: 0.0297\n",
      "train MAE: 2533.3085\n",
      "val Loss: 0.0340\n",
      "val MAE: 2646.8738\n",
      "\n",
      "Epoch 51/100\n",
      "----------\n",
      "train Loss: 0.0294\n",
      "train MAE: 2556.4826\n",
      "val Loss: 0.0329\n",
      "val MAE: 2599.7477\n",
      "\n",
      "Epoch 52/100\n",
      "----------\n",
      "train Loss: 0.0281\n",
      "train MAE: 2480.5270\n",
      "val Loss: 0.0329\n",
      "val MAE: 2594.6009\n",
      "\n",
      "Epoch 53/100\n",
      "----------\n",
      "train Loss: 0.0303\n",
      "train MAE: 2585.5988\n",
      "val Loss: 0.0332\n",
      "val MAE: 2604.7024\n",
      "\n",
      "Epoch 54/100\n",
      "----------\n",
      "train Loss: 0.0302\n",
      "train MAE: 2556.2544\n",
      "val Loss: 0.0334\n",
      "val MAE: 2621.6908\n",
      "\n",
      "Epoch 55/100\n",
      "----------\n",
      "train Loss: 0.0293\n",
      "train MAE: 2528.2264\n",
      "val Loss: 0.0333\n",
      "val MAE: 2615.8067\n",
      "\n",
      "Epoch 56/100\n",
      "----------\n",
      "train Loss: 0.0290\n",
      "train MAE: 2509.1048\n",
      "val Loss: 0.0330\n",
      "val MAE: 2601.3324\n",
      "\n",
      "Epoch 57/100\n",
      "----------\n",
      "train Loss: 0.0296\n",
      "train MAE: 2535.9121\n",
      "val Loss: 0.0328\n",
      "val MAE: 2594.6589\n",
      "\n",
      "Epoch 58/100\n",
      "----------\n",
      "train Loss: 0.0301\n",
      "train MAE: 2585.6696\n",
      "val Loss: 0.0330\n",
      "val MAE: 2599.7952\n",
      "\n",
      "Epoch 59/100\n",
      "----------\n",
      "train Loss: 0.0305\n",
      "train MAE: 2569.1350\n",
      "val Loss: 0.0329\n",
      "val MAE: 2602.6069\n",
      "\n",
      "Epoch 60/100\n",
      "----------\n",
      "train Loss: 0.0301\n",
      "train MAE: 2573.0142\n",
      "val Loss: 0.0330\n",
      "val MAE: 2598.2142\n",
      "\n",
      "Epoch 61/100\n",
      "----------\n",
      "train Loss: 0.0301\n",
      "train MAE: 2587.4162\n",
      "val Loss: 0.0329\n",
      "val MAE: 2597.9883\n",
      "\n",
      "Epoch 62/100\n",
      "----------\n",
      "train Loss: 0.0299\n",
      "train MAE: 2556.8434\n",
      "val Loss: 0.0332\n",
      "val MAE: 2608.2587\n",
      "\n",
      "Epoch 63/100\n",
      "----------\n",
      "train Loss: 0.0301\n",
      "train MAE: 2551.0230\n",
      "val Loss: 0.0330\n",
      "val MAE: 2601.3826\n",
      "\n",
      "Epoch 64/100\n",
      "----------\n",
      "train Loss: 0.0298\n",
      "train MAE: 2571.8313\n",
      "val Loss: 0.0329\n",
      "val MAE: 2596.9376\n",
      "\n",
      "Epoch 65/100\n",
      "----------\n",
      "train Loss: 0.0299\n",
      "train MAE: 2527.6233\n",
      "val Loss: 0.0328\n",
      "val MAE: 2594.0319\n",
      "\n",
      "Epoch 66/100\n",
      "----------\n",
      "train Loss: 0.0304\n",
      "train MAE: 2580.2057\n",
      "val Loss: 0.0339\n",
      "val MAE: 2639.3300\n",
      "\n",
      "Epoch 67/100\n",
      "----------\n",
      "train Loss: 0.0289\n",
      "train MAE: 2532.1036\n",
      "val Loss: 0.0328\n",
      "val MAE: 2598.1435\n",
      "\n",
      "Epoch 68/100\n",
      "----------\n",
      "train Loss: 0.0290\n",
      "train MAE: 2510.2792\n",
      "val Loss: 0.0329\n",
      "val MAE: 2595.6300\n",
      "\n",
      "Epoch 69/100\n",
      "----------\n",
      "train Loss: 0.0296\n",
      "train MAE: 2576.7430\n",
      "val Loss: 0.0329\n",
      "val MAE: 2592.9787\n",
      "\n",
      "Epoch 70/100\n",
      "----------\n",
      "train Loss: 0.0293\n",
      "train MAE: 2510.4913\n",
      "val Loss: 0.0329\n",
      "val MAE: 2601.7088\n",
      "\n",
      "Epoch 71/100\n",
      "----------\n",
      "train Loss: 0.0298\n",
      "train MAE: 2556.0478\n",
      "val Loss: 0.0329\n",
      "val MAE: 2594.7240\n",
      "\n",
      "Epoch 72/100\n",
      "----------\n",
      "train Loss: 0.0301\n",
      "train MAE: 2546.8534\n",
      "val Loss: 0.0332\n",
      "val MAE: 2608.2851\n",
      "\n",
      "Epoch 73/100\n",
      "----------\n",
      "train Loss: 0.0296\n",
      "train MAE: 2536.5326\n",
      "val Loss: 0.0327\n",
      "val MAE: 2585.7089\n",
      "\n",
      "Epoch 74/100\n",
      "----------\n",
      "train Loss: 0.0303\n",
      "train MAE: 2576.7298\n",
      "val Loss: 0.0328\n",
      "val MAE: 2593.5141\n",
      "\n",
      "Epoch 75/100\n",
      "----------\n",
      "train Loss: 0.0295\n",
      "train MAE: 2536.9074\n",
      "val Loss: 0.0331\n",
      "val MAE: 2611.5296\n",
      "\n",
      "Epoch 76/100\n",
      "----------\n",
      "train Loss: 0.0300\n",
      "train MAE: 2575.8005\n",
      "val Loss: 0.0329\n",
      "val MAE: 2596.2536\n",
      "\n",
      "Epoch 77/100\n",
      "----------\n",
      "train Loss: 0.0300\n",
      "train MAE: 2546.3634\n",
      "val Loss: 0.0332\n",
      "val MAE: 2609.6216\n",
      "\n",
      "Epoch 78/100\n",
      "----------\n",
      "train Loss: 0.0293\n",
      "train MAE: 2519.1015\n",
      "val Loss: 0.0330\n",
      "val MAE: 2606.9286\n",
      "\n",
      "Epoch 79/100\n",
      "----------\n",
      "train Loss: 0.0295\n",
      "train MAE: 2564.0052\n",
      "val Loss: 0.0328\n",
      "val MAE: 2593.1802\n",
      "\n",
      "Epoch 80/100\n",
      "----------\n",
      "train Loss: 0.0302\n",
      "train MAE: 2562.1648\n",
      "val Loss: 0.0330\n",
      "val MAE: 2607.8441\n",
      "\n",
      "Epoch 81/100\n",
      "----------\n",
      "train Loss: 0.0291\n",
      "train MAE: 2521.4491\n",
      "val Loss: 0.0328\n",
      "val MAE: 2598.6263\n",
      "\n",
      "Epoch 82/100\n",
      "----------\n",
      "train Loss: 0.0294\n",
      "train MAE: 2568.5751\n",
      "val Loss: 0.0330\n",
      "val MAE: 2604.1649\n",
      "\n",
      "Epoch 83/100\n",
      "----------\n",
      "train Loss: 0.0295\n",
      "train MAE: 2523.9073\n",
      "val Loss: 0.0327\n",
      "val MAE: 2585.5026\n",
      "\n",
      "Epoch 84/100\n",
      "----------\n",
      "train Loss: 0.0301\n",
      "train MAE: 2547.8149\n",
      "val Loss: 0.0330\n",
      "val MAE: 2602.1669\n",
      "\n",
      "Epoch 85/100\n",
      "----------\n",
      "train Loss: 0.0292\n",
      "train MAE: 2531.8257\n",
      "val Loss: 0.0331\n",
      "val MAE: 2606.0806\n",
      "\n",
      "Epoch 86/100\n",
      "----------\n",
      "train Loss: 0.0285\n",
      "train MAE: 2477.9649\n",
      "val Loss: 0.0330\n",
      "val MAE: 2598.6852\n",
      "\n",
      "Epoch 87/100\n",
      "----------\n",
      "train Loss: 0.0295\n",
      "train MAE: 2541.6815\n",
      "val Loss: 0.0330\n",
      "val MAE: 2604.7939\n",
      "\n",
      "Epoch 88/100\n",
      "----------\n",
      "train Loss: 0.0299\n",
      "train MAE: 2540.3585\n",
      "val Loss: 0.0346\n",
      "val MAE: 2675.9605\n",
      "\n",
      "Epoch 89/100\n",
      "----------\n",
      "train Loss: 0.0289\n",
      "train MAE: 2506.0995\n",
      "val Loss: 0.0331\n",
      "val MAE: 2600.5133\n",
      "\n",
      "Epoch 90/100\n",
      "----------\n",
      "train Loss: 0.0299\n",
      "train MAE: 2550.3905\n",
      "val Loss: 0.0328\n",
      "val MAE: 2597.2422\n",
      "\n",
      "Epoch 91/100\n",
      "----------\n",
      "train Loss: 0.0298\n",
      "train MAE: 2575.8935\n",
      "val Loss: 0.0328\n",
      "val MAE: 2587.4239\n",
      "\n",
      "Epoch 92/100\n",
      "----------\n",
      "train Loss: 0.0282\n",
      "train MAE: 2486.2431\n",
      "val Loss: 0.0335\n",
      "val MAE: 2624.8236\n",
      "\n",
      "Epoch 93/100\n",
      "----------\n",
      "train Loss: 0.0300\n",
      "train MAE: 2545.8381\n",
      "val Loss: 0.0327\n",
      "val MAE: 2590.0195\n",
      "\n",
      "Epoch 94/100\n",
      "----------\n",
      "train Loss: 0.0301\n",
      "train MAE: 2558.6974\n",
      "val Loss: 0.0331\n",
      "val MAE: 2609.2764\n",
      "\n",
      "Epoch 95/100\n",
      "----------\n",
      "train Loss: 0.0288\n",
      "train MAE: 2489.2591\n",
      "val Loss: 0.0328\n",
      "val MAE: 2598.2193\n",
      "\n",
      "Epoch 96/100\n",
      "----------\n",
      "train Loss: 0.0301\n",
      "train MAE: 2561.9377\n",
      "val Loss: 0.0337\n",
      "val MAE: 2628.2193\n",
      "\n",
      "Epoch 97/100\n",
      "----------\n",
      "train Loss: 0.0299\n",
      "train MAE: 2547.5520\n",
      "val Loss: 0.0327\n",
      "val MAE: 2590.1668\n",
      "\n",
      "Epoch 98/100\n",
      "----------\n",
      "train Loss: 0.0294\n",
      "train MAE: 2536.7713\n",
      "val Loss: 0.0334\n",
      "val MAE: 2621.6049\n",
      "\n",
      "Epoch 99/100\n",
      "----------\n",
      "train Loss: 0.0292\n",
      "train MAE: 2510.1603\n",
      "val Loss: 0.0338\n",
      "val MAE: 2633.4003\n",
      "\n",
      "Epoch 100/100\n",
      "----------\n",
      "train Loss: 0.0291\n",
      "train MAE: 2508.3921\n",
      "val Loss: 0.0327\n",
      "val MAE: 2591.4782\n",
      "\n",
      "Training complete in 127m 33s\n",
      "Best val Loss: 0.032585 at epoch 38\n",
      "Best val MAE: 2585.948771 at epoch 38\n",
      "\n",
      "Load the model weights at the best epoch\n"
     ]
    }
   ],
   "source": [
    "model_res152, mae_list_3 = train_model(model_ft, model_LU, criterion, optimizer_ft, exp_lr_scheduler, num_epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (2053, 256, 1) + CB3+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "### ResNet18\n",
    "model_ft = models.resnet152(pretrained=True)\n",
    "num_ftrs = model_ft.fc.in_features\n",
    "model_ft.fc = nn.Identity()\n",
    "\n",
    "### Freeze and Fine Tuning\n",
    "for param in model_ft.parameters():\n",
    "    param.requires_grad = False\n",
    "for param in model_ft.layer3.parameters():\n",
    "    param.requires_grad = True\n",
    "for param in model_ft.layer4.parameters():\n",
    "    param.requires_grad = True\n",
    "assert [param.requires_grad for param in model_ft.parameters()][-1]\n",
    "\n",
    "### LU\n",
    "model_LU = nn.Sequential(\n",
    "    nn.Linear(num_ftrs + 5, 256),\n",
    "    nn.Tanh(), \n",
    "    nn.Linear(256, 1)\n",
    ")\n",
    "\n",
    "### model setup\n",
    "model_ft = model_ft.to(device)\n",
    "model_LU = model_LU.to(device)\n",
    "criterion = nn.MSELoss()\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.SGD(list(model_ft.parameters())+list(model_LU.parameters()), lr=0.001, momentum=0.9)\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=20, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "----------\n",
      "train Loss: 0.0857\n",
      "train MAE: 4303.8513\n",
      "val Loss: 0.0544\n",
      "val MAE: 3464.2085\n",
      "\n",
      "Epoch 2/100\n",
      "----------\n",
      "train Loss: 0.0597\n",
      "train MAE: 3653.8600\n",
      "val Loss: 0.0499\n",
      "val MAE: 3228.5116\n",
      "\n",
      "Epoch 3/100\n",
      "----------\n",
      "train Loss: 0.0543\n",
      "train MAE: 3466.7035\n",
      "val Loss: 0.0412\n",
      "val MAE: 2954.0585\n",
      "\n",
      "Epoch 4/100\n",
      "----------\n",
      "train Loss: 0.0496\n",
      "train MAE: 3364.3578\n",
      "val Loss: 0.0404\n",
      "val MAE: 2936.5862\n",
      "\n",
      "Epoch 5/100\n",
      "----------\n",
      "train Loss: 0.0470\n",
      "train MAE: 3254.8241\n",
      "val Loss: 0.0377\n",
      "val MAE: 2817.6215\n",
      "\n",
      "Epoch 6/100\n",
      "----------\n",
      "train Loss: 0.0442\n",
      "train MAE: 3152.6217\n",
      "val Loss: 0.0402\n",
      "val MAE: 2903.2326\n",
      "\n",
      "Epoch 7/100\n",
      "----------\n",
      "train Loss: 0.0457\n",
      "train MAE: 3203.7513\n",
      "val Loss: 0.0454\n",
      "val MAE: 3115.4586\n",
      "\n",
      "Epoch 8/100\n",
      "----------\n",
      "train Loss: 0.0424\n",
      "train MAE: 3059.0936\n",
      "val Loss: 0.0355\n",
      "val MAE: 2740.7619\n",
      "\n",
      "Epoch 9/100\n",
      "----------\n",
      "train Loss: 0.0437\n",
      "train MAE: 3108.1404\n",
      "val Loss: 0.0372\n",
      "val MAE: 2800.2737\n",
      "\n",
      "Epoch 10/100\n",
      "----------\n",
      "train Loss: 0.0415\n",
      "train MAE: 3035.0524\n",
      "val Loss: 0.0356\n",
      "val MAE: 2754.1853\n",
      "\n",
      "Epoch 11/100\n",
      "----------\n",
      "train Loss: 0.0403\n",
      "train MAE: 2973.8383\n",
      "val Loss: 0.0418\n",
      "val MAE: 2944.1053\n",
      "\n",
      "Epoch 12/100\n",
      "----------\n",
      "train Loss: 0.0391\n",
      "train MAE: 2934.5664\n",
      "val Loss: 0.0346\n",
      "val MAE: 2681.2214\n",
      "\n",
      "Epoch 13/100\n",
      "----------\n",
      "train Loss: 0.0368\n",
      "train MAE: 2903.6860\n",
      "val Loss: 0.0414\n",
      "val MAE: 2952.0429\n",
      "\n",
      "Epoch 14/100\n",
      "----------\n",
      "train Loss: 0.0369\n",
      "train MAE: 2858.1871\n",
      "val Loss: 0.0341\n",
      "val MAE: 2661.0256\n",
      "\n",
      "Epoch 15/100\n",
      "----------\n",
      "train Loss: 0.0371\n",
      "train MAE: 2860.9560\n",
      "val Loss: 0.0348\n",
      "val MAE: 2723.8391\n",
      "\n",
      "Epoch 16/100\n",
      "----------\n",
      "train Loss: 0.0355\n",
      "train MAE: 2794.5818\n",
      "val Loss: 0.0419\n",
      "val MAE: 2970.3823\n",
      "\n",
      "Epoch 17/100\n",
      "----------\n",
      "train Loss: 0.0366\n",
      "train MAE: 2866.1224\n",
      "val Loss: 0.0378\n",
      "val MAE: 2801.2417\n",
      "\n",
      "Epoch 18/100\n",
      "----------\n",
      "train Loss: 0.0354\n",
      "train MAE: 2793.5538\n",
      "val Loss: 0.0339\n",
      "val MAE: 2659.5821\n",
      "\n",
      "Epoch 19/100\n",
      "----------\n",
      "train Loss: 0.0342\n",
      "train MAE: 2767.6075\n",
      "val Loss: 0.0349\n",
      "val MAE: 2687.4158\n",
      "\n",
      "Epoch 20/100\n",
      "----------\n",
      "train Loss: 0.0348\n",
      "train MAE: 2770.5017\n",
      "val Loss: 0.0329\n",
      "val MAE: 2612.1168\n",
      "\n",
      "Epoch 21/100\n",
      "----------\n",
      "train Loss: 0.0308\n",
      "train MAE: 2624.2099\n",
      "val Loss: 0.0341\n",
      "val MAE: 2652.5500\n",
      "\n",
      "Epoch 22/100\n",
      "----------\n",
      "train Loss: 0.0308\n",
      "train MAE: 2617.8120\n",
      "val Loss: 0.0346\n",
      "val MAE: 2682.3712\n",
      "\n",
      "Epoch 23/100\n",
      "----------\n",
      "train Loss: 0.0319\n",
      "train MAE: 2646.5600\n",
      "val Loss: 0.0334\n",
      "val MAE: 2622.5870\n",
      "\n",
      "Epoch 24/100\n",
      "----------\n",
      "train Loss: 0.0321\n",
      "train MAE: 2667.9758\n",
      "val Loss: 0.0337\n",
      "val MAE: 2635.7580\n",
      "\n",
      "Epoch 25/100\n",
      "----------\n",
      "train Loss: 0.0318\n",
      "train MAE: 2646.6766\n",
      "val Loss: 0.0331\n",
      "val MAE: 2611.8547\n",
      "\n",
      "Epoch 26/100\n",
      "----------\n",
      "train Loss: 0.0306\n",
      "train MAE: 2587.3805\n",
      "val Loss: 0.0330\n",
      "val MAE: 2602.6877\n",
      "\n",
      "Epoch 27/100\n",
      "----------\n",
      "train Loss: 0.0306\n",
      "train MAE: 2617.4773\n",
      "val Loss: 0.0331\n",
      "val MAE: 2603.6194\n",
      "\n",
      "Epoch 28/100\n",
      "----------\n",
      "train Loss: 0.0317\n",
      "train MAE: 2651.7563\n",
      "val Loss: 0.0333\n",
      "val MAE: 2607.7622\n",
      "\n",
      "Epoch 29/100\n",
      "----------\n",
      "train Loss: 0.0314\n",
      "train MAE: 2635.1203\n",
      "val Loss: 0.0331\n",
      "val MAE: 2612.8909\n",
      "\n",
      "Epoch 30/100\n",
      "----------\n",
      "train Loss: 0.0306\n",
      "train MAE: 2605.9357\n",
      "val Loss: 0.0339\n",
      "val MAE: 2634.9441\n",
      "\n",
      "Epoch 31/100\n",
      "----------\n",
      "train Loss: 0.0305\n",
      "train MAE: 2597.4769\n",
      "val Loss: 0.0332\n",
      "val MAE: 2601.9023\n",
      "\n",
      "Epoch 32/100\n",
      "----------\n",
      "train Loss: 0.0316\n",
      "train MAE: 2668.7416\n",
      "val Loss: 0.0333\n",
      "val MAE: 2618.8237\n",
      "\n",
      "Epoch 33/100\n",
      "----------\n",
      "train Loss: 0.0303\n",
      "train MAE: 2568.0696\n",
      "val Loss: 0.0332\n",
      "val MAE: 2607.1580\n",
      "\n",
      "Epoch 34/100\n",
      "----------\n",
      "train Loss: 0.0308\n",
      "train MAE: 2588.6179\n",
      "val Loss: 0.0337\n",
      "val MAE: 2634.4287\n",
      "\n",
      "Epoch 35/100\n",
      "----------\n",
      "train Loss: 0.0310\n",
      "train MAE: 2601.4555\n",
      "val Loss: 0.0334\n",
      "val MAE: 2615.0270\n",
      "\n",
      "Epoch 36/100\n",
      "----------\n",
      "train Loss: 0.0317\n",
      "train MAE: 2665.0449\n",
      "val Loss: 0.0334\n",
      "val MAE: 2616.6075\n",
      "\n",
      "Epoch 37/100\n",
      "----------\n",
      "train Loss: 0.0306\n",
      "train MAE: 2609.2373\n",
      "val Loss: 0.0342\n",
      "val MAE: 2656.8018\n",
      "\n",
      "Epoch 38/100\n",
      "----------\n",
      "train Loss: 0.0304\n",
      "train MAE: 2592.6084\n",
      "val Loss: 0.0333\n",
      "val MAE: 2605.0064\n",
      "\n",
      "Epoch 39/100\n",
      "----------\n",
      "train Loss: 0.0300\n",
      "train MAE: 2556.0192\n",
      "val Loss: 0.0339\n",
      "val MAE: 2634.4515\n",
      "\n",
      "Epoch 40/100\n",
      "----------\n",
      "train Loss: 0.0298\n",
      "train MAE: 2568.3906\n",
      "val Loss: 0.0332\n",
      "val MAE: 2604.9380\n",
      "\n",
      "Epoch 41/100\n",
      "----------\n",
      "train Loss: 0.0304\n",
      "train MAE: 2615.0984\n",
      "val Loss: 0.0335\n",
      "val MAE: 2614.1075\n",
      "\n",
      "Epoch 42/100\n",
      "----------\n",
      "train Loss: 0.0300\n",
      "train MAE: 2589.0182\n",
      "val Loss: 0.0332\n",
      "val MAE: 2601.5464\n",
      "\n",
      "Epoch 43/100\n",
      "----------\n",
      "train Loss: 0.0305\n",
      "train MAE: 2577.3726\n",
      "val Loss: 0.0333\n",
      "val MAE: 2606.7781\n",
      "\n",
      "Epoch 44/100\n",
      "----------\n",
      "train Loss: 0.0299\n",
      "train MAE: 2606.9080\n",
      "val Loss: 0.0334\n",
      "val MAE: 2612.6833\n",
      "\n",
      "Epoch 45/100\n",
      "----------\n",
      "train Loss: 0.0290\n",
      "train MAE: 2532.0866\n",
      "val Loss: 0.0334\n",
      "val MAE: 2612.6321\n",
      "\n",
      "Epoch 46/100\n",
      "----------\n",
      "train Loss: 0.0290\n",
      "train MAE: 2522.4395\n",
      "val Loss: 0.0340\n",
      "val MAE: 2641.1152\n",
      "\n",
      "Epoch 47/100\n",
      "----------\n",
      "train Loss: 0.0304\n",
      "train MAE: 2578.6166\n",
      "val Loss: 0.0338\n",
      "val MAE: 2627.7620\n",
      "\n",
      "Epoch 48/100\n",
      "----------\n",
      "train Loss: 0.0296\n",
      "train MAE: 2549.0074\n",
      "val Loss: 0.0332\n",
      "val MAE: 2607.5098\n",
      "\n",
      "Epoch 49/100\n",
      "----------\n",
      "train Loss: 0.0299\n",
      "train MAE: 2571.3844\n",
      "val Loss: 0.0333\n",
      "val MAE: 2615.0175\n",
      "\n",
      "Epoch 50/100\n",
      "----------\n",
      "train Loss: 0.0303\n",
      "train MAE: 2593.8111\n",
      "val Loss: 0.0334\n",
      "val MAE: 2614.2380\n",
      "\n",
      "Epoch 51/100\n",
      "----------\n",
      "train Loss: 0.0298\n",
      "train MAE: 2581.9160\n",
      "val Loss: 0.0337\n",
      "val MAE: 2624.3949\n",
      "\n",
      "Epoch 52/100\n",
      "----------\n",
      "train Loss: 0.0304\n",
      "train MAE: 2586.3109\n",
      "val Loss: 0.0341\n",
      "val MAE: 2645.6484\n",
      "\n",
      "Epoch 53/100\n",
      "----------\n",
      "train Loss: 0.0293\n",
      "train MAE: 2544.0854\n",
      "val Loss: 0.0332\n",
      "val MAE: 2600.4045\n",
      "\n",
      "Epoch 54/100\n",
      "----------\n",
      "train Loss: 0.0299\n",
      "train MAE: 2559.6015\n",
      "val Loss: 0.0333\n",
      "val MAE: 2607.0297\n",
      "\n",
      "Epoch 55/100\n",
      "----------\n",
      "train Loss: 0.0297\n",
      "train MAE: 2553.4449\n",
      "val Loss: 0.0334\n",
      "val MAE: 2610.3380\n",
      "\n",
      "Epoch 56/100\n",
      "----------\n",
      "train Loss: 0.0309\n",
      "train MAE: 2589.6032\n",
      "val Loss: 0.0333\n",
      "val MAE: 2613.8799\n",
      "\n",
      "Epoch 57/100\n",
      "----------\n",
      "train Loss: 0.0308\n",
      "train MAE: 2609.6264\n",
      "val Loss: 0.0333\n",
      "val MAE: 2609.3863\n",
      "\n",
      "Epoch 58/100\n",
      "----------\n",
      "train Loss: 0.0299\n",
      "train MAE: 2534.5805\n",
      "val Loss: 0.0333\n",
      "val MAE: 2613.9914\n",
      "\n",
      "Epoch 59/100\n",
      "----------\n",
      "train Loss: 0.0289\n",
      "train MAE: 2539.0387\n",
      "val Loss: 0.0332\n",
      "val MAE: 2615.8181\n",
      "\n",
      "Epoch 60/100\n",
      "----------\n",
      "train Loss: 0.0295\n",
      "train MAE: 2541.0067\n",
      "val Loss: 0.0335\n",
      "val MAE: 2616.4487\n",
      "\n",
      "Epoch 61/100\n",
      "----------\n",
      "train Loss: 0.0305\n",
      "train MAE: 2592.1327\n",
      "val Loss: 0.0334\n",
      "val MAE: 2613.1373\n",
      "\n",
      "Epoch 62/100\n",
      "----------\n",
      "train Loss: 0.0307\n",
      "train MAE: 2614.4233\n",
      "val Loss: 0.0341\n",
      "val MAE: 2650.1918\n",
      "\n",
      "Epoch 63/100\n",
      "----------\n",
      "train Loss: 0.0296\n",
      "train MAE: 2551.4833\n",
      "val Loss: 0.0337\n",
      "val MAE: 2626.6181\n",
      "\n",
      "Epoch 64/100\n",
      "----------\n",
      "train Loss: 0.0298\n",
      "train MAE: 2541.8458\n",
      "val Loss: 0.0336\n",
      "val MAE: 2616.1382\n",
      "\n",
      "Epoch 65/100\n",
      "----------\n",
      "train Loss: 0.0300\n",
      "train MAE: 2571.8696\n",
      "val Loss: 0.0334\n",
      "val MAE: 2611.0828\n",
      "\n",
      "Epoch 66/100\n",
      "----------\n",
      "train Loss: 0.0298\n",
      "train MAE: 2562.2315\n",
      "val Loss: 0.0344\n",
      "val MAE: 2662.1768\n",
      "\n",
      "Epoch 67/100\n",
      "----------\n",
      "train Loss: 0.0291\n",
      "train MAE: 2516.2973\n",
      "val Loss: 0.0347\n",
      "val MAE: 2673.3993\n",
      "\n",
      "Epoch 68/100\n",
      "----------\n",
      "train Loss: 0.0302\n",
      "train MAE: 2595.7064\n",
      "val Loss: 0.0332\n",
      "val MAE: 2606.5771\n",
      "\n",
      "Epoch 69/100\n",
      "----------\n",
      "train Loss: 0.0296\n",
      "train MAE: 2522.1774\n",
      "val Loss: 0.0334\n",
      "val MAE: 2608.5584\n",
      "\n",
      "Epoch 70/100\n",
      "----------\n",
      "train Loss: 0.0304\n",
      "train MAE: 2583.2670\n",
      "val Loss: 0.0332\n",
      "val MAE: 2606.2005\n",
      "\n",
      "Epoch 71/100\n",
      "----------\n",
      "train Loss: 0.0311\n",
      "train MAE: 2604.5876\n",
      "val Loss: 0.0333\n",
      "val MAE: 2610.0363\n",
      "\n",
      "Epoch 72/100\n",
      "----------\n",
      "train Loss: 0.0307\n",
      "train MAE: 2585.0581\n",
      "val Loss: 0.0332\n",
      "val MAE: 2606.6505\n",
      "\n",
      "Epoch 73/100\n",
      "----------\n",
      "train Loss: 0.0295\n",
      "train MAE: 2555.6727\n",
      "val Loss: 0.0334\n",
      "val MAE: 2612.2357\n",
      "\n",
      "Epoch 74/100\n",
      "----------\n",
      "train Loss: 0.0310\n",
      "train MAE: 2580.1376\n",
      "val Loss: 0.0332\n",
      "val MAE: 2597.8118\n",
      "\n",
      "Epoch 75/100\n",
      "----------\n",
      "train Loss: 0.0295\n",
      "train MAE: 2559.8583\n",
      "val Loss: 0.0340\n",
      "val MAE: 2644.4402\n",
      "\n",
      "Epoch 76/100\n",
      "----------\n",
      "train Loss: 0.0292\n",
      "train MAE: 2539.0820\n",
      "val Loss: 0.0343\n",
      "val MAE: 2658.8744\n",
      "\n",
      "Epoch 77/100\n",
      "----------\n",
      "train Loss: 0.0299\n",
      "train MAE: 2553.0353\n",
      "val Loss: 0.0332\n",
      "val MAE: 2604.3468\n",
      "\n",
      "Epoch 78/100\n",
      "----------\n",
      "train Loss: 0.0295\n",
      "train MAE: 2548.0074\n",
      "val Loss: 0.0336\n",
      "val MAE: 2615.2838\n",
      "\n",
      "Epoch 79/100\n",
      "----------\n",
      "train Loss: 0.0308\n",
      "train MAE: 2595.8580\n",
      "val Loss: 0.0333\n",
      "val MAE: 2607.6933\n",
      "\n",
      "Epoch 80/100\n",
      "----------\n",
      "train Loss: 0.0300\n",
      "train MAE: 2558.1077\n",
      "val Loss: 0.0332\n",
      "val MAE: 2611.8024\n",
      "\n",
      "Epoch 81/100\n",
      "----------\n",
      "train Loss: 0.0305\n",
      "train MAE: 2599.1931\n",
      "val Loss: 0.0334\n",
      "val MAE: 2612.6089\n",
      "\n",
      "Epoch 82/100\n",
      "----------\n",
      "train Loss: 0.0296\n",
      "train MAE: 2559.5196\n",
      "val Loss: 0.0333\n",
      "val MAE: 2607.2236\n",
      "\n",
      "Epoch 83/100\n",
      "----------\n",
      "train Loss: 0.0303\n",
      "train MAE: 2601.1868\n",
      "val Loss: 0.0329\n",
      "val MAE: 2595.1278\n",
      "\n",
      "Epoch 84/100\n",
      "----------\n",
      "train Loss: 0.0307\n",
      "train MAE: 2597.0793\n",
      "val Loss: 0.0332\n",
      "val MAE: 2604.8080\n",
      "\n",
      "Epoch 85/100\n",
      "----------\n",
      "train Loss: 0.0294\n",
      "train MAE: 2531.1678\n",
      "val Loss: 0.0330\n",
      "val MAE: 2597.5305\n",
      "\n",
      "Epoch 86/100\n",
      "----------\n",
      "train Loss: 0.0316\n",
      "train MAE: 2630.0975\n",
      "val Loss: 0.0336\n",
      "val MAE: 2626.0281\n",
      "\n",
      "Epoch 87/100\n",
      "----------\n",
      "train Loss: 0.0310\n",
      "train MAE: 2634.0958\n",
      "val Loss: 0.0335\n",
      "val MAE: 2615.4510\n",
      "\n",
      "Epoch 88/100\n",
      "----------\n",
      "train Loss: 0.0297\n",
      "train MAE: 2559.9070\n",
      "val Loss: 0.0329\n",
      "val MAE: 2595.1642\n",
      "\n",
      "Epoch 89/100\n",
      "----------\n",
      "train Loss: 0.0296\n",
      "train MAE: 2546.4622\n",
      "val Loss: 0.0332\n",
      "val MAE: 2610.6436\n",
      "\n",
      "Epoch 90/100\n",
      "----------\n",
      "train Loss: 0.0304\n",
      "train MAE: 2589.5099\n",
      "val Loss: 0.0335\n",
      "val MAE: 2612.3148\n",
      "\n",
      "Epoch 91/100\n",
      "----------\n",
      "train Loss: 0.0296\n",
      "train MAE: 2528.6099\n",
      "val Loss: 0.0335\n",
      "val MAE: 2613.7835\n",
      "\n",
      "Epoch 92/100\n",
      "----------\n",
      "train Loss: 0.0299\n",
      "train MAE: 2553.6316\n",
      "val Loss: 0.0333\n",
      "val MAE: 2608.0783\n",
      "\n",
      "Epoch 93/100\n",
      "----------\n",
      "train Loss: 0.0295\n",
      "train MAE: 2540.9024\n",
      "val Loss: 0.0332\n",
      "val MAE: 2605.0964\n",
      "\n",
      "Epoch 94/100\n",
      "----------\n",
      "train Loss: 0.0295\n",
      "train MAE: 2536.9511\n",
      "val Loss: 0.0331\n",
      "val MAE: 2599.2135\n",
      "\n",
      "Epoch 95/100\n",
      "----------\n",
      "train Loss: 0.0304\n",
      "train MAE: 2595.9554\n",
      "val Loss: 0.0332\n",
      "val MAE: 2606.1938\n",
      "\n",
      "Epoch 96/100\n",
      "----------\n",
      "train Loss: 0.0298\n",
      "train MAE: 2555.4687\n",
      "val Loss: 0.0338\n",
      "val MAE: 2633.4717\n",
      "\n",
      "Epoch 97/100\n",
      "----------\n",
      "train Loss: 0.0298\n",
      "train MAE: 2577.3839\n",
      "val Loss: 0.0331\n",
      "val MAE: 2602.6601\n",
      "\n",
      "Epoch 98/100\n",
      "----------\n",
      "train Loss: 0.0302\n",
      "train MAE: 2578.4675\n",
      "val Loss: 0.0333\n",
      "val MAE: 2611.2632\n",
      "\n",
      "Epoch 99/100\n",
      "----------\n",
      "train Loss: 0.0293\n",
      "train MAE: 2557.0837\n",
      "val Loss: 0.0334\n",
      "val MAE: 2612.6852\n",
      "\n",
      "Epoch 100/100\n",
      "----------\n",
      "train Loss: 0.0298\n",
      "train MAE: 2559.6838\n",
      "val Loss: 0.0344\n",
      "val MAE: 2657.7589\n",
      "\n",
      "Training complete in 127m 40s\n",
      "Best val Loss: 0.032884 at epoch 20\n",
      "Best val MAE: 2612.116795 at epoch 20\n",
      "\n",
      "Load the model weights at the best epoch\n"
     ]
    }
   ],
   "source": [
    "model_res152, mae_list_5 = train_model(model_ft, model_LU, criterion, optimizer_ft, exp_lr_scheduler, num_epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (2053, 32, 1) + DO + CB3+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "### ResNet18\n",
    "model_ft = models.resnet152(pretrained=True)\n",
    "num_ftrs = model_ft.fc.in_features\n",
    "model_ft.fc = nn.Identity()\n",
    "\n",
    "### Freeze and Fine Tuning\n",
    "for param in model_ft.parameters():\n",
    "    param.requires_grad = False\n",
    "for param in model_ft.layer3.parameters():\n",
    "    param.requires_grad = True\n",
    "for param in model_ft.layer4.parameters():\n",
    "    param.requires_grad = True\n",
    "assert [param.requires_grad for param in model_ft.parameters()][-1]\n",
    "\n",
    "### LU\n",
    "model_LU = nn.Sequential(\n",
    "    nn.Linear(num_ftrs + 5, 32),\n",
    "    nn.Tanh(), \n",
    "    nn.Dropout(p=0.4),\n",
    "    nn.Linear(32, 1)\n",
    ")\n",
    "\n",
    "### model setup\n",
    "model_ft = model_ft.to(device)\n",
    "model_LU = model_LU.to(device)\n",
    "criterion = nn.MSELoss()\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.SGD(list(model_ft.parameters())+list(model_LU.parameters()), lr=0.001, momentum=0.9)\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=20, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "----------\n",
      "train Loss: 0.0943\n",
      "train MAE: 4596.5484\n",
      "val Loss: 0.0562\n",
      "val MAE: 3475.2613\n",
      "\n",
      "Epoch 2/100\n",
      "----------\n",
      "train Loss: 0.0643\n",
      "train MAE: 3780.7022\n",
      "val Loss: 0.0517\n",
      "val MAE: 3285.6866\n",
      "\n",
      "Epoch 3/100\n",
      "----------\n",
      "train Loss: 0.0585\n",
      "train MAE: 3619.5315\n",
      "val Loss: 0.0482\n",
      "val MAE: 3170.3074\n",
      "\n",
      "Epoch 4/100\n",
      "----------\n",
      "train Loss: 0.0549\n",
      "train MAE: 3517.7332\n",
      "val Loss: 0.0469\n",
      "val MAE: 3127.5215\n",
      "\n",
      "Epoch 5/100\n",
      "----------\n",
      "train Loss: 0.0524\n",
      "train MAE: 3397.6696\n",
      "val Loss: 0.0442\n",
      "val MAE: 3059.9985\n",
      "\n",
      "Epoch 6/100\n",
      "----------\n",
      "train Loss: 0.0517\n",
      "train MAE: 3360.8065\n",
      "val Loss: 0.0485\n",
      "val MAE: 3218.7589\n",
      "\n",
      "Epoch 7/100\n",
      "----------\n",
      "train Loss: 0.0484\n",
      "train MAE: 3301.4213\n",
      "val Loss: 0.0452\n",
      "val MAE: 3099.9392\n",
      "\n",
      "Epoch 8/100\n",
      "----------\n",
      "train Loss: 0.0465\n",
      "train MAE: 3195.0921\n",
      "val Loss: 0.0410\n",
      "val MAE: 2907.3924\n",
      "\n",
      "Epoch 9/100\n",
      "----------\n",
      "train Loss: 0.0443\n",
      "train MAE: 3123.7097\n",
      "val Loss: 0.0396\n",
      "val MAE: 2895.5838\n",
      "\n",
      "Epoch 10/100\n",
      "----------\n",
      "train Loss: 0.0446\n",
      "train MAE: 3166.7866\n",
      "val Loss: 0.0406\n",
      "val MAE: 2907.8046\n",
      "\n",
      "Epoch 11/100\n",
      "----------\n",
      "train Loss: 0.0431\n",
      "train MAE: 3121.7189\n",
      "val Loss: 0.0404\n",
      "val MAE: 2916.7559\n",
      "\n",
      "Epoch 12/100\n",
      "----------\n",
      "train Loss: 0.0433\n",
      "train MAE: 3093.4677\n",
      "val Loss: 0.0388\n",
      "val MAE: 2830.1933\n",
      "\n",
      "Epoch 13/100\n",
      "----------\n",
      "train Loss: 0.0414\n",
      "train MAE: 3031.2872\n",
      "val Loss: 0.0390\n",
      "val MAE: 2853.7817\n",
      "\n",
      "Epoch 14/100\n",
      "----------\n",
      "train Loss: 0.0407\n",
      "train MAE: 2996.7257\n",
      "val Loss: 0.0383\n",
      "val MAE: 2840.1528\n",
      "\n",
      "Epoch 15/100\n",
      "----------\n",
      "train Loss: 0.0407\n",
      "train MAE: 2994.9415\n",
      "val Loss: 0.0366\n",
      "val MAE: 2768.1543\n",
      "\n",
      "Epoch 16/100\n",
      "----------\n",
      "train Loss: 0.0404\n",
      "train MAE: 3010.5230\n",
      "val Loss: 0.0422\n",
      "val MAE: 2995.5028\n",
      "\n",
      "Epoch 17/100\n",
      "----------\n",
      "train Loss: 0.0392\n",
      "train MAE: 2956.7814\n",
      "val Loss: 0.0439\n",
      "val MAE: 3081.0107\n",
      "\n",
      "Epoch 18/100\n",
      "----------\n",
      "train Loss: 0.0395\n",
      "train MAE: 2957.8470\n",
      "val Loss: 0.0377\n",
      "val MAE: 2824.6128\n",
      "\n",
      "Epoch 19/100\n",
      "----------\n",
      "train Loss: 0.0390\n",
      "train MAE: 2956.6265\n",
      "val Loss: 0.0369\n",
      "val MAE: 2770.5921\n",
      "\n",
      "Epoch 20/100\n",
      "----------\n",
      "train Loss: 0.0372\n",
      "train MAE: 2870.3844\n",
      "val Loss: 0.0363\n",
      "val MAE: 2731.0438\n",
      "\n",
      "Epoch 21/100\n",
      "----------\n",
      "train Loss: 0.0350\n",
      "train MAE: 2806.1318\n",
      "val Loss: 0.0362\n",
      "val MAE: 2743.1040\n",
      "\n",
      "Epoch 22/100\n",
      "----------\n",
      "train Loss: 0.0360\n",
      "train MAE: 2848.4041\n",
      "val Loss: 0.0370\n",
      "val MAE: 2765.6744\n",
      "\n",
      "Epoch 23/100\n",
      "----------\n",
      "train Loss: 0.0355\n",
      "train MAE: 2820.9148\n",
      "val Loss: 0.0372\n",
      "val MAE: 2773.9217\n",
      "\n",
      "Epoch 24/100\n",
      "----------\n",
      "train Loss: 0.0356\n",
      "train MAE: 2819.3861\n",
      "val Loss: 0.0373\n",
      "val MAE: 2781.1062\n",
      "\n",
      "Epoch 25/100\n",
      "----------\n",
      "train Loss: 0.0346\n",
      "train MAE: 2776.5902\n",
      "val Loss: 0.0366\n",
      "val MAE: 2724.8872\n",
      "\n",
      "Epoch 26/100\n",
      "----------\n",
      "train Loss: 0.0358\n",
      "train MAE: 2824.5309\n",
      "val Loss: 0.0367\n",
      "val MAE: 2745.9010\n",
      "\n",
      "Epoch 27/100\n",
      "----------\n",
      "train Loss: 0.0344\n",
      "train MAE: 2781.4649\n",
      "val Loss: 0.0368\n",
      "val MAE: 2744.5473\n",
      "\n",
      "Epoch 28/100\n",
      "----------\n",
      "train Loss: 0.0336\n",
      "train MAE: 2737.6822\n",
      "val Loss: 0.0369\n",
      "val MAE: 2765.3313\n",
      "\n",
      "Epoch 29/100\n",
      "----------\n",
      "train Loss: 0.0353\n",
      "train MAE: 2809.6961\n",
      "val Loss: 0.0372\n",
      "val MAE: 2754.1408\n",
      "\n",
      "Epoch 30/100\n",
      "----------\n",
      "train Loss: 0.0345\n",
      "train MAE: 2752.0412\n",
      "val Loss: 0.0365\n",
      "val MAE: 2738.9417\n",
      "\n",
      "Epoch 31/100\n",
      "----------\n",
      "train Loss: 0.0346\n",
      "train MAE: 2792.1786\n",
      "val Loss: 0.0371\n",
      "val MAE: 2756.1988\n",
      "\n",
      "Epoch 32/100\n",
      "----------\n",
      "train Loss: 0.0347\n",
      "train MAE: 2781.0775\n",
      "val Loss: 0.0376\n",
      "val MAE: 2784.5748\n",
      "\n",
      "Epoch 33/100\n",
      "----------\n",
      "train Loss: 0.0344\n",
      "train MAE: 2789.2302\n",
      "val Loss: 0.0365\n",
      "val MAE: 2723.0761\n",
      "\n",
      "Epoch 34/100\n",
      "----------\n",
      "train Loss: 0.0353\n",
      "train MAE: 2798.6408\n",
      "val Loss: 0.0360\n",
      "val MAE: 2710.3261\n",
      "\n",
      "Epoch 35/100\n",
      "----------\n",
      "train Loss: 0.0337\n",
      "train MAE: 2727.3090\n",
      "val Loss: 0.0357\n",
      "val MAE: 2709.1317\n",
      "\n",
      "Epoch 36/100\n",
      "----------\n",
      "train Loss: 0.0341\n",
      "train MAE: 2740.8740\n",
      "val Loss: 0.0366\n",
      "val MAE: 2742.2243\n",
      "\n",
      "Epoch 37/100\n",
      "----------\n",
      "train Loss: 0.0334\n",
      "train MAE: 2732.1036\n",
      "val Loss: 0.0361\n",
      "val MAE: 2721.9774\n",
      "\n",
      "Epoch 38/100\n",
      "----------\n",
      "train Loss: 0.0337\n",
      "train MAE: 2734.6179\n",
      "val Loss: 0.0361\n",
      "val MAE: 2745.2273\n",
      "\n",
      "Epoch 39/100\n",
      "----------\n",
      "train Loss: 0.0334\n",
      "train MAE: 2704.0511\n",
      "val Loss: 0.0363\n",
      "val MAE: 2715.3869\n",
      "\n",
      "Epoch 40/100\n",
      "----------\n",
      "train Loss: 0.0333\n",
      "train MAE: 2704.5827\n",
      "val Loss: 0.0382\n",
      "val MAE: 2815.8012\n",
      "\n",
      "Epoch 41/100\n",
      "----------\n",
      "train Loss: 0.0347\n",
      "train MAE: 2767.5801\n",
      "val Loss: 0.0381\n",
      "val MAE: 2821.4617\n",
      "\n",
      "Epoch 42/100\n",
      "----------\n",
      "train Loss: 0.0345\n",
      "train MAE: 2817.3812\n",
      "val Loss: 0.0366\n",
      "val MAE: 2740.0423\n",
      "\n",
      "Epoch 43/100\n",
      "----------\n",
      "train Loss: 0.0341\n",
      "train MAE: 2765.9785\n",
      "val Loss: 0.0364\n",
      "val MAE: 2729.6490\n",
      "\n",
      "Epoch 44/100\n",
      "----------\n",
      "train Loss: 0.0340\n",
      "train MAE: 2769.4112\n",
      "val Loss: 0.0380\n",
      "val MAE: 2809.1800\n",
      "\n",
      "Epoch 45/100\n",
      "----------\n",
      "train Loss: 0.0342\n",
      "train MAE: 2758.2194\n",
      "val Loss: 0.0368\n",
      "val MAE: 2734.5140\n",
      "\n",
      "Epoch 46/100\n",
      "----------\n",
      "train Loss: 0.0322\n",
      "train MAE: 2676.5559\n",
      "val Loss: 0.0363\n",
      "val MAE: 2739.4720\n",
      "\n",
      "Epoch 47/100\n",
      "----------\n",
      "train Loss: 0.0336\n",
      "train MAE: 2741.8690\n",
      "val Loss: 0.0365\n",
      "val MAE: 2730.2777\n",
      "\n",
      "Epoch 48/100\n",
      "----------\n",
      "train Loss: 0.0335\n",
      "train MAE: 2733.7404\n",
      "val Loss: 0.0368\n",
      "val MAE: 2770.5534\n",
      "\n",
      "Epoch 49/100\n",
      "----------\n",
      "train Loss: 0.0339\n",
      "train MAE: 2767.8259\n",
      "val Loss: 0.0373\n",
      "val MAE: 2768.4803\n",
      "\n",
      "Epoch 50/100\n",
      "----------\n",
      "train Loss: 0.0335\n",
      "train MAE: 2713.8852\n",
      "val Loss: 0.0364\n",
      "val MAE: 2719.4862\n",
      "\n",
      "Epoch 51/100\n",
      "----------\n",
      "train Loss: 0.0352\n",
      "train MAE: 2763.0547\n",
      "val Loss: 0.0379\n",
      "val MAE: 2832.8174\n",
      "\n",
      "Epoch 52/100\n",
      "----------\n",
      "train Loss: 0.0337\n",
      "train MAE: 2748.7724\n",
      "val Loss: 0.0359\n",
      "val MAE: 2723.8045\n",
      "\n",
      "Epoch 53/100\n",
      "----------\n",
      "train Loss: 0.0347\n",
      "train MAE: 2778.2050\n",
      "val Loss: 0.0366\n",
      "val MAE: 2749.2266\n",
      "\n",
      "Epoch 54/100\n",
      "----------\n",
      "train Loss: 0.0346\n",
      "train MAE: 2786.7894\n",
      "val Loss: 0.0364\n",
      "val MAE: 2745.5723\n",
      "\n",
      "Epoch 55/100\n",
      "----------\n",
      "train Loss: 0.0329\n",
      "train MAE: 2713.9383\n",
      "val Loss: 0.0369\n",
      "val MAE: 2784.2503\n",
      "\n",
      "Epoch 56/100\n",
      "----------\n",
      "train Loss: 0.0330\n",
      "train MAE: 2736.3764\n",
      "val Loss: 0.0363\n",
      "val MAE: 2722.7887\n",
      "\n",
      "Epoch 57/100\n",
      "----------\n",
      "train Loss: 0.0338\n",
      "train MAE: 2719.2669\n",
      "val Loss: 0.0368\n",
      "val MAE: 2775.9316\n",
      "\n",
      "Epoch 58/100\n",
      "----------\n",
      "train Loss: 0.0347\n",
      "train MAE: 2802.0842\n",
      "val Loss: 0.0371\n",
      "val MAE: 2765.8265\n",
      "\n",
      "Epoch 59/100\n",
      "----------\n",
      "train Loss: 0.0336\n",
      "train MAE: 2731.3446\n",
      "val Loss: 0.0368\n",
      "val MAE: 2740.4083\n",
      "\n",
      "Epoch 60/100\n",
      "----------\n",
      "train Loss: 0.0339\n",
      "train MAE: 2755.2908\n",
      "val Loss: 0.0374\n",
      "val MAE: 2769.1841\n",
      "\n",
      "Epoch 61/100\n",
      "----------\n",
      "train Loss: 0.0341\n",
      "train MAE: 2741.7696\n",
      "val Loss: 0.0372\n",
      "val MAE: 2769.9789\n",
      "\n",
      "Epoch 62/100\n",
      "----------\n",
      "train Loss: 0.0335\n",
      "train MAE: 2735.3627\n",
      "val Loss: 0.0377\n",
      "val MAE: 2794.2055\n",
      "\n",
      "Epoch 63/100\n",
      "----------\n",
      "train Loss: 0.0344\n",
      "train MAE: 2764.8492\n",
      "val Loss: 0.0375\n",
      "val MAE: 2812.8457\n",
      "\n",
      "Epoch 64/100\n",
      "----------\n",
      "train Loss: 0.0342\n",
      "train MAE: 2760.4693\n",
      "val Loss: 0.0370\n",
      "val MAE: 2775.4747\n",
      "\n",
      "Epoch 65/100\n",
      "----------\n",
      "train Loss: 0.0339\n",
      "train MAE: 2720.6337\n",
      "val Loss: 0.0371\n",
      "val MAE: 2751.2789\n",
      "\n",
      "Epoch 66/100\n",
      "----------\n",
      "train Loss: 0.0348\n",
      "train MAE: 2788.8669\n",
      "val Loss: 0.0364\n",
      "val MAE: 2717.7588\n",
      "\n",
      "Epoch 67/100\n",
      "----------\n",
      "train Loss: 0.0343\n",
      "train MAE: 2743.0104\n",
      "val Loss: 0.0367\n",
      "val MAE: 2754.8697\n",
      "\n",
      "Epoch 68/100\n",
      "----------\n",
      "train Loss: 0.0329\n",
      "train MAE: 2711.1234\n",
      "val Loss: 0.0376\n",
      "val MAE: 2769.1036\n",
      "\n",
      "Epoch 69/100\n",
      "----------\n",
      "train Loss: 0.0344\n",
      "train MAE: 2778.8748\n",
      "val Loss: 0.0364\n",
      "val MAE: 2742.5164\n",
      "\n",
      "Epoch 70/100\n",
      "----------\n",
      "train Loss: 0.0331\n",
      "train MAE: 2707.4616\n",
      "val Loss: 0.0361\n",
      "val MAE: 2711.6972\n",
      "\n",
      "Epoch 71/100\n",
      "----------\n",
      "train Loss: 0.0333\n",
      "train MAE: 2722.7781\n",
      "val Loss: 0.0364\n",
      "val MAE: 2716.1892\n",
      "\n",
      "Epoch 72/100\n",
      "----------\n",
      "train Loss: 0.0338\n",
      "train MAE: 2752.6161\n",
      "val Loss: 0.0368\n",
      "val MAE: 2742.7522\n",
      "\n",
      "Epoch 73/100\n",
      "----------\n",
      "train Loss: 0.0330\n",
      "train MAE: 2698.9765\n",
      "val Loss: 0.0365\n",
      "val MAE: 2745.3134\n",
      "\n",
      "Epoch 74/100\n",
      "----------\n",
      "train Loss: 0.0336\n",
      "train MAE: 2737.4915\n",
      "val Loss: 0.0372\n",
      "val MAE: 2754.1772\n",
      "\n",
      "Epoch 75/100\n",
      "----------\n",
      "train Loss: 0.0342\n",
      "train MAE: 2744.5992\n",
      "val Loss: 0.0356\n",
      "val MAE: 2688.7419\n",
      "\n",
      "Epoch 76/100\n",
      "----------\n",
      "train Loss: 0.0335\n",
      "train MAE: 2710.4278\n",
      "val Loss: 0.0367\n",
      "val MAE: 2785.8036\n",
      "\n",
      "Epoch 77/100\n",
      "----------\n",
      "train Loss: 0.0343\n",
      "train MAE: 2788.0847\n",
      "val Loss: 0.0363\n",
      "val MAE: 2700.9252\n",
      "\n",
      "Epoch 78/100\n",
      "----------\n",
      "train Loss: 0.0334\n",
      "train MAE: 2740.5888\n",
      "val Loss: 0.0378\n",
      "val MAE: 2787.9498\n",
      "\n",
      "Epoch 79/100\n",
      "----------\n",
      "train Loss: 0.0335\n",
      "train MAE: 2727.7214\n",
      "val Loss: 0.0364\n",
      "val MAE: 2731.2582\n",
      "\n",
      "Epoch 80/100\n",
      "----------\n",
      "train Loss: 0.0346\n",
      "train MAE: 2754.7744\n",
      "val Loss: 0.0362\n",
      "val MAE: 2726.8325\n",
      "\n",
      "Epoch 81/100\n",
      "----------\n",
      "train Loss: 0.0336\n",
      "train MAE: 2733.1638\n",
      "val Loss: 0.0371\n",
      "val MAE: 2779.8405\n",
      "\n",
      "Epoch 82/100\n",
      "----------\n",
      "train Loss: 0.0337\n",
      "train MAE: 2753.5983\n",
      "val Loss: 0.0362\n",
      "val MAE: 2743.8538\n",
      "\n",
      "Epoch 83/100\n",
      "----------\n",
      "train Loss: 0.0344\n",
      "train MAE: 2772.5729\n",
      "val Loss: 0.0381\n",
      "val MAE: 2809.9116\n",
      "\n",
      "Epoch 84/100\n",
      "----------\n",
      "train Loss: 0.0337\n",
      "train MAE: 2736.8591\n",
      "val Loss: 0.0373\n",
      "val MAE: 2784.4483\n",
      "\n",
      "Epoch 85/100\n",
      "----------\n",
      "train Loss: 0.0339\n",
      "train MAE: 2743.8183\n",
      "val Loss: 0.0366\n",
      "val MAE: 2773.0059\n",
      "\n",
      "Epoch 86/100\n",
      "----------\n",
      "train Loss: 0.0333\n",
      "train MAE: 2725.3702\n",
      "val Loss: 0.0370\n",
      "val MAE: 2773.6315\n",
      "\n",
      "Epoch 87/100\n",
      "----------\n",
      "train Loss: 0.0339\n",
      "train MAE: 2740.4410\n",
      "val Loss: 0.0353\n",
      "val MAE: 2683.1526\n",
      "\n",
      "Epoch 88/100\n",
      "----------\n",
      "train Loss: 0.0342\n",
      "train MAE: 2776.3405\n",
      "val Loss: 0.0365\n",
      "val MAE: 2744.0337\n",
      "\n",
      "Epoch 89/100\n",
      "----------\n",
      "train Loss: 0.0335\n",
      "train MAE: 2730.7843\n",
      "val Loss: 0.0368\n",
      "val MAE: 2766.4871\n",
      "\n",
      "Epoch 90/100\n",
      "----------\n",
      "train Loss: 0.0323\n",
      "train MAE: 2676.0781\n",
      "val Loss: 0.0367\n",
      "val MAE: 2785.1150\n",
      "\n",
      "Epoch 91/100\n",
      "----------\n",
      "train Loss: 0.0341\n",
      "train MAE: 2766.6539\n",
      "val Loss: 0.0367\n",
      "val MAE: 2732.1492\n",
      "\n",
      "Epoch 92/100\n",
      "----------\n",
      "train Loss: 0.0335\n",
      "train MAE: 2738.4709\n",
      "val Loss: 0.0367\n",
      "val MAE: 2752.0445\n",
      "\n",
      "Epoch 93/100\n",
      "----------\n",
      "train Loss: 0.0327\n",
      "train MAE: 2715.8241\n",
      "val Loss: 0.0368\n",
      "val MAE: 2778.2186\n",
      "\n",
      "Epoch 94/100\n",
      "----------\n",
      "train Loss: 0.0331\n",
      "train MAE: 2725.7956\n",
      "val Loss: 0.0366\n",
      "val MAE: 2758.6955\n",
      "\n",
      "Epoch 95/100\n",
      "----------\n",
      "train Loss: 0.0340\n",
      "train MAE: 2741.8013\n",
      "val Loss: 0.0364\n",
      "val MAE: 2717.7489\n",
      "\n",
      "Epoch 96/100\n",
      "----------\n",
      "train Loss: 0.0325\n",
      "train MAE: 2698.1619\n",
      "val Loss: 0.0378\n",
      "val MAE: 2787.0923\n",
      "\n",
      "Epoch 97/100\n",
      "----------\n",
      "train Loss: 0.0333\n",
      "train MAE: 2740.5468\n",
      "val Loss: 0.0373\n",
      "val MAE: 2788.4563\n",
      "\n",
      "Epoch 98/100\n",
      "----------\n",
      "train Loss: 0.0342\n",
      "train MAE: 2773.7183\n",
      "val Loss: 0.0357\n",
      "val MAE: 2731.0946\n",
      "\n",
      "Epoch 99/100\n",
      "----------\n",
      "train Loss: 0.0328\n",
      "train MAE: 2718.6835\n",
      "val Loss: 0.0363\n",
      "val MAE: 2737.1010\n",
      "\n",
      "Epoch 100/100\n",
      "----------\n",
      "train Loss: 0.0334\n",
      "train MAE: 2726.4528\n",
      "val Loss: 0.0358\n",
      "val MAE: 2716.1499\n",
      "\n",
      "Training complete in 127m 47s\n",
      "Best val Loss: 0.035349 at epoch 87\n",
      "Best val MAE: 2683.152620 at epoch 87\n",
      "\n",
      "Load the model weights at the best epoch\n"
     ]
    }
   ],
   "source": [
    "model_res152, mae_list_2 = train_model(model_ft, model_LU, criterion, optimizer_ft, exp_lr_scheduler, num_epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (2053, 64, 1) + DO + CB3+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "### ResNet18\n",
    "model_ft = models.resnet152(pretrained=True)\n",
    "num_ftrs = model_ft.fc.in_features\n",
    "model_ft.fc = nn.Identity()\n",
    "\n",
    "### Freeze and Fine Tuning\n",
    "for param in model_ft.parameters():\n",
    "    param.requires_grad = False\n",
    "for param in model_ft.layer3.parameters():\n",
    "    param.requires_grad = True\n",
    "for param in model_ft.layer4.parameters():\n",
    "    param.requires_grad = True\n",
    "assert [param.requires_grad for param in model_ft.parameters()][-1]\n",
    "\n",
    "### LU\n",
    "model_LU = nn.Sequential(\n",
    "    nn.Linear(num_ftrs + 5, 64),\n",
    "    nn.Tanh(), \n",
    "    nn.Dropout(p=0.4),\n",
    "    nn.Linear(64, 1)\n",
    ")\n",
    "\n",
    "### model setup\n",
    "model_ft = model_ft.to(device)\n",
    "model_LU = model_LU.to(device)\n",
    "criterion = nn.MSELoss()\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.SGD(list(model_ft.parameters())+list(model_LU.parameters()), lr=0.001, momentum=0.9)\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=20, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "----------\n",
      "train Loss: 0.0986\n",
      "train MAE: 4580.7431\n",
      "val Loss: 0.0671\n",
      "val MAE: 3909.1609\n",
      "\n",
      "Epoch 2/100\n",
      "----------\n",
      "train Loss: 0.0674\n",
      "train MAE: 3876.8607\n",
      "val Loss: 0.0517\n",
      "val MAE: 3358.9410\n",
      "\n",
      "Epoch 3/100\n",
      "----------\n",
      "train Loss: 0.0595\n",
      "train MAE: 3648.0643\n",
      "val Loss: 0.0508\n",
      "val MAE: 3311.5708\n",
      "\n",
      "Epoch 4/100\n",
      "----------\n",
      "train Loss: 0.0537\n",
      "train MAE: 3445.9775\n",
      "val Loss: 0.0447\n",
      "val MAE: 3069.0476\n",
      "\n",
      "Epoch 5/100\n",
      "----------\n",
      "train Loss: 0.0522\n",
      "train MAE: 3393.5715\n",
      "val Loss: 0.0527\n",
      "val MAE: 3397.2014\n",
      "\n",
      "Epoch 6/100\n",
      "----------\n",
      "train Loss: 0.0488\n",
      "train MAE: 3286.1721\n",
      "val Loss: 0.0426\n",
      "val MAE: 3012.8017\n",
      "\n",
      "Epoch 7/100\n",
      "----------\n",
      "train Loss: 0.0468\n",
      "train MAE: 3228.0724\n",
      "val Loss: 0.0423\n",
      "val MAE: 2963.2726\n",
      "\n",
      "Epoch 8/100\n",
      "----------\n",
      "train Loss: 0.0470\n",
      "train MAE: 3194.6751\n",
      "val Loss: 0.0393\n",
      "val MAE: 2887.9360\n",
      "\n",
      "Epoch 9/100\n",
      "----------\n",
      "train Loss: 0.0468\n",
      "train MAE: 3185.1937\n",
      "val Loss: 0.0399\n",
      "val MAE: 2901.8096\n",
      "\n",
      "Epoch 10/100\n",
      "----------\n",
      "train Loss: 0.0436\n",
      "train MAE: 3096.1859\n",
      "val Loss: 0.0399\n",
      "val MAE: 2867.3746\n",
      "\n",
      "Epoch 11/100\n",
      "----------\n",
      "train Loss: 0.0424\n",
      "train MAE: 3063.5558\n",
      "val Loss: 0.0390\n",
      "val MAE: 2834.2483\n",
      "\n",
      "Epoch 12/100\n",
      "----------\n",
      "train Loss: 0.0423\n",
      "train MAE: 3070.1729\n",
      "val Loss: 0.0374\n",
      "val MAE: 2769.9612\n",
      "\n",
      "Epoch 13/100\n",
      "----------\n",
      "train Loss: 0.0418\n",
      "train MAE: 3043.6231\n",
      "val Loss: 0.0368\n",
      "val MAE: 2769.3604\n",
      "\n",
      "Epoch 14/100\n",
      "----------\n",
      "train Loss: 0.0403\n",
      "train MAE: 2988.6558\n",
      "val Loss: 0.0370\n",
      "val MAE: 2766.5749\n",
      "\n",
      "Epoch 15/100\n",
      "----------\n",
      "train Loss: 0.0393\n",
      "train MAE: 2917.6353\n",
      "val Loss: 0.0365\n",
      "val MAE: 2750.4034\n",
      "\n",
      "Epoch 16/100\n",
      "----------\n",
      "train Loss: 0.0397\n",
      "train MAE: 2949.2538\n",
      "val Loss: 0.0378\n",
      "val MAE: 2802.3804\n",
      "\n",
      "Epoch 17/100\n",
      "----------\n",
      "train Loss: 0.0391\n",
      "train MAE: 2930.7328\n",
      "val Loss: 0.0368\n",
      "val MAE: 2731.4063\n",
      "\n",
      "Epoch 18/100\n",
      "----------\n",
      "train Loss: 0.0399\n",
      "train MAE: 2978.2077\n",
      "val Loss: 0.0363\n",
      "val MAE: 2732.7674\n",
      "\n",
      "Epoch 19/100\n",
      "----------\n",
      "train Loss: 0.0381\n",
      "train MAE: 2909.8804\n",
      "val Loss: 0.0364\n",
      "val MAE: 2745.5880\n",
      "\n",
      "Epoch 20/100\n",
      "----------\n",
      "train Loss: 0.0385\n",
      "train MAE: 2917.3624\n",
      "val Loss: 0.0355\n",
      "val MAE: 2724.7150\n",
      "\n",
      "Epoch 21/100\n",
      "----------\n",
      "train Loss: 0.0356\n",
      "train MAE: 2816.9456\n",
      "val Loss: 0.0361\n",
      "val MAE: 2712.2509\n",
      "\n",
      "Epoch 22/100\n",
      "----------\n",
      "train Loss: 0.0354\n",
      "train MAE: 2819.3009\n",
      "val Loss: 0.0350\n",
      "val MAE: 2699.1776\n",
      "\n",
      "Epoch 23/100\n",
      "----------\n",
      "train Loss: 0.0354\n",
      "train MAE: 2788.1356\n",
      "val Loss: 0.0360\n",
      "val MAE: 2750.5557\n",
      "\n",
      "Epoch 24/100\n",
      "----------\n",
      "train Loss: 0.0342\n",
      "train MAE: 2742.8007\n",
      "val Loss: 0.0350\n",
      "val MAE: 2686.0163\n",
      "\n",
      "Epoch 25/100\n",
      "----------\n",
      "train Loss: 0.0344\n",
      "train MAE: 2750.9040\n",
      "val Loss: 0.0358\n",
      "val MAE: 2701.9379\n",
      "\n",
      "Epoch 26/100\n",
      "----------\n",
      "train Loss: 0.0341\n",
      "train MAE: 2729.5576\n",
      "val Loss: 0.0371\n",
      "val MAE: 2765.9339\n",
      "\n",
      "Epoch 27/100\n",
      "----------\n",
      "train Loss: 0.0346\n",
      "train MAE: 2777.1679\n",
      "val Loss: 0.0348\n",
      "val MAE: 2661.0267\n",
      "\n",
      "Epoch 28/100\n",
      "----------\n",
      "train Loss: 0.0338\n",
      "train MAE: 2744.2198\n",
      "val Loss: 0.0344\n",
      "val MAE: 2661.8165\n",
      "\n",
      "Epoch 29/100\n",
      "----------\n",
      "train Loss: 0.0339\n",
      "train MAE: 2726.9820\n",
      "val Loss: 0.0350\n",
      "val MAE: 2680.5097\n",
      "\n",
      "Epoch 30/100\n",
      "----------\n",
      "train Loss: 0.0344\n",
      "train MAE: 2737.9727\n",
      "val Loss: 0.0352\n",
      "val MAE: 2702.1939\n",
      "\n",
      "Epoch 31/100\n",
      "----------\n",
      "train Loss: 0.0340\n",
      "train MAE: 2737.8006\n",
      "val Loss: 0.0362\n",
      "val MAE: 2715.1889\n",
      "\n",
      "Epoch 32/100\n",
      "----------\n",
      "train Loss: 0.0344\n",
      "train MAE: 2748.1791\n",
      "val Loss: 0.0354\n",
      "val MAE: 2709.7541\n",
      "\n",
      "Epoch 33/100\n",
      "----------\n",
      "train Loss: 0.0339\n",
      "train MAE: 2728.5820\n",
      "val Loss: 0.0356\n",
      "val MAE: 2683.1719\n",
      "\n",
      "Epoch 34/100\n",
      "----------\n",
      "train Loss: 0.0338\n",
      "train MAE: 2738.1965\n",
      "val Loss: 0.0360\n",
      "val MAE: 2718.2134\n",
      "\n",
      "Epoch 35/100\n",
      "----------\n",
      "train Loss: 0.0343\n",
      "train MAE: 2730.2001\n",
      "val Loss: 0.0355\n",
      "val MAE: 2700.6781\n",
      "\n",
      "Epoch 36/100\n",
      "----------\n",
      "train Loss: 0.0354\n",
      "train MAE: 2803.1287\n",
      "val Loss: 0.0352\n",
      "val MAE: 2685.7418\n",
      "\n",
      "Epoch 37/100\n",
      "----------\n",
      "train Loss: 0.0344\n",
      "train MAE: 2779.0346\n",
      "val Loss: 0.0351\n",
      "val MAE: 2683.4274\n",
      "\n",
      "Epoch 38/100\n",
      "----------\n",
      "train Loss: 0.0338\n",
      "train MAE: 2696.5911\n",
      "val Loss: 0.0356\n",
      "val MAE: 2683.0471\n",
      "\n",
      "Epoch 39/100\n",
      "----------\n",
      "train Loss: 0.0344\n",
      "train MAE: 2735.5644\n",
      "val Loss: 0.0352\n",
      "val MAE: 2694.5999\n",
      "\n",
      "Epoch 40/100\n",
      "----------\n",
      "train Loss: 0.0329\n",
      "train MAE: 2683.5993\n",
      "val Loss: 0.0353\n",
      "val MAE: 2680.3107\n",
      "\n",
      "Epoch 41/100\n",
      "----------\n",
      "train Loss: 0.0335\n",
      "train MAE: 2696.9579\n",
      "val Loss: 0.0350\n",
      "val MAE: 2653.8008\n",
      "\n",
      "Epoch 42/100\n",
      "----------\n",
      "train Loss: 0.0341\n",
      "train MAE: 2720.1676\n",
      "val Loss: 0.0352\n",
      "val MAE: 2701.1816\n",
      "\n",
      "Epoch 43/100\n",
      "----------\n",
      "train Loss: 0.0337\n",
      "train MAE: 2728.1920\n",
      "val Loss: 0.0357\n",
      "val MAE: 2721.4438\n",
      "\n",
      "Epoch 44/100\n",
      "----------\n",
      "train Loss: 0.0331\n",
      "train MAE: 2667.6553\n",
      "val Loss: 0.0350\n",
      "val MAE: 2635.4165\n",
      "\n",
      "Epoch 45/100\n",
      "----------\n",
      "train Loss: 0.0318\n",
      "train MAE: 2643.5210\n",
      "val Loss: 0.0352\n",
      "val MAE: 2654.5455\n",
      "\n",
      "Epoch 46/100\n",
      "----------\n",
      "train Loss: 0.0341\n",
      "train MAE: 2719.6270\n",
      "val Loss: 0.0357\n",
      "val MAE: 2702.5303\n",
      "\n",
      "Epoch 47/100\n",
      "----------\n",
      "train Loss: 0.0320\n",
      "train MAE: 2655.1657\n",
      "val Loss: 0.0358\n",
      "val MAE: 2685.5506\n",
      "\n",
      "Epoch 48/100\n",
      "----------\n",
      "train Loss: 0.0326\n",
      "train MAE: 2694.5367\n",
      "val Loss: 0.0362\n",
      "val MAE: 2725.0698\n",
      "\n",
      "Epoch 49/100\n",
      "----------\n",
      "train Loss: 0.0342\n",
      "train MAE: 2751.0540\n",
      "val Loss: 0.0350\n",
      "val MAE: 2665.0416\n",
      "\n",
      "Epoch 50/100\n",
      "----------\n",
      "train Loss: 0.0337\n",
      "train MAE: 2701.5723\n",
      "val Loss: 0.0363\n",
      "val MAE: 2715.4800\n",
      "\n",
      "Epoch 51/100\n",
      "----------\n",
      "train Loss: 0.0337\n",
      "train MAE: 2759.5257\n",
      "val Loss: 0.0350\n",
      "val MAE: 2672.5521\n",
      "\n",
      "Epoch 52/100\n",
      "----------\n",
      "train Loss: 0.0319\n",
      "train MAE: 2662.8300\n",
      "val Loss: 0.0351\n",
      "val MAE: 2675.4647\n",
      "\n",
      "Epoch 53/100\n",
      "----------\n",
      "train Loss: 0.0342\n",
      "train MAE: 2762.2225\n",
      "val Loss: 0.0360\n",
      "val MAE: 2732.0256\n",
      "\n",
      "Epoch 54/100\n",
      "----------\n",
      "train Loss: 0.0334\n",
      "train MAE: 2694.4995\n",
      "val Loss: 0.0360\n",
      "val MAE: 2731.4696\n",
      "\n",
      "Epoch 55/100\n",
      "----------\n",
      "train Loss: 0.0333\n",
      "train MAE: 2687.8169\n",
      "val Loss: 0.0359\n",
      "val MAE: 2733.7546\n",
      "\n",
      "Epoch 56/100\n",
      "----------\n",
      "train Loss: 0.0331\n",
      "train MAE: 2678.6868\n",
      "val Loss: 0.0354\n",
      "val MAE: 2705.4252\n",
      "\n",
      "Epoch 57/100\n",
      "----------\n",
      "train Loss: 0.0332\n",
      "train MAE: 2699.5761\n",
      "val Loss: 0.0355\n",
      "val MAE: 2702.5568\n",
      "\n",
      "Epoch 58/100\n",
      "----------\n",
      "train Loss: 0.0341\n",
      "train MAE: 2769.4915\n",
      "val Loss: 0.0357\n",
      "val MAE: 2713.8879\n",
      "\n",
      "Epoch 59/100\n",
      "----------\n",
      "train Loss: 0.0344\n",
      "train MAE: 2745.7960\n",
      "val Loss: 0.0356\n",
      "val MAE: 2679.6675\n",
      "\n",
      "Epoch 60/100\n",
      "----------\n",
      "train Loss: 0.0347\n",
      "train MAE: 2780.7966\n",
      "val Loss: 0.0362\n",
      "val MAE: 2726.8392\n",
      "\n",
      "Epoch 61/100\n",
      "----------\n",
      "train Loss: 0.0339\n",
      "train MAE: 2732.7691\n",
      "val Loss: 0.0359\n",
      "val MAE: 2698.0163\n",
      "\n",
      "Epoch 62/100\n",
      "----------\n",
      "train Loss: 0.0335\n",
      "train MAE: 2708.7634\n",
      "val Loss: 0.0346\n",
      "val MAE: 2686.9063\n",
      "\n",
      "Epoch 63/100\n",
      "----------\n",
      "train Loss: 0.0341\n",
      "train MAE: 2728.3265\n",
      "val Loss: 0.0363\n",
      "val MAE: 2722.5368\n",
      "\n",
      "Epoch 64/100\n",
      "----------\n",
      "train Loss: 0.0338\n",
      "train MAE: 2735.5257\n",
      "val Loss: 0.0349\n",
      "val MAE: 2653.8825\n",
      "\n",
      "Epoch 65/100\n",
      "----------\n",
      "train Loss: 0.0335\n",
      "train MAE: 2696.7558\n",
      "val Loss: 0.0355\n",
      "val MAE: 2702.9078\n",
      "\n",
      "Epoch 66/100\n",
      "----------\n",
      "train Loss: 0.0343\n",
      "train MAE: 2755.2496\n",
      "val Loss: 0.0370\n",
      "val MAE: 2751.9802\n",
      "\n",
      "Epoch 67/100\n",
      "----------\n",
      "train Loss: 0.0327\n",
      "train MAE: 2688.8202\n",
      "val Loss: 0.0353\n",
      "val MAE: 2722.5751\n",
      "\n",
      "Epoch 68/100\n",
      "----------\n",
      "train Loss: 0.0329\n",
      "train MAE: 2687.4245\n",
      "val Loss: 0.0350\n",
      "val MAE: 2674.6571\n",
      "\n",
      "Epoch 69/100\n",
      "----------\n",
      "train Loss: 0.0338\n",
      "train MAE: 2759.3452\n",
      "val Loss: 0.0353\n",
      "val MAE: 2666.4854\n",
      "\n",
      "Epoch 70/100\n",
      "----------\n",
      "train Loss: 0.0332\n",
      "train MAE: 2691.3632\n",
      "val Loss: 0.0352\n",
      "val MAE: 2672.8493\n",
      "\n",
      "Epoch 71/100\n",
      "----------\n",
      "train Loss: 0.0335\n",
      "train MAE: 2728.7509\n",
      "val Loss: 0.0354\n",
      "val MAE: 2672.2225\n",
      "\n",
      "Epoch 72/100\n",
      "----------\n",
      "train Loss: 0.0336\n",
      "train MAE: 2705.8104\n",
      "val Loss: 0.0351\n",
      "val MAE: 2673.2788\n",
      "\n",
      "Epoch 73/100\n",
      "----------\n",
      "train Loss: 0.0334\n",
      "train MAE: 2706.9105\n",
      "val Loss: 0.0357\n",
      "val MAE: 2707.1760\n",
      "\n",
      "Epoch 74/100\n",
      "----------\n",
      "train Loss: 0.0340\n",
      "train MAE: 2745.3893\n",
      "val Loss: 0.0351\n",
      "val MAE: 2685.7532\n",
      "\n",
      "Epoch 75/100\n",
      "----------\n",
      "train Loss: 0.0332\n",
      "train MAE: 2694.0330\n",
      "val Loss: 0.0352\n",
      "val MAE: 2694.6181\n",
      "\n",
      "Epoch 76/100\n",
      "----------\n",
      "train Loss: 0.0341\n",
      "train MAE: 2759.5370\n",
      "val Loss: 0.0361\n",
      "val MAE: 2717.0833\n",
      "\n",
      "Epoch 77/100\n",
      "----------\n",
      "train Loss: 0.0341\n",
      "train MAE: 2718.2791\n",
      "val Loss: 0.0351\n",
      "val MAE: 2677.2691\n",
      "\n",
      "Epoch 78/100\n",
      "----------\n",
      "train Loss: 0.0333\n",
      "train MAE: 2710.1054\n",
      "val Loss: 0.0359\n",
      "val MAE: 2694.9210\n",
      "\n",
      "Epoch 79/100\n",
      "----------\n",
      "train Loss: 0.0335\n",
      "train MAE: 2720.1238\n",
      "val Loss: 0.0352\n",
      "val MAE: 2667.5068\n",
      "\n",
      "Epoch 80/100\n",
      "----------\n",
      "train Loss: 0.0346\n",
      "train MAE: 2752.5407\n",
      "val Loss: 0.0358\n",
      "val MAE: 2709.0988\n",
      "\n",
      "Epoch 81/100\n",
      "----------\n",
      "train Loss: 0.0334\n",
      "train MAE: 2710.9213\n",
      "val Loss: 0.0354\n",
      "val MAE: 2691.9320\n",
      "\n",
      "Epoch 82/100\n",
      "----------\n",
      "train Loss: 0.0332\n",
      "train MAE: 2721.8767\n",
      "val Loss: 0.0346\n",
      "val MAE: 2679.8298\n",
      "\n",
      "Epoch 83/100\n",
      "----------\n",
      "train Loss: 0.0325\n",
      "train MAE: 2658.8855\n",
      "val Loss: 0.0352\n",
      "val MAE: 2701.9471\n",
      "\n",
      "Epoch 84/100\n",
      "----------\n",
      "train Loss: 0.0341\n",
      "train MAE: 2729.9740\n",
      "val Loss: 0.0351\n",
      "val MAE: 2693.6417\n",
      "\n",
      "Epoch 85/100\n",
      "----------\n",
      "train Loss: 0.0334\n",
      "train MAE: 2712.6365\n",
      "val Loss: 0.0356\n",
      "val MAE: 2702.8593\n",
      "\n",
      "Epoch 86/100\n",
      "----------\n",
      "train Loss: 0.0320\n",
      "train MAE: 2640.7465\n",
      "val Loss: 0.0356\n",
      "val MAE: 2686.1818\n",
      "\n",
      "Epoch 87/100\n",
      "----------\n",
      "train Loss: 0.0334\n",
      "train MAE: 2710.0609\n",
      "val Loss: 0.0359\n",
      "val MAE: 2727.9514\n",
      "\n",
      "Epoch 88/100\n",
      "----------\n",
      "train Loss: 0.0339\n",
      "train MAE: 2698.0290\n",
      "val Loss: 0.0365\n",
      "val MAE: 2722.7300\n",
      "\n",
      "Epoch 89/100\n",
      "----------\n",
      "train Loss: 0.0322\n",
      "train MAE: 2659.9148\n",
      "val Loss: 0.0353\n",
      "val MAE: 2665.0914\n",
      "\n",
      "Epoch 90/100\n",
      "----------\n",
      "train Loss: 0.0334\n",
      "train MAE: 2709.8079\n",
      "val Loss: 0.0352\n",
      "val MAE: 2671.9640\n",
      "\n",
      "Epoch 91/100\n",
      "----------\n",
      "train Loss: 0.0336\n",
      "train MAE: 2732.2468\n",
      "val Loss: 0.0354\n",
      "val MAE: 2676.6798\n",
      "\n",
      "Epoch 92/100\n",
      "----------\n",
      "train Loss: 0.0317\n",
      "train MAE: 2634.7059\n",
      "val Loss: 0.0358\n",
      "val MAE: 2708.7708\n",
      "\n",
      "Epoch 93/100\n",
      "----------\n",
      "train Loss: 0.0343\n",
      "train MAE: 2732.9499\n",
      "val Loss: 0.0350\n",
      "val MAE: 2659.4170\n",
      "\n",
      "Epoch 94/100\n",
      "----------\n",
      "train Loss: 0.0336\n",
      "train MAE: 2707.7237\n",
      "val Loss: 0.0356\n",
      "val MAE: 2699.9698\n",
      "\n",
      "Epoch 95/100\n",
      "----------\n",
      "train Loss: 0.0327\n",
      "train MAE: 2653.5784\n",
      "val Loss: 0.0350\n",
      "val MAE: 2681.4969\n",
      "\n",
      "Epoch 96/100\n",
      "----------\n",
      "train Loss: 0.0343\n",
      "train MAE: 2742.8599\n",
      "val Loss: 0.0364\n",
      "val MAE: 2751.7986\n",
      "\n",
      "Epoch 97/100\n",
      "----------\n",
      "train Loss: 0.0337\n",
      "train MAE: 2711.3679\n",
      "val Loss: 0.0348\n",
      "val MAE: 2690.8937\n",
      "\n",
      "Epoch 98/100\n",
      "----------\n",
      "train Loss: 0.0333\n",
      "train MAE: 2707.3925\n",
      "val Loss: 0.0358\n",
      "val MAE: 2727.2254\n",
      "\n",
      "Epoch 99/100\n",
      "----------\n",
      "train Loss: 0.0328\n",
      "train MAE: 2666.7973\n",
      "val Loss: 0.0358\n",
      "val MAE: 2695.9055\n",
      "\n",
      "Epoch 100/100\n",
      "----------\n",
      "train Loss: 0.0332\n",
      "train MAE: 2693.7268\n",
      "val Loss: 0.0354\n",
      "val MAE: 2675.8424\n",
      "\n",
      "Training complete in 127m 38s\n",
      "Best val Loss: 0.034404 at epoch 28\n",
      "Best val MAE: 2661.816467 at epoch 28\n",
      "\n",
      "Load the model weights at the best epoch\n"
     ]
    }
   ],
   "source": [
    "model_res152, mae_list_4 = train_model(model_ft, model_LU, criterion, optimizer_ft, exp_lr_scheduler, num_epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (2053, 256, 1) + DO + CB3+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "### ResNet18\n",
    "model_ft = models.resnet152(pretrained=True)\n",
    "num_ftrs = model_ft.fc.in_features\n",
    "model_ft.fc = nn.Identity()\n",
    "\n",
    "### Freeze and Fine Tuning\n",
    "for param in model_ft.parameters():\n",
    "    param.requires_grad = False\n",
    "for param in model_ft.layer3.parameters():\n",
    "    param.requires_grad = True\n",
    "for param in model_ft.layer4.parameters():\n",
    "    param.requires_grad = True\n",
    "assert [param.requires_grad for param in model_ft.parameters()][-1]\n",
    "\n",
    "### LU\n",
    "model_LU = nn.Sequential(\n",
    "    nn.Linear(num_ftrs + 5, 256),\n",
    "    nn.Tanh(), \n",
    "    nn.Dropout(p=0.4),\n",
    "    nn.Linear(256, 1)\n",
    ")\n",
    "\n",
    "### model setup\n",
    "model_ft = model_ft.to(device)\n",
    "model_LU = model_LU.to(device)\n",
    "criterion = nn.MSELoss()\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.SGD(list(model_ft.parameters())+list(model_LU.parameters()), lr=0.001, momentum=0.9)\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=20, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "----------\n",
      "train Loss: 0.0964\n",
      "train MAE: 4536.6060\n",
      "val Loss: 0.0550\n",
      "val MAE: 3465.9310\n",
      "\n",
      "Epoch 2/100\n",
      "----------\n",
      "train Loss: 0.0640\n",
      "train MAE: 3801.8644\n",
      "val Loss: 0.0479\n",
      "val MAE: 3255.9154\n",
      "\n",
      "Epoch 3/100\n",
      "----------\n",
      "train Loss: 0.0568\n",
      "train MAE: 3565.2622\n",
      "val Loss: 0.0465\n",
      "val MAE: 3116.8081\n",
      "\n",
      "Epoch 4/100\n",
      "----------\n",
      "train Loss: 0.0528\n",
      "train MAE: 3427.7877\n",
      "val Loss: 0.0421\n",
      "val MAE: 2990.6768\n",
      "\n",
      "Epoch 5/100\n",
      "----------\n",
      "train Loss: 0.0493\n",
      "train MAE: 3347.8585\n",
      "val Loss: 0.0393\n",
      "val MAE: 2914.2692\n",
      "\n",
      "Epoch 6/100\n",
      "----------\n",
      "train Loss: 0.0464\n",
      "train MAE: 3210.2689\n",
      "val Loss: 0.0438\n",
      "val MAE: 3059.7734\n",
      "\n",
      "Epoch 7/100\n",
      "----------\n",
      "train Loss: 0.0478\n",
      "train MAE: 3252.4334\n",
      "val Loss: 0.0392\n",
      "val MAE: 2905.5526\n",
      "\n",
      "Epoch 8/100\n",
      "----------\n",
      "train Loss: 0.0446\n",
      "train MAE: 3146.4938\n",
      "val Loss: 0.0433\n",
      "val MAE: 3020.4330\n",
      "\n",
      "Epoch 9/100\n",
      "----------\n",
      "train Loss: 0.0452\n",
      "train MAE: 3163.6701\n",
      "val Loss: 0.0382\n",
      "val MAE: 2834.1482\n",
      "\n",
      "Epoch 10/100\n",
      "----------\n",
      "train Loss: 0.0436\n",
      "train MAE: 3102.0383\n",
      "val Loss: 0.0410\n",
      "val MAE: 2897.2842\n",
      "\n",
      "Epoch 11/100\n",
      "----------\n",
      "train Loss: 0.0427\n",
      "train MAE: 3068.1247\n",
      "val Loss: 0.0385\n",
      "val MAE: 2827.7201\n",
      "\n",
      "Epoch 12/100\n",
      "----------\n",
      "train Loss: 0.0412\n",
      "train MAE: 2996.9128\n",
      "val Loss: 0.0366\n",
      "val MAE: 2739.8026\n",
      "\n",
      "Epoch 13/100\n",
      "----------\n",
      "train Loss: 0.0393\n",
      "train MAE: 2995.3013\n",
      "val Loss: 0.0358\n",
      "val MAE: 2737.9354\n",
      "\n",
      "Epoch 14/100\n",
      "----------\n",
      "train Loss: 0.0391\n",
      "train MAE: 2960.1893\n",
      "val Loss: 0.0361\n",
      "val MAE: 2732.2010\n",
      "\n",
      "Epoch 15/100\n",
      "----------\n",
      "train Loss: 0.0404\n",
      "train MAE: 2984.2688\n",
      "val Loss: 0.0350\n",
      "val MAE: 2722.1953\n",
      "\n",
      "Epoch 16/100\n",
      "----------\n",
      "train Loss: 0.0379\n",
      "train MAE: 2899.6208\n",
      "val Loss: 0.0494\n",
      "val MAE: 3274.0486\n",
      "\n",
      "Epoch 17/100\n",
      "----------\n",
      "train Loss: 0.0390\n",
      "train MAE: 2946.5657\n",
      "val Loss: 0.0346\n",
      "val MAE: 2693.9869\n",
      "\n",
      "Epoch 18/100\n",
      "----------\n",
      "train Loss: 0.0380\n",
      "train MAE: 2904.4558\n",
      "val Loss: 0.0356\n",
      "val MAE: 2731.3982\n",
      "\n",
      "Epoch 19/100\n",
      "----------\n",
      "train Loss: 0.0370\n",
      "train MAE: 2881.9850\n",
      "val Loss: 0.0350\n",
      "val MAE: 2680.9528\n",
      "\n",
      "Epoch 20/100\n",
      "----------\n",
      "train Loss: 0.0357\n",
      "train MAE: 2791.0104\n",
      "val Loss: 0.0354\n",
      "val MAE: 2701.2062\n",
      "\n",
      "Epoch 21/100\n",
      "----------\n",
      "train Loss: 0.0330\n",
      "train MAE: 2719.4983\n",
      "val Loss: 0.0359\n",
      "val MAE: 2750.5312\n",
      "\n",
      "Epoch 22/100\n",
      "----------\n",
      "train Loss: 0.0335\n",
      "train MAE: 2726.8061\n",
      "val Loss: 0.0365\n",
      "val MAE: 2739.5765\n",
      "\n",
      "Epoch 23/100\n",
      "----------\n",
      "train Loss: 0.0344\n",
      "train MAE: 2751.9073\n",
      "val Loss: 0.0344\n",
      "val MAE: 2673.9849\n",
      "\n",
      "Epoch 24/100\n",
      "----------\n",
      "train Loss: 0.0348\n",
      "train MAE: 2783.5536\n",
      "val Loss: 0.0356\n",
      "val MAE: 2728.8769\n",
      "\n",
      "Epoch 25/100\n",
      "----------\n",
      "train Loss: 0.0342\n",
      "train MAE: 2741.8037\n",
      "val Loss: 0.0345\n",
      "val MAE: 2657.4644\n",
      "\n",
      "Epoch 26/100\n",
      "----------\n",
      "train Loss: 0.0328\n",
      "train MAE: 2695.4003\n",
      "val Loss: 0.0342\n",
      "val MAE: 2653.6981\n",
      "\n",
      "Epoch 27/100\n",
      "----------\n",
      "train Loss: 0.0330\n",
      "train MAE: 2717.6150\n",
      "val Loss: 0.0350\n",
      "val MAE: 2683.3764\n",
      "\n",
      "Epoch 28/100\n",
      "----------\n",
      "train Loss: 0.0340\n",
      "train MAE: 2746.2575\n",
      "val Loss: 0.0344\n",
      "val MAE: 2667.5832\n",
      "\n",
      "Epoch 29/100\n",
      "----------\n",
      "train Loss: 0.0340\n",
      "train MAE: 2735.4735\n",
      "val Loss: 0.0336\n",
      "val MAE: 2653.1477\n",
      "\n",
      "Epoch 30/100\n",
      "----------\n",
      "train Loss: 0.0330\n",
      "train MAE: 2712.4969\n",
      "val Loss: 0.0347\n",
      "val MAE: 2687.2118\n",
      "\n",
      "Epoch 31/100\n",
      "----------\n",
      "train Loss: 0.0334\n",
      "train MAE: 2723.9461\n",
      "val Loss: 0.0346\n",
      "val MAE: 2677.7629\n",
      "\n",
      "Epoch 32/100\n",
      "----------\n",
      "train Loss: 0.0346\n",
      "train MAE: 2786.8078\n",
      "val Loss: 0.0349\n",
      "val MAE: 2682.5758\n",
      "\n",
      "Epoch 33/100\n",
      "----------\n",
      "train Loss: 0.0328\n",
      "train MAE: 2668.0054\n",
      "val Loss: 0.0348\n",
      "val MAE: 2660.8653\n",
      "\n",
      "Epoch 34/100\n",
      "----------\n",
      "train Loss: 0.0330\n",
      "train MAE: 2688.3227\n",
      "val Loss: 0.0356\n",
      "val MAE: 2706.7738\n",
      "\n",
      "Epoch 35/100\n",
      "----------\n",
      "train Loss: 0.0336\n",
      "train MAE: 2712.8933\n",
      "val Loss: 0.0344\n",
      "val MAE: 2655.8732\n",
      "\n",
      "Epoch 36/100\n",
      "----------\n",
      "train Loss: 0.0344\n",
      "train MAE: 2765.0552\n",
      "val Loss: 0.0351\n",
      "val MAE: 2693.4900\n",
      "\n",
      "Epoch 37/100\n",
      "----------\n",
      "train Loss: 0.0328\n",
      "train MAE: 2678.1655\n",
      "val Loss: 0.0349\n",
      "val MAE: 2706.1626\n",
      "\n",
      "Epoch 38/100\n",
      "----------\n",
      "train Loss: 0.0329\n",
      "train MAE: 2696.8809\n",
      "val Loss: 0.0343\n",
      "val MAE: 2638.4348\n",
      "\n",
      "Epoch 39/100\n",
      "----------\n",
      "train Loss: 0.0323\n",
      "train MAE: 2653.2225\n",
      "val Loss: 0.0345\n",
      "val MAE: 2673.2719\n",
      "\n",
      "Epoch 40/100\n",
      "----------\n",
      "train Loss: 0.0320\n",
      "train MAE: 2660.6567\n",
      "val Loss: 0.0343\n",
      "val MAE: 2645.2753\n",
      "\n",
      "Epoch 41/100\n",
      "----------\n",
      "train Loss: 0.0328\n",
      "train MAE: 2702.6681\n",
      "val Loss: 0.0349\n",
      "val MAE: 2692.3750\n",
      "\n",
      "Epoch 42/100\n",
      "----------\n",
      "train Loss: 0.0326\n",
      "train MAE: 2697.0061\n",
      "val Loss: 0.0338\n",
      "val MAE: 2641.3365\n",
      "\n",
      "Epoch 43/100\n",
      "----------\n",
      "train Loss: 0.0334\n",
      "train MAE: 2680.1482\n",
      "val Loss: 0.0348\n",
      "val MAE: 2677.4783\n",
      "\n",
      "Epoch 44/100\n",
      "----------\n",
      "train Loss: 0.0324\n",
      "train MAE: 2704.2999\n",
      "val Loss: 0.0343\n",
      "val MAE: 2642.0534\n",
      "\n",
      "Epoch 45/100\n",
      "----------\n",
      "train Loss: 0.0313\n",
      "train MAE: 2637.3619\n",
      "val Loss: 0.0350\n",
      "val MAE: 2678.1430\n",
      "\n",
      "Epoch 46/100\n",
      "----------\n",
      "train Loss: 0.0314\n",
      "train MAE: 2624.1387\n",
      "val Loss: 0.0354\n",
      "val MAE: 2702.2573\n",
      "\n",
      "Epoch 47/100\n",
      "----------\n",
      "train Loss: 0.0331\n",
      "train MAE: 2688.8947\n",
      "val Loss: 0.0352\n",
      "val MAE: 2678.3247\n",
      "\n",
      "Epoch 48/100\n",
      "----------\n",
      "train Loss: 0.0315\n",
      "train MAE: 2634.3663\n",
      "val Loss: 0.0345\n",
      "val MAE: 2666.4842\n",
      "\n",
      "Epoch 49/100\n",
      "----------\n",
      "train Loss: 0.0325\n",
      "train MAE: 2667.5021\n",
      "val Loss: 0.0352\n",
      "val MAE: 2680.9959\n",
      "\n",
      "Epoch 50/100\n",
      "----------\n",
      "train Loss: 0.0332\n",
      "train MAE: 2713.1853\n",
      "val Loss: 0.0352\n",
      "val MAE: 2696.6155\n",
      "\n",
      "Epoch 51/100\n",
      "----------\n",
      "train Loss: 0.0320\n",
      "train MAE: 2689.5617\n",
      "val Loss: 0.0350\n",
      "val MAE: 2686.0608\n",
      "\n",
      "Epoch 52/100\n",
      "----------\n",
      "train Loss: 0.0331\n",
      "train MAE: 2687.7868\n",
      "val Loss: 0.0356\n",
      "val MAE: 2705.8495\n",
      "\n",
      "Epoch 53/100\n",
      "----------\n",
      "train Loss: 0.0315\n",
      "train MAE: 2643.5641\n",
      "val Loss: 0.0347\n",
      "val MAE: 2675.4309\n",
      "\n",
      "Epoch 54/100\n",
      "----------\n",
      "train Loss: 0.0324\n",
      "train MAE: 2664.8002\n",
      "val Loss: 0.0343\n",
      "val MAE: 2647.0702\n",
      "\n",
      "Epoch 55/100\n",
      "----------\n",
      "train Loss: 0.0323\n",
      "train MAE: 2668.6377\n",
      "val Loss: 0.0350\n",
      "val MAE: 2676.1573\n",
      "\n",
      "Epoch 56/100\n",
      "----------\n",
      "train Loss: 0.0333\n",
      "train MAE: 2703.1139\n",
      "val Loss: 0.0345\n",
      "val MAE: 2670.5933\n",
      "\n",
      "Epoch 57/100\n",
      "----------\n",
      "train Loss: 0.0337\n",
      "train MAE: 2729.7319\n",
      "val Loss: 0.0339\n",
      "val MAE: 2634.4360\n",
      "\n",
      "Epoch 58/100\n",
      "----------\n",
      "train Loss: 0.0322\n",
      "train MAE: 2632.5020\n",
      "val Loss: 0.0348\n",
      "val MAE: 2669.9238\n",
      "\n",
      "Epoch 59/100\n",
      "----------\n",
      "train Loss: 0.0314\n",
      "train MAE: 2643.6655\n",
      "val Loss: 0.0349\n",
      "val MAE: 2674.8047\n",
      "\n",
      "Epoch 60/100\n",
      "----------\n",
      "train Loss: 0.0320\n",
      "train MAE: 2643.0757\n",
      "val Loss: 0.0348\n",
      "val MAE: 2702.6414\n",
      "\n",
      "Epoch 61/100\n",
      "----------\n",
      "train Loss: 0.0331\n",
      "train MAE: 2716.1523\n",
      "val Loss: 0.0342\n",
      "val MAE: 2672.2239\n",
      "\n",
      "Epoch 62/100\n",
      "----------\n",
      "train Loss: 0.0334\n",
      "train MAE: 2728.3386\n",
      "val Loss: 0.0355\n",
      "val MAE: 2700.9860\n",
      "\n",
      "Epoch 63/100\n",
      "----------\n",
      "train Loss: 0.0319\n",
      "train MAE: 2655.6602\n",
      "val Loss: 0.0349\n",
      "val MAE: 2675.9402\n",
      "\n",
      "Epoch 64/100\n",
      "----------\n",
      "train Loss: 0.0323\n",
      "train MAE: 2664.7080\n",
      "val Loss: 0.0351\n",
      "val MAE: 2685.7647\n",
      "\n",
      "Epoch 65/100\n",
      "----------\n",
      "train Loss: 0.0324\n",
      "train MAE: 2678.3778\n",
      "val Loss: 0.0349\n",
      "val MAE: 2672.2031\n",
      "\n",
      "Epoch 66/100\n",
      "----------\n",
      "train Loss: 0.0320\n",
      "train MAE: 2651.8503\n",
      "val Loss: 0.0357\n",
      "val MAE: 2699.8619\n",
      "\n",
      "Epoch 67/100\n",
      "----------\n",
      "train Loss: 0.0317\n",
      "train MAE: 2631.3010\n",
      "val Loss: 0.0365\n",
      "val MAE: 2748.1908\n",
      "\n",
      "Epoch 68/100\n",
      "----------\n",
      "train Loss: 0.0326\n",
      "train MAE: 2685.1788\n",
      "val Loss: 0.0345\n",
      "val MAE: 2650.1476\n",
      "\n",
      "Epoch 69/100\n",
      "----------\n",
      "train Loss: 0.0320\n",
      "train MAE: 2615.0857\n",
      "val Loss: 0.0350\n",
      "val MAE: 2649.5162\n",
      "\n",
      "Epoch 70/100\n",
      "----------\n",
      "train Loss: 0.0329\n",
      "train MAE: 2676.4643\n",
      "val Loss: 0.0347\n",
      "val MAE: 2652.5810\n",
      "\n",
      "Epoch 71/100\n",
      "----------\n",
      "train Loss: 0.0336\n",
      "train MAE: 2702.9128\n",
      "val Loss: 0.0347\n",
      "val MAE: 2677.8701\n",
      "\n",
      "Epoch 72/100\n",
      "----------\n",
      "train Loss: 0.0333\n",
      "train MAE: 2694.0808\n",
      "val Loss: 0.0339\n",
      "val MAE: 2628.5525\n",
      "\n",
      "Epoch 73/100\n",
      "----------\n",
      "train Loss: 0.0317\n",
      "train MAE: 2635.8879\n",
      "val Loss: 0.0347\n",
      "val MAE: 2670.9421\n",
      "\n",
      "Epoch 74/100\n",
      "----------\n",
      "train Loss: 0.0338\n",
      "train MAE: 2688.2323\n",
      "val Loss: 0.0343\n",
      "val MAE: 2665.0585\n",
      "\n",
      "Epoch 75/100\n",
      "----------\n",
      "train Loss: 0.0321\n",
      "train MAE: 2670.7933\n",
      "val Loss: 0.0356\n",
      "val MAE: 2723.1203\n",
      "\n",
      "Epoch 76/100\n",
      "----------\n",
      "train Loss: 0.0319\n",
      "train MAE: 2638.2812\n",
      "val Loss: 0.0358\n",
      "val MAE: 2734.7125\n",
      "\n",
      "Epoch 77/100\n",
      "----------\n",
      "train Loss: 0.0324\n",
      "train MAE: 2651.4349\n",
      "val Loss: 0.0344\n",
      "val MAE: 2651.7331\n",
      "\n",
      "Epoch 78/100\n",
      "----------\n",
      "train Loss: 0.0321\n",
      "train MAE: 2671.8947\n",
      "val Loss: 0.0354\n",
      "val MAE: 2679.0112\n",
      "\n",
      "Epoch 79/100\n",
      "----------\n",
      "train Loss: 0.0332\n",
      "train MAE: 2691.0697\n",
      "val Loss: 0.0349\n",
      "val MAE: 2677.3388\n",
      "\n",
      "Epoch 80/100\n",
      "----------\n",
      "train Loss: 0.0324\n",
      "train MAE: 2660.3872\n",
      "val Loss: 0.0347\n",
      "val MAE: 2680.0119\n",
      "\n",
      "Epoch 81/100\n",
      "----------\n",
      "train Loss: 0.0334\n",
      "train MAE: 2711.0986\n",
      "val Loss: 0.0341\n",
      "val MAE: 2643.7448\n",
      "\n",
      "Epoch 82/100\n",
      "----------\n",
      "train Loss: 0.0317\n",
      "train MAE: 2651.0040\n",
      "val Loss: 0.0341\n",
      "val MAE: 2667.2457\n",
      "\n",
      "Epoch 83/100\n",
      "----------\n",
      "train Loss: 0.0328\n",
      "train MAE: 2707.2175\n",
      "val Loss: 0.0344\n",
      "val MAE: 2676.5569\n",
      "\n",
      "Epoch 84/100\n",
      "----------\n",
      "train Loss: 0.0334\n",
      "train MAE: 2719.2905\n",
      "val Loss: 0.0347\n",
      "val MAE: 2681.7101\n",
      "\n",
      "Epoch 85/100\n",
      "----------\n",
      "train Loss: 0.0320\n",
      "train MAE: 2645.7816\n",
      "val Loss: 0.0352\n",
      "val MAE: 2694.8779\n",
      "\n",
      "Epoch 86/100\n",
      "----------\n",
      "train Loss: 0.0343\n",
      "train MAE: 2745.8206\n",
      "val Loss: 0.0346\n",
      "val MAE: 2674.0819\n",
      "\n",
      "Epoch 87/100\n",
      "----------\n",
      "train Loss: 0.0335\n",
      "train MAE: 2717.8172\n",
      "val Loss: 0.0344\n",
      "val MAE: 2674.2245\n",
      "\n",
      "Epoch 88/100\n",
      "----------\n",
      "train Loss: 0.0319\n",
      "train MAE: 2664.7526\n",
      "val Loss: 0.0341\n",
      "val MAE: 2649.2656\n",
      "\n",
      "Epoch 89/100\n",
      "----------\n",
      "train Loss: 0.0320\n",
      "train MAE: 2646.8137\n",
      "val Loss: 0.0344\n",
      "val MAE: 2661.1062\n",
      "\n",
      "Epoch 90/100\n",
      "----------\n",
      "train Loss: 0.0334\n",
      "train MAE: 2701.9661\n",
      "val Loss: 0.0354\n",
      "val MAE: 2696.1975\n",
      "\n",
      "Epoch 91/100\n",
      "----------\n",
      "train Loss: 0.0320\n",
      "train MAE: 2626.7126\n",
      "val Loss: 0.0340\n",
      "val MAE: 2653.5557\n",
      "\n",
      "Epoch 92/100\n",
      "----------\n",
      "train Loss: 0.0322\n",
      "train MAE: 2651.5593\n",
      "val Loss: 0.0346\n",
      "val MAE: 2681.4815\n",
      "\n",
      "Epoch 93/100\n",
      "----------\n",
      "train Loss: 0.0315\n",
      "train MAE: 2630.4575\n",
      "val Loss: 0.0337\n",
      "val MAE: 2639.7002\n",
      "\n",
      "Epoch 94/100\n",
      "----------\n",
      "train Loss: 0.0324\n",
      "train MAE: 2659.1295\n",
      "val Loss: 0.0343\n",
      "val MAE: 2657.3104\n",
      "\n",
      "Epoch 95/100\n",
      "----------\n",
      "train Loss: 0.0329\n",
      "train MAE: 2699.4339\n",
      "val Loss: 0.0348\n",
      "val MAE: 2669.0271\n",
      "\n",
      "Epoch 96/100\n",
      "----------\n",
      "train Loss: 0.0324\n",
      "train MAE: 2653.9901\n",
      "val Loss: 0.0347\n",
      "val MAE: 2666.7131\n",
      "\n",
      "Epoch 97/100\n",
      "----------\n",
      "train Loss: 0.0324\n",
      "train MAE: 2673.7340\n",
      "val Loss: 0.0341\n",
      "val MAE: 2651.6321\n",
      "\n",
      "Epoch 98/100\n",
      "----------\n",
      "train Loss: 0.0327\n",
      "train MAE: 2679.6064\n",
      "val Loss: 0.0347\n",
      "val MAE: 2674.3414\n",
      "\n",
      "Epoch 99/100\n",
      "----------\n",
      "train Loss: 0.0319\n",
      "train MAE: 2663.9255\n",
      "val Loss: 0.0342\n",
      "val MAE: 2637.2449\n",
      "\n",
      "Epoch 100/100\n",
      "----------\n",
      "train Loss: 0.0325\n",
      "train MAE: 2664.8255\n",
      "val Loss: 0.0356\n",
      "val MAE: 2719.9606\n",
      "\n",
      "Training complete in 127m 28s\n",
      "Best val Loss: 0.033620 at epoch 29\n",
      "Best val MAE: 2653.147727 at epoch 29\n",
      "\n",
      "Load the model weights at the best epoch\n"
     ]
    }
   ],
   "source": [
    "model_res152, mae_list_6 = train_model(model_ft, model_LU, criterion, optimizer_ft, exp_lr_scheduler, num_epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Residual Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(mae_list_6, bins=50, density=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2653.148, 2005.1562, 1850)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(mae_list_6), np.median(mae_list_6), len(mae_list_6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86.32%\n"
     ]
    }
   ],
   "source": [
    "thres = 5000\n",
    "print(\"%.2f%%\" % (sum(np.array(mae_list_6) < thres) / len(mae_list_6) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_env",
   "language": "python",
   "name": "torch_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
