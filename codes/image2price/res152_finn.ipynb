{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models, utils\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from PIL import Image\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabular_data = \"../../data/SkidSteer_2019-08.csv\"\n",
    "color = pd.read_csv('../colorfulness/skid_steer_color_score.csv')\n",
    "\n",
    "df = pd.read_csv(tabular_data, index_col=1)\n",
    "df['Unique_ID'] = df[['Source','item#']].apply(lambda x: '_'.join(x),axis = 1)\n",
    "df = df.filter(['Unique_ID','Winning Bid','Hours Final','Age at Sale (bin)','Bucket','Engine','Tires','Transmission'], axis = 1)\n",
    "df = pd.merge(df, color,on='Unique_ID',how='inner')\n",
    "df = df.rename(columns={\n",
    "    'Unique_ID': \"unique_id\",\n",
    "    'Hours Final': \"hours_final\",\n",
    "    'Winning Bid': \"winning_bid\",\n",
    "    'Age at Sale (bin)': \"age_at_sale\",\n",
    "    'Bucket': \"bucket\",\n",
    "    'Engine': \"engine\",\n",
    "    'Tires': \"tires\",\n",
    "    'Transmission': \"transmission\", \n",
    "    'socre': \"colorfulness_score\"\n",
    "})\n",
    "# color = pd.read_csv('skid_steer_color_score.csv')\n",
    "# final_df = pd.merge(new_df, color,on='Unique_ID',how='inner')\n",
    "\n",
    "\n",
    "### removal\n",
    "# remove duplicant\n",
    "duplicated_item = [item for item, count in Counter(df[\"unique_id\"]).items() if count > 1]\n",
    "df = df[~df['unique_id'].isin(duplicated_item)]\n",
    "\n",
    "# remove not matched rows\n",
    "image_item = [img_name.strip(\".jpg\") for img_name in os.listdir(\"../../data/images/\")]\n",
    "df = df[df[\"unique_id\"].isin(image_item)]\n",
    "\n",
    "# remove comma\n",
    "df[\"winning_bid\"] = df[\"winning_bid\"].str.replace(',', '').astype(int)\n",
    "\n",
    "# remove special image\n",
    "df = df[df['unique_id'] != \"rbauction_10525632\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### winning_bid\n",
    "\n",
    "# log-transform\n",
    "df[\"winning_bid\"] = np.log(df[\"winning_bid\"])\n",
    "\n",
    "# min max scale\n",
    "mm_scaler_price = preprocessing.MinMaxScaler((-1, 1))\n",
    "df[\"winning_bid\"] = mm_scaler_price.fit_transform(df[\"winning_bid\"].to_numpy().reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### hours_final\n",
    "\n",
    "# impute nan with median and new binary indicator\n",
    "df[\"hours_final\"] = df[\"hours_final\"].str.replace(\",\", \"\")\n",
    "df[\"hours_final\"] = df[\"hours_final\"].astype(float)\n",
    "df.insert(3, column=\"hours_final_nan\", value=df[\"hours_final\"].isna().astype(int))\n",
    "df.loc[df[\"hours_final\"].isna(), \"hours_final\"] = df[\"hours_final\"].median(skipna=True)\n",
    "\n",
    "# log transform\n",
    "df[\"hours_final\"] = np.log(df[\"hours_final\"])\n",
    "\n",
    "# normalize\n",
    "rb_scaler_hour = preprocessing.RobustScaler()\n",
    "df[\"hours_final\"] = rb_scaler_hour.fit_transform(np.array(df[\"hours_final\"]).reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### age_at_sale\n",
    "\n",
    "# impute nan with median and new binary indicator\n",
    "df[\"age_at_sale\"] = df[\"age_at_sale\"].astype(float)\n",
    "df.insert(5, column=\"age_at_sale_nan\", value=df[\"age_at_sale\"].isna().astype(int))\n",
    "df.loc[df[\"age_at_sale\"].isna(), \"age_at_sale\"] = df[\"age_at_sale\"].median(skipna=True)\n",
    "\n",
    "# normalize\n",
    "rb_scaler_age = preprocessing.RobustScaler()\n",
    "df[\"age_at_sale\"] = rb_scaler_age.fit_transform(np.array(df[\"age_at_sale\"]).reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "### bucket\n",
    "df.insert(7, column=\"bucket_bin\", value=0)\n",
    "df.loc[\n",
    "    ~df[\"bucket\"].isna() & \n",
    "    df[\"bucket\"].str.contains(\"bucket\", case=False) | \n",
    "    df[\"bucket\"].str.contains(\"bkt\", case=False), \"bucket_bin\"\n",
    "] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle and split\n",
    "np.random.seed(1)\n",
    "split = [0.7, 0.3]\n",
    "split0 = round(df.shape[0] * split[0])\n",
    "# split1 = round(df.shape[0] * (split[0] + split[1]))\n",
    "df = df.sample(frac=1)\n",
    "df_train = df.iloc[:split0]\n",
    "df_val = df.iloc[split0:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_id</th>\n",
       "      <th>winning_bid</th>\n",
       "      <th>hours_final</th>\n",
       "      <th>hours_final_nan</th>\n",
       "      <th>age_at_sale</th>\n",
       "      <th>age_at_sale_nan</th>\n",
       "      <th>bucket</th>\n",
       "      <th>bucket_bin</th>\n",
       "      <th>engine</th>\n",
       "      <th>tires</th>\n",
       "      <th>transmission</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5364</th>\n",
       "      <td>ironplanet_1703726</td>\n",
       "      <td>0.105406</td>\n",
       "      <td>-6.732824</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.666667</td>\n",
       "      <td>0</td>\n",
       "      <td>74\" Wide General Purpose Smooth Edge Bucket</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cushion Tires</td>\n",
       "      <td>NaN</td>\n",
       "      <td>45.382919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3191</th>\n",
       "      <td>PW_DD1289</td>\n",
       "      <td>0.172815</td>\n",
       "      <td>-1.629216</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>Kubota 68\"W bucket</td>\n",
       "      <td>1</td>\n",
       "      <td>Kubota V3307-CR four cylinder turbo diesel engine</td>\n",
       "      <td>Titan 12-16.5 NHS tires</td>\n",
       "      <td>Two speed hydrostatic transmission</td>\n",
       "      <td>55.968483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5495</th>\n",
       "      <td>rbauction_10239624</td>\n",
       "      <td>0.219707</td>\n",
       "      <td>-0.164164</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.666667</td>\n",
       "      <td>0</td>\n",
       "      <td>hyd Q/C bkt</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35.573711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2563</th>\n",
       "      <td>PW_H1380</td>\n",
       "      <td>-0.072566</td>\n",
       "      <td>-0.769452</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>80\"W bucket</td>\n",
       "      <td>1</td>\n",
       "      <td>81 HP, Case 3.2L four cylinder turbo diesel en...</td>\n",
       "      <td>12-16.5 tires</td>\n",
       "      <td>Hydrostatic transmission</td>\n",
       "      <td>38.453826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2883</th>\n",
       "      <td>PW_J8873</td>\n",
       "      <td>-0.305592</td>\n",
       "      <td>-0.416323</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>John Deere 5030TT001 3.0L turbo diesel engine</td>\n",
       "      <td>12-16.5 tires</td>\n",
       "      <td>Two speed hydrostatic transmission</td>\n",
       "      <td>72.305753</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               unique_id  winning_bid  hours_final  hours_final_nan  \\\n",
       "5364  ironplanet_1703726     0.105406    -6.732824                0   \n",
       "3191           PW_DD1289     0.172815    -1.629216                0   \n",
       "5495  rbauction_10239624     0.219707    -0.164164                0   \n",
       "2563            PW_H1380    -0.072566    -0.769452                0   \n",
       "2883            PW_J8873    -0.305592    -0.416323                0   \n",
       "\n",
       "      age_at_sale  age_at_sale_nan  \\\n",
       "5364    -0.666667                0   \n",
       "3191    -1.000000                0   \n",
       "5495    -0.666667                0   \n",
       "2563    -0.333333                0   \n",
       "2883    -0.333333                0   \n",
       "\n",
       "                                           bucket  bucket_bin  \\\n",
       "5364  74\" Wide General Purpose Smooth Edge Bucket           1   \n",
       "3191                           Kubota 68\"W bucket           1   \n",
       "5495                                  hyd Q/C bkt           1   \n",
       "2563                                  80\"W bucket           1   \n",
       "2883                                          NaN           0   \n",
       "\n",
       "                                                 engine  \\\n",
       "5364                                                NaN   \n",
       "3191  Kubota V3307-CR four cylinder turbo diesel engine   \n",
       "5495                                                NaN   \n",
       "2563  81 HP, Case 3.2L four cylinder turbo diesel en...   \n",
       "2883      John Deere 5030TT001 3.0L turbo diesel engine   \n",
       "\n",
       "                        tires                        transmission      score  \n",
       "5364            Cushion Tires                                 NaN  45.382919  \n",
       "3191  Titan 12-16.5 NHS tires  Two speed hydrostatic transmission  55.968483  \n",
       "5495                      NaN                                 NaN  35.573711  \n",
       "2563            12-16.5 tires            Hydrostatic transmission  38.453826  \n",
       "2883            12-16.5 tires  Two speed hydrostatic transmission  72.305753  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_id</th>\n",
       "      <th>winning_bid</th>\n",
       "      <th>hours_final</th>\n",
       "      <th>hours_final_nan</th>\n",
       "      <th>age_at_sale</th>\n",
       "      <th>age_at_sale_nan</th>\n",
       "      <th>bucket</th>\n",
       "      <th>bucket_bin</th>\n",
       "      <th>engine</th>\n",
       "      <th>tires</th>\n",
       "      <th>transmission</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4563</th>\n",
       "      <td>bigiron_EN9531</td>\n",
       "      <td>0.164709</td>\n",
       "      <td>-0.503074</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>84\" Bucket</td>\n",
       "      <td>1</td>\n",
       "      <td>4-Cyl Turbo Diesel Engine, 84 Hp</td>\n",
       "      <td>Some Tires Have Cuts (Pictured), Tires- 14-17....</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.801346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>972</th>\n",
       "      <td>rbauction_10693873</td>\n",
       "      <td>-0.861828</td>\n",
       "      <td>-0.443163</td>\n",
       "      <td>0</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>bkt</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.575992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4915</th>\n",
       "      <td>bigiron_BO0203</td>\n",
       "      <td>-0.180158</td>\n",
       "      <td>-0.226316</td>\n",
       "      <td>0</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>Buckets 12\", 64\" Bucket</td>\n",
       "      <td>1</td>\n",
       "      <td>58 Horse Power Isuzu Diesel Engine</td>\n",
       "      <td>12-16.5 Tires, Spare Tire And Rim</td>\n",
       "      <td>Hydrostat Transmission</td>\n",
       "      <td>19.348823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5351</th>\n",
       "      <td>ironplanet_1891010</td>\n",
       "      <td>-0.402470</td>\n",
       "      <td>-6.732824</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>72\" Wide General Purpose Smooth Edge Bucket</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>59.205629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2819</th>\n",
       "      <td>PW_J2936</td>\n",
       "      <td>-0.402470</td>\n",
       "      <td>-1.926828</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Case four cylinder turbo diesel engine, Non-op...</td>\n",
       "      <td>12-16.5 tires</td>\n",
       "      <td>Hydrostatic transmission</td>\n",
       "      <td>27.390935</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               unique_id  winning_bid  hours_final  hours_final_nan  \\\n",
       "4563      bigiron_EN9531     0.164709    -0.503074                0   \n",
       "972   rbauction_10693873    -0.861828    -0.443163                0   \n",
       "4915      bigiron_BO0203    -0.180158    -0.226316                0   \n",
       "5351  ironplanet_1891010    -0.402470    -6.732824                0   \n",
       "2819            PW_J2936    -0.402470    -1.926828                0   \n",
       "\n",
       "      age_at_sale  age_at_sale_nan  \\\n",
       "4563    -0.333333                0   \n",
       "972      1.333333                0   \n",
       "4915     1.333333                0   \n",
       "5351    -0.333333                0   \n",
       "2819    -0.333333                0   \n",
       "\n",
       "                                           bucket  bucket_bin  \\\n",
       "4563                                   84\" Bucket           1   \n",
       "972                                           bkt           1   \n",
       "4915                      Buckets 12\", 64\" Bucket           1   \n",
       "5351  72\" Wide General Purpose Smooth Edge Bucket           1   \n",
       "2819                                          NaN           0   \n",
       "\n",
       "                                                 engine  \\\n",
       "4563                   4-Cyl Turbo Diesel Engine, 84 Hp   \n",
       "972                                                 NaN   \n",
       "4915                 58 Horse Power Isuzu Diesel Engine   \n",
       "5351                                                NaN   \n",
       "2819  Case four cylinder turbo diesel engine, Non-op...   \n",
       "\n",
       "                                                  tires  \\\n",
       "4563  Some Tires Have Cuts (Pictured), Tires- 14-17....   \n",
       "972                                                 NaN   \n",
       "4915                  12-16.5 Tires, Spare Tire And Rim   \n",
       "5351                                                NaN   \n",
       "2819                                      12-16.5 tires   \n",
       "\n",
       "                  transmission      score  \n",
       "4563                       NaN  40.801346  \n",
       "972                        NaN  19.575992  \n",
       "4915    Hydrostat Transmission  19.348823  \n",
       "5351                       NaN  59.205629  \n",
       "2819  Hydrostatic transmission  27.390935  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_val.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.to_csv(\"./SkidSteer_2019-08_clean_train.csv\")\n",
    "df_val.to_csv(\"./SkidSteer_2019-08_clean_val.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class skidsteer_dataset(Dataset):\n",
    "    \"\"\"Corrosion Detection dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, \n",
    "                 csv_file, \n",
    "                 img_root, \n",
    "                 transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the csv file with annotations.\n",
    "            img_root (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied on a sample (including augmentation).\n",
    "        \"\"\"\n",
    "        self.csv_file = pd.read_csv(csv_file, index_col=0)\n",
    "        self.img_root = img_root\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.csv_file)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        '''Return one data point with a PIL image and its label.'''\n",
    "        img_dir = os.path.join(self.img_root, self.csv_file.iloc[idx, 0]) + \".jpg\"\n",
    "        price = self.csv_file.iloc[idx, 1]\n",
    "        image = Image.open(img_dir)\n",
    "        others = torch.tensor(self.csv_file.iloc[idx, [2, 3, 4, 5, 7, 11]])  # change this when new columns are added\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        sample = {'image': image, 'price': price, \"others\": others}\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm2price(tensor, min_max_scaler):\n",
    "    array2d = tensor.to(\"cpu\").data.numpy().reshape(-1, 1)\n",
    "    return np.exp(min_max_scaler.inverse_transform(array2d))\n",
    "\n",
    "def price_MAE(outputs, prices, min_max_scaler):\n",
    "    outputs = norm2price(outputs, min_max_scaler)\n",
    "    prices = norm2price(prices, min_max_scaler)\n",
    "    mae = np.abs(outputs - prices)\n",
    "    maep = np.abs(outputs - prices) / prices\n",
    "    return mae.mean(), mae, maep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, model_LU, criterion, optimizer, scheduler, num_epochs=25):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_epoch = None\n",
    "    best_loss = float(\"Inf\")\n",
    "    best_mae = float(\"Inf\")\n",
    "    best_mae_list = None\n",
    "    best_maep_list = None\n",
    "    all_loss = {x: [] for x in ['train', 'val']}\n",
    "    all_mae = {x: [] for x in ['train', 'val']}\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch + 1, num_epochs))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "            running_loss = 0.0\n",
    "            running_mae = 0.0\n",
    "            running_mae_list = []\n",
    "            running_maep_list = []\n",
    "            \n",
    "            # Iterate over data.\n",
    "            for items in dataloaders[phase]:\n",
    "                images = items[\"image\"].to(device)\n",
    "                prices = items[\"price\"].to(device)\n",
    "                others = items[\"others\"].to(device)\n",
    "                optimizer.zero_grad()\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = cat_net(model, model_LU, images, others).squeeze()\n",
    "                    loss = criterion(outputs, prices)\n",
    "                    mae, mae_np, maep_np = price_MAE(outputs, prices, mm_scaler_price)\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                running_loss += loss.item() * images.size(0)\n",
    "                running_mae += mae * images.size(0)\n",
    "                running_mae_list += list(mae_np.flatten())\n",
    "                running_maep_list += list(maep_np.flatten())\n",
    "            if phase == 'train':\n",
    "                scheduler.step(running_mae)\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_mae = running_mae / dataset_sizes[phase]\n",
    "            all_loss[phase].append(epoch_loss)\n",
    "            all_mae[phase].append(epoch_mae)\n",
    "            print('{} Loss: {:.4f}'.format(phase, epoch_loss))\n",
    "            print('{} MAE: {:.4f}'.format(phase, epoch_mae))\n",
    "            \n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_loss < best_loss:\n",
    "                best_epoch = epoch + 1\n",
    "                best_loss = epoch_loss\n",
    "                best_mae = epoch_mae\n",
    "                best_mae_list = running_mae_list\n",
    "                best_maep_list = running_maep_list\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Loss: {:4f} at epoch {}'.format(best_loss, best_epoch))\n",
    "    print('Best val MAE: {:4f} at epoch {}'.format(best_mae, best_epoch))\n",
    "\n",
    "    # load best model weights\n",
    "    print(\"\\nLoad the model weights at the best epoch\")\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, best_mae_list, all_loss, all_mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV_FILE = {\"train\": \"./SkidSteer_2019-08_clean_train.csv\",\n",
    "            \"val\": \"./SkidSteer_2019-08_clean_val.csv\"}\n",
    "IMG_ROOT = \"../../data/images/\"\n",
    "TRANSFORM = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "datasets = {x: skidsteer_dataset(csv_file=CSV_FILE[x],\n",
    "                                 img_root=IMG_ROOT,\n",
    "                                 transform=TRANSFORM[x])\n",
    "            for x in [\"train\", \"val\"]}\n",
    "dataloaders = {x: DataLoader(datasets[x], \n",
    "                             batch_size=16, \n",
    "                             shuffle=True, \n",
    "                             num_workers=4)\n",
    "               for x in [\"train\", \"val\"]}\n",
    "dataset_sizes = {x: len(datasets[x]) for x in [\"train\", \"val\"]}\n",
    "num_tabular_features = len(datasets[\"train\"][0][\"others\"])\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cat_net(model, model_LU, images, others):\n",
    "    z = torch.cat((model(images), others), dim=1)\n",
    "    return model_LU(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. (2053, 32, 1) + Tanh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "### ResNet18\n",
    "model_ft = models.resnet152(pretrained=True)\n",
    "num_ftrs = model_ft.fc.in_features\n",
    "model_ft.fc = nn.Identity()\n",
    "\n",
    "### Freeze and Fine Tuning\n",
    "for param in model_ft.parameters():\n",
    "    param.requires_grad = False\n",
    "for param in model_ft.layer3.parameters():\n",
    "    param.requires_grad = True\n",
    "for param in model_ft.layer4.parameters():\n",
    "    param.requires_grad = True\n",
    "assert [param.requires_grad for param in model_ft.parameters()][-1]\n",
    "\n",
    "### LU\n",
    "model_LU = nn.Sequential(\n",
    "    nn.Linear(num_ftrs + num_tabular_features, 32),\n",
    "    nn.Tanh(),\n",
    "    nn.Linear(32, 1)\n",
    ")\n",
    "\n",
    "### model setup\n",
    "model_ft = model_ft.to(device)\n",
    "model_LU = model_LU.to(device)\n",
    "criterion = nn.MSELoss()\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.SGD(list(model_ft.parameters())+list(model_LU.parameters()), lr=0.001, momentum=0.9)\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=20, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "----------\n",
      "train Loss: 0.0920\n",
      "train MAE: 4535.1636\n",
      "val Loss: 0.0523\n",
      "val MAE: 3356.4828\n",
      "\n",
      "Epoch 2/100\n",
      "----------\n",
      "train Loss: 0.0679\n",
      "train MAE: 3891.4323\n",
      "val Loss: 0.0478\n",
      "val MAE: 3215.8706\n",
      "\n",
      "Epoch 3/100\n",
      "----------\n",
      "train Loss: 0.0594\n",
      "train MAE: 3630.5844\n",
      "val Loss: 0.0431\n",
      "val MAE: 3053.4833\n",
      "\n",
      "Epoch 4/100\n",
      "----------\n",
      "train Loss: 0.0560\n",
      "train MAE: 3548.3563\n",
      "val Loss: 0.0595\n",
      "val MAE: 3654.5581\n",
      "\n",
      "Epoch 5/100\n",
      "----------\n",
      "train Loss: 0.0537\n",
      "train MAE: 3471.5338\n",
      "val Loss: 0.0413\n",
      "val MAE: 2977.5897\n",
      "\n",
      "Epoch 6/100\n",
      "----------\n",
      "train Loss: 0.0490\n",
      "train MAE: 3301.3261\n",
      "val Loss: 0.0452\n",
      "val MAE: 3130.2727\n",
      "\n",
      "Epoch 7/100\n",
      "----------\n",
      "train Loss: 0.0492\n",
      "train MAE: 3297.2635\n",
      "val Loss: 0.0726\n",
      "val MAE: 4219.8945\n",
      "\n",
      "Epoch 8/100\n",
      "----------\n",
      "train Loss: 0.0473\n",
      "train MAE: 3263.9279\n",
      "val Loss: 0.0402\n",
      "val MAE: 2901.6929\n",
      "\n",
      "Epoch 9/100\n",
      "----------\n",
      "train Loss: 0.0468\n",
      "train MAE: 3229.3841\n",
      "val Loss: 0.0454\n",
      "val MAE: 3134.3024\n",
      "\n",
      "Epoch 10/100\n",
      "----------\n",
      "train Loss: 0.0453\n",
      "train MAE: 3166.4574\n",
      "val Loss: 0.0379\n",
      "val MAE: 2834.4005\n",
      "\n",
      "Epoch 11/100\n",
      "----------\n",
      "train Loss: 0.0446\n",
      "train MAE: 3141.4203\n",
      "val Loss: 0.0366\n",
      "val MAE: 2792.8255\n",
      "\n",
      "Epoch 12/100\n",
      "----------\n",
      "train Loss: 0.0431\n",
      "train MAE: 3102.5211\n",
      "val Loss: 0.0369\n",
      "val MAE: 2793.2875\n",
      "\n",
      "Epoch 13/100\n",
      "----------\n",
      "train Loss: 0.0428\n",
      "train MAE: 3083.8046\n",
      "val Loss: 0.0383\n",
      "val MAE: 2867.7762\n",
      "\n",
      "Epoch 14/100\n",
      "----------\n",
      "train Loss: 0.0411\n",
      "train MAE: 3048.8434\n",
      "val Loss: 0.0365\n",
      "val MAE: 2773.5023\n",
      "\n",
      "Epoch 15/100\n",
      "----------\n",
      "train Loss: 0.0390\n",
      "train MAE: 2911.9907\n",
      "val Loss: 0.0370\n",
      "val MAE: 2808.8850\n",
      "\n",
      "Epoch 16/100\n",
      "----------\n",
      "train Loss: 0.0401\n",
      "train MAE: 2989.0715\n",
      "val Loss: 0.0378\n",
      "val MAE: 2818.9127\n",
      "\n",
      "Epoch 17/100\n",
      "----------\n",
      "train Loss: 0.0384\n",
      "train MAE: 2905.3729\n",
      "val Loss: 0.0354\n",
      "val MAE: 2727.4580\n",
      "\n",
      "Epoch 18/100\n",
      "----------\n",
      "train Loss: 0.0370\n",
      "train MAE: 2876.3621\n",
      "val Loss: 0.0360\n",
      "val MAE: 2741.9648\n",
      "\n",
      "Epoch 19/100\n",
      "----------\n",
      "train Loss: 0.0379\n",
      "train MAE: 2908.9010\n",
      "val Loss: 0.0379\n",
      "val MAE: 2843.5678\n",
      "\n",
      "Epoch 20/100\n",
      "----------\n",
      "train Loss: 0.0371\n",
      "train MAE: 2857.6082\n",
      "val Loss: 0.0382\n",
      "val MAE: 2828.7524\n",
      "\n",
      "Epoch 21/100\n",
      "----------\n",
      "train Loss: 0.0341\n",
      "train MAE: 2733.7896\n",
      "val Loss: 0.0345\n",
      "val MAE: 2699.5970\n",
      "\n",
      "Epoch 22/100\n",
      "----------\n",
      "train Loss: 0.0329\n",
      "train MAE: 2696.5154\n",
      "val Loss: 0.0341\n",
      "val MAE: 2685.9898\n",
      "\n",
      "Epoch 23/100\n",
      "----------\n",
      "train Loss: 0.0342\n",
      "train MAE: 2742.5187\n",
      "val Loss: 0.0342\n",
      "val MAE: 2687.6264\n",
      "\n",
      "Epoch 24/100\n",
      "----------\n",
      "train Loss: 0.0320\n",
      "train MAE: 2672.3615\n",
      "val Loss: 0.0342\n",
      "val MAE: 2693.6202\n",
      "\n",
      "Epoch 25/100\n",
      "----------\n",
      "train Loss: 0.0329\n",
      "train MAE: 2671.7860\n",
      "val Loss: 0.0344\n",
      "val MAE: 2698.7537\n",
      "\n",
      "Epoch 26/100\n",
      "----------\n",
      "train Loss: 0.0333\n",
      "train MAE: 2698.7503\n",
      "val Loss: 0.0348\n",
      "val MAE: 2711.9934\n",
      "\n",
      "Epoch 27/100\n",
      "----------\n",
      "train Loss: 0.0334\n",
      "train MAE: 2726.5492\n",
      "val Loss: 0.0340\n",
      "val MAE: 2695.7081\n",
      "\n",
      "Epoch 28/100\n",
      "----------\n",
      "train Loss: 0.0332\n",
      "train MAE: 2711.9137\n",
      "val Loss: 0.0346\n",
      "val MAE: 2707.5227\n",
      "\n",
      "Epoch 29/100\n",
      "----------\n",
      "train Loss: 0.0327\n",
      "train MAE: 2684.0695\n",
      "val Loss: 0.0340\n",
      "val MAE: 2687.8101\n",
      "\n",
      "Epoch 30/100\n",
      "----------\n",
      "train Loss: 0.0349\n",
      "train MAE: 2765.9314\n",
      "val Loss: 0.0344\n",
      "val MAE: 2688.9674\n",
      "\n",
      "Epoch 31/100\n",
      "----------\n",
      "train Loss: 0.0311\n",
      "train MAE: 2622.5166\n",
      "val Loss: 0.0340\n",
      "val MAE: 2688.0195\n",
      "\n",
      "Epoch 32/100\n",
      "----------\n",
      "train Loss: 0.0336\n",
      "train MAE: 2692.3874\n",
      "val Loss: 0.0342\n",
      "val MAE: 2695.8098\n",
      "\n",
      "Epoch 33/100\n",
      "----------\n",
      "train Loss: 0.0326\n",
      "train MAE: 2642.1581\n",
      "val Loss: 0.0340\n",
      "val MAE: 2682.4694\n",
      "\n",
      "Epoch 34/100\n",
      "----------\n",
      "train Loss: 0.0326\n",
      "train MAE: 2664.2197\n",
      "val Loss: 0.0347\n",
      "val MAE: 2710.0833\n",
      "\n",
      "Epoch 35/100\n",
      "----------\n",
      "train Loss: 0.0321\n",
      "train MAE: 2662.5512\n",
      "val Loss: 0.0351\n",
      "val MAE: 2717.6223\n",
      "\n",
      "Epoch 36/100\n",
      "----------\n",
      "train Loss: 0.0309\n",
      "train MAE: 2584.2667\n",
      "val Loss: 0.0342\n",
      "val MAE: 2694.0402\n",
      "\n",
      "Epoch 37/100\n",
      "----------\n",
      "train Loss: 0.0322\n",
      "train MAE: 2653.2814\n",
      "val Loss: 0.0355\n",
      "val MAE: 2729.8390\n",
      "\n",
      "Epoch 38/100\n",
      "----------\n",
      "train Loss: 0.0319\n",
      "train MAE: 2660.4865\n",
      "val Loss: 0.0346\n",
      "val MAE: 2704.5252\n",
      "\n",
      "Epoch 39/100\n",
      "----------\n",
      "train Loss: 0.0319\n",
      "train MAE: 2633.9215\n",
      "val Loss: 0.0343\n",
      "val MAE: 2701.0957\n",
      "\n",
      "Epoch 40/100\n",
      "----------\n",
      "train Loss: 0.0321\n",
      "train MAE: 2660.1271\n",
      "val Loss: 0.0351\n",
      "val MAE: 2719.2715\n",
      "\n",
      "Epoch 41/100\n",
      "----------\n",
      "train Loss: 0.0324\n",
      "train MAE: 2668.4604\n",
      "val Loss: 0.0343\n",
      "val MAE: 2687.3431\n",
      "\n",
      "Epoch 42/100\n",
      "----------\n",
      "train Loss: 0.0314\n",
      "train MAE: 2638.6260\n",
      "val Loss: 0.0341\n",
      "val MAE: 2683.3181\n",
      "\n",
      "Epoch 43/100\n",
      "----------\n",
      "train Loss: 0.0320\n",
      "train MAE: 2678.9247\n",
      "val Loss: 0.0340\n",
      "val MAE: 2681.1469\n",
      "\n",
      "Epoch 44/100\n",
      "----------\n",
      "train Loss: 0.0322\n",
      "train MAE: 2658.1074\n",
      "val Loss: 0.0343\n",
      "val MAE: 2685.8423\n",
      "\n",
      "Epoch 45/100\n",
      "----------\n",
      "train Loss: 0.0314\n",
      "train MAE: 2629.3494\n",
      "val Loss: 0.0346\n",
      "val MAE: 2701.1986\n",
      "\n",
      "Epoch 46/100\n",
      "----------\n",
      "train Loss: 0.0309\n",
      "train MAE: 2608.9649\n",
      "val Loss: 0.0351\n",
      "val MAE: 2719.1988\n",
      "\n",
      "Epoch 47/100\n",
      "----------\n",
      "train Loss: 0.0313\n",
      "train MAE: 2631.5851\n",
      "val Loss: 0.0345\n",
      "val MAE: 2700.4600\n",
      "\n",
      "Epoch 48/100\n",
      "----------\n",
      "train Loss: 0.0311\n",
      "train MAE: 2607.1882\n",
      "val Loss: 0.0342\n",
      "val MAE: 2692.4615\n",
      "\n",
      "Epoch 49/100\n",
      "----------\n",
      "train Loss: 0.0318\n",
      "train MAE: 2658.5807\n",
      "val Loss: 0.0344\n",
      "val MAE: 2698.8931\n",
      "\n",
      "Epoch 50/100\n",
      "----------\n",
      "train Loss: 0.0312\n",
      "train MAE: 2633.6013\n",
      "val Loss: 0.0351\n",
      "val MAE: 2717.5923\n",
      "\n",
      "Epoch 51/100\n",
      "----------\n",
      "train Loss: 0.0307\n",
      "train MAE: 2597.2781\n",
      "val Loss: 0.0344\n",
      "val MAE: 2696.7864\n",
      "\n",
      "Epoch 52/100\n",
      "----------\n",
      "train Loss: 0.0312\n",
      "train MAE: 2625.1813\n",
      "val Loss: 0.0346\n",
      "val MAE: 2702.9528\n",
      "\n",
      "Epoch 53/100\n",
      "----------\n",
      "train Loss: 0.0318\n",
      "train MAE: 2650.9412\n",
      "val Loss: 0.0345\n",
      "val MAE: 2692.8830\n",
      "\n",
      "Epoch 54/100\n",
      "----------\n",
      "train Loss: 0.0306\n",
      "train MAE: 2583.3459\n",
      "val Loss: 0.0339\n",
      "val MAE: 2678.2361\n",
      "\n",
      "Epoch 55/100\n",
      "----------\n",
      "train Loss: 0.0320\n",
      "train MAE: 2633.3643\n",
      "val Loss: 0.0348\n",
      "val MAE: 2700.0510\n",
      "\n",
      "Epoch 56/100\n",
      "----------\n",
      "train Loss: 0.0325\n",
      "train MAE: 2679.9228\n",
      "val Loss: 0.0343\n",
      "val MAE: 2687.8960\n",
      "\n",
      "Epoch 57/100\n",
      "----------\n",
      "train Loss: 0.0325\n",
      "train MAE: 2653.3395\n",
      "val Loss: 0.0341\n",
      "val MAE: 2687.6512\n",
      "\n",
      "Epoch 58/100\n",
      "----------\n",
      "train Loss: 0.0315\n",
      "train MAE: 2611.8983\n",
      "val Loss: 0.0347\n",
      "val MAE: 2708.6354\n",
      "\n",
      "Epoch 59/100\n",
      "----------\n",
      "train Loss: 0.0310\n",
      "train MAE: 2594.6504\n",
      "val Loss: 0.0338\n",
      "val MAE: 2674.1301\n",
      "\n",
      "Epoch 60/100\n",
      "----------\n",
      "train Loss: 0.0314\n",
      "train MAE: 2605.3108\n",
      "val Loss: 0.0341\n",
      "val MAE: 2692.9060\n",
      "\n",
      "Epoch 61/100\n",
      "----------\n",
      "train Loss: 0.0309\n",
      "train MAE: 2598.6947\n",
      "val Loss: 0.0353\n",
      "val MAE: 2724.0868\n",
      "\n",
      "Epoch 62/100\n",
      "----------\n",
      "train Loss: 0.0308\n",
      "train MAE: 2600.2857\n",
      "val Loss: 0.0341\n",
      "val MAE: 2684.1586\n",
      "\n",
      "Epoch 63/100\n",
      "----------\n",
      "train Loss: 0.0325\n",
      "train MAE: 2667.9462\n",
      "val Loss: 0.0351\n",
      "val MAE: 2716.3409\n",
      "\n",
      "Epoch 64/100\n",
      "----------\n",
      "train Loss: 0.0316\n",
      "train MAE: 2632.9710\n",
      "val Loss: 0.0346\n",
      "val MAE: 2694.0455\n",
      "\n",
      "Epoch 65/100\n",
      "----------\n",
      "train Loss: 0.0331\n",
      "train MAE: 2694.0738\n",
      "val Loss: 0.0356\n",
      "val MAE: 2733.2313\n",
      "\n",
      "Epoch 66/100\n",
      "----------\n",
      "train Loss: 0.0318\n",
      "train MAE: 2638.7405\n",
      "val Loss: 0.0349\n",
      "val MAE: 2712.6434\n",
      "\n",
      "Epoch 67/100\n",
      "----------\n",
      "train Loss: 0.0315\n",
      "train MAE: 2615.9715\n",
      "val Loss: 0.0341\n",
      "val MAE: 2686.0309\n",
      "\n",
      "Epoch 68/100\n",
      "----------\n",
      "train Loss: 0.0305\n",
      "train MAE: 2574.4354\n",
      "val Loss: 0.0343\n",
      "val MAE: 2689.7408\n",
      "\n",
      "Epoch 69/100\n",
      "----------\n",
      "train Loss: 0.0312\n",
      "train MAE: 2607.4106\n",
      "val Loss: 0.0352\n",
      "val MAE: 2719.2021\n",
      "\n",
      "Epoch 70/100\n",
      "----------\n",
      "train Loss: 0.0311\n",
      "train MAE: 2625.5046\n",
      "val Loss: 0.0342\n",
      "val MAE: 2684.2211\n",
      "\n",
      "Epoch 71/100\n",
      "----------\n",
      "train Loss: 0.0316\n",
      "train MAE: 2636.9656\n",
      "val Loss: 0.0346\n",
      "val MAE: 2701.6690\n",
      "\n",
      "Epoch 72/100\n",
      "----------\n",
      "train Loss: 0.0304\n",
      "train MAE: 2577.2108\n",
      "val Loss: 0.0340\n",
      "val MAE: 2679.5743\n",
      "\n",
      "Epoch 73/100\n",
      "----------\n",
      "train Loss: 0.0302\n",
      "train MAE: 2583.8408\n",
      "val Loss: 0.0346\n",
      "val MAE: 2700.2453\n",
      "\n",
      "Epoch 74/100\n",
      "----------\n",
      "train Loss: 0.0314\n",
      "train MAE: 2602.0940\n",
      "val Loss: 0.0342\n",
      "val MAE: 2693.6431\n",
      "\n",
      "Epoch 75/100\n",
      "----------\n",
      "train Loss: 0.0320\n",
      "train MAE: 2620.6325\n",
      "val Loss: 0.0343\n",
      "val MAE: 2697.3614\n",
      "\n",
      "Epoch 76/100\n",
      "----------\n",
      "train Loss: 0.0304\n",
      "train MAE: 2584.7053\n",
      "val Loss: 0.0342\n",
      "val MAE: 2693.1202\n",
      "\n",
      "Epoch 77/100\n",
      "----------\n",
      "train Loss: 0.0314\n",
      "train MAE: 2625.0540\n",
      "val Loss: 0.0344\n",
      "val MAE: 2694.8883\n",
      "\n",
      "Epoch 78/100\n",
      "----------\n",
      "train Loss: 0.0319\n",
      "train MAE: 2636.6574\n",
      "val Loss: 0.0344\n",
      "val MAE: 2691.3808\n",
      "\n",
      "Epoch 79/100\n",
      "----------\n",
      "train Loss: 0.0308\n",
      "train MAE: 2603.3184\n",
      "val Loss: 0.0343\n",
      "val MAE: 2694.1037\n",
      "\n",
      "Epoch 80/100\n",
      "----------\n",
      "train Loss: 0.0322\n",
      "train MAE: 2662.1484\n",
      "val Loss: 0.0350\n",
      "val MAE: 2709.9329\n",
      "\n",
      "Epoch 81/100\n",
      "----------\n",
      "train Loss: 0.0317\n",
      "train MAE: 2634.0602\n",
      "val Loss: 0.0341\n",
      "val MAE: 2697.9468\n",
      "\n",
      "Epoch 82/100\n",
      "----------\n",
      "train Loss: 0.0320\n",
      "train MAE: 2641.3612\n",
      "val Loss: 0.0340\n",
      "val MAE: 2679.2840\n",
      "\n",
      "Epoch 83/100\n",
      "----------\n",
      "train Loss: 0.0308\n",
      "train MAE: 2583.9147\n",
      "val Loss: 0.0343\n",
      "val MAE: 2691.2696\n",
      "\n",
      "Epoch 84/100\n",
      "----------\n",
      "train Loss: 0.0317\n",
      "train MAE: 2645.0755\n",
      "val Loss: 0.0342\n",
      "val MAE: 2688.8133\n",
      "\n",
      "Epoch 85/100\n",
      "----------\n",
      "train Loss: 0.0314\n",
      "train MAE: 2644.4678\n",
      "val Loss: 0.0342\n",
      "val MAE: 2687.0968\n",
      "\n",
      "Epoch 86/100\n",
      "----------\n",
      "train Loss: 0.0310\n",
      "train MAE: 2612.9349\n",
      "val Loss: 0.0356\n",
      "val MAE: 2729.7852\n",
      "\n",
      "Epoch 87/100\n",
      "----------\n",
      "train Loss: 0.0317\n",
      "train MAE: 2625.2307\n",
      "val Loss: 0.0340\n",
      "val MAE: 2679.3695\n",
      "\n",
      "Epoch 88/100\n",
      "----------\n",
      "train Loss: 0.0316\n",
      "train MAE: 2627.1698\n",
      "val Loss: 0.0344\n",
      "val MAE: 2695.9492\n",
      "\n",
      "Epoch 89/100\n",
      "----------\n",
      "train Loss: 0.0307\n",
      "train MAE: 2611.9841\n",
      "val Loss: 0.0350\n",
      "val MAE: 2713.0146\n",
      "\n",
      "Epoch 90/100\n",
      "----------\n",
      "train Loss: 0.0310\n",
      "train MAE: 2621.5160\n",
      "val Loss: 0.0348\n",
      "val MAE: 2708.5251\n",
      "\n",
      "Epoch 91/100\n",
      "----------\n",
      "train Loss: 0.0304\n",
      "train MAE: 2575.0854\n",
      "val Loss: 0.0347\n",
      "val MAE: 2707.1986\n",
      "\n",
      "Epoch 92/100\n",
      "----------\n",
      "train Loss: 0.0311\n",
      "train MAE: 2622.1693\n",
      "val Loss: 0.0341\n",
      "val MAE: 2684.2762\n",
      "\n",
      "Epoch 93/100\n",
      "----------\n",
      "train Loss: 0.0304\n",
      "train MAE: 2584.8611\n",
      "val Loss: 0.0341\n",
      "val MAE: 2680.9485\n",
      "\n",
      "Epoch 94/100\n",
      "----------\n",
      "train Loss: 0.0314\n",
      "train MAE: 2628.0058\n",
      "val Loss: 0.0341\n",
      "val MAE: 2682.7986\n",
      "\n",
      "Epoch 95/100\n",
      "----------\n",
      "train Loss: 0.0315\n",
      "train MAE: 2633.1392\n",
      "val Loss: 0.0342\n",
      "val MAE: 2688.8706\n",
      "\n",
      "Epoch 96/100\n",
      "----------\n",
      "train Loss: 0.0300\n",
      "train MAE: 2553.4132\n",
      "val Loss: 0.0342\n",
      "val MAE: 2688.6118\n",
      "\n",
      "Epoch 97/100\n",
      "----------\n",
      "train Loss: 0.0319\n",
      "train MAE: 2641.2574\n",
      "val Loss: 0.0348\n",
      "val MAE: 2704.0976\n",
      "\n",
      "Epoch 98/100\n",
      "----------\n",
      "train Loss: 0.0319\n",
      "train MAE: 2636.2189\n",
      "val Loss: 0.0341\n",
      "val MAE: 2677.1878\n",
      "\n",
      "Epoch 99/100\n",
      "----------\n",
      "train Loss: 0.0313\n",
      "train MAE: 2620.9588\n",
      "val Loss: 0.0341\n",
      "val MAE: 2678.9766\n",
      "\n",
      "Epoch 100/100\n",
      "----------\n",
      "train Loss: 0.0320\n",
      "train MAE: 2656.3408\n",
      "val Loss: 0.0339\n",
      "val MAE: 2674.6641\n",
      "\n",
      "Training complete in 129m 60s\n",
      "Best val Loss: 0.033799 at epoch 59\n",
      "Best val MAE: 2674.130097 at epoch 59\n",
      "\n",
      "Load the model weights at the best epoch\n"
     ]
    }
   ],
   "source": [
    "model_res152, mae_list_0, all_loss_0, all_mae_0 = train_model(model_ft, model_LU, criterion, optimizer_ft, exp_lr_scheduler, num_epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. (2053, 32, 1) + Sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "### ResNet18\n",
    "model_ft = models.resnet152(pretrained=True)\n",
    "num_ftrs = model_ft.fc.in_features\n",
    "model_ft.fc = nn.Identity()\n",
    "\n",
    "### Freeze and Fine Tuning\n",
    "for param in model_ft.parameters():\n",
    "    param.requires_grad = False\n",
    "for param in model_ft.layer3.parameters():\n",
    "    param.requires_grad = True\n",
    "for param in model_ft.layer4.parameters():\n",
    "    param.requires_grad = True\n",
    "assert [param.requires_grad for param in model_ft.parameters()][-1]\n",
    "\n",
    "### LU\n",
    "model_LU = nn.Sequential(\n",
    "    nn.Linear(num_ftrs + num_tabular_features, 32),\n",
    "    nn.Sigmoid(),\n",
    "    nn.Linear(32, 1)\n",
    ")\n",
    "\n",
    "### model setup\n",
    "model_ft = model_ft.to(device)\n",
    "model_LU = model_LU.to(device)\n",
    "criterion = nn.MSELoss()\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.SGD(list(model_ft.parameters())+list(model_LU.parameters()), lr=0.001, momentum=0.9)\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=20, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "----------\n",
      "train Loss: 0.0992\n",
      "train MAE: 4745.8374\n",
      "val Loss: 0.0623\n",
      "val MAE: 3734.8699\n",
      "\n",
      "Epoch 2/100\n",
      "----------\n",
      "train Loss: 0.0687\n",
      "train MAE: 3947.3478\n",
      "val Loss: 0.0496\n",
      "val MAE: 3259.8694\n",
      "\n",
      "Epoch 3/100\n",
      "----------\n",
      "train Loss: 0.0606\n",
      "train MAE: 3690.1719\n",
      "val Loss: 0.0446\n",
      "val MAE: 3095.4583\n",
      "\n",
      "Epoch 4/100\n",
      "----------\n",
      "train Loss: 0.0574\n",
      "train MAE: 3601.5153\n",
      "val Loss: 0.0527\n",
      "val MAE: 3368.2378\n",
      "\n",
      "Epoch 5/100\n",
      "----------\n",
      "train Loss: 0.0557\n",
      "train MAE: 3529.3085\n",
      "val Loss: 0.0415\n",
      "val MAE: 2977.0102\n",
      "\n",
      "Epoch 6/100\n",
      "----------\n",
      "train Loss: 0.0504\n",
      "train MAE: 3346.1993\n",
      "val Loss: 0.0405\n",
      "val MAE: 2966.5879\n",
      "\n",
      "Epoch 7/100\n",
      "----------\n",
      "train Loss: 0.0500\n",
      "train MAE: 3332.2103\n",
      "val Loss: 0.0526\n",
      "val MAE: 3406.8758\n",
      "\n",
      "Epoch 8/100\n",
      "----------\n",
      "train Loss: 0.0474\n",
      "train MAE: 3259.2268\n",
      "val Loss: 0.0385\n",
      "val MAE: 2867.6982\n",
      "\n",
      "Epoch 9/100\n",
      "----------\n",
      "train Loss: 0.0474\n",
      "train MAE: 3240.2886\n",
      "val Loss: 0.0389\n",
      "val MAE: 2898.8871\n",
      "\n",
      "Epoch 10/100\n",
      "----------\n",
      "train Loss: 0.0463\n",
      "train MAE: 3195.0982\n",
      "val Loss: 0.0371\n",
      "val MAE: 2820.2490\n",
      "\n",
      "Epoch 11/100\n",
      "----------\n",
      "train Loss: 0.0450\n",
      "train MAE: 3144.0650\n",
      "val Loss: 0.0369\n",
      "val MAE: 2808.5112\n",
      "\n",
      "Epoch 12/100\n",
      "----------\n",
      "train Loss: 0.0434\n",
      "train MAE: 3112.6664\n",
      "val Loss: 0.0363\n",
      "val MAE: 2773.7736\n",
      "\n",
      "Epoch 13/100\n",
      "----------\n",
      "train Loss: 0.0441\n",
      "train MAE: 3110.5243\n",
      "val Loss: 0.0380\n",
      "val MAE: 2832.0112\n",
      "\n",
      "Epoch 14/100\n",
      "----------\n",
      "train Loss: 0.0423\n",
      "train MAE: 3087.5546\n",
      "val Loss: 0.0367\n",
      "val MAE: 2785.5837\n",
      "\n",
      "Epoch 15/100\n",
      "----------\n",
      "train Loss: 0.0400\n",
      "train MAE: 2957.8120\n",
      "val Loss: 0.0355\n",
      "val MAE: 2737.9849\n",
      "\n",
      "Epoch 16/100\n",
      "----------\n",
      "train Loss: 0.0399\n",
      "train MAE: 2977.1080\n",
      "val Loss: 0.0356\n",
      "val MAE: 2732.7689\n",
      "\n",
      "Epoch 17/100\n",
      "----------\n",
      "train Loss: 0.0392\n",
      "train MAE: 2946.4213\n",
      "val Loss: 0.0358\n",
      "val MAE: 2745.9159\n",
      "\n",
      "Epoch 18/100\n",
      "----------\n",
      "train Loss: 0.0383\n",
      "train MAE: 2926.6525\n",
      "val Loss: 0.0382\n",
      "val MAE: 2819.8996\n",
      "\n",
      "Epoch 19/100\n",
      "----------\n",
      "train Loss: 0.0390\n",
      "train MAE: 2940.5380\n",
      "val Loss: 0.0393\n",
      "val MAE: 2884.1778\n",
      "\n",
      "Epoch 20/100\n",
      "----------\n",
      "train Loss: 0.0375\n",
      "train MAE: 2882.9113\n",
      "val Loss: 0.0348\n",
      "val MAE: 2698.1260\n",
      "\n",
      "Epoch 21/100\n",
      "----------\n",
      "train Loss: 0.0357\n",
      "train MAE: 2801.2424\n",
      "val Loss: 0.0346\n",
      "val MAE: 2693.3351\n",
      "\n",
      "Epoch 22/100\n",
      "----------\n",
      "train Loss: 0.0343\n",
      "train MAE: 2756.8312\n",
      "val Loss: 0.0338\n",
      "val MAE: 2667.4121\n",
      "\n",
      "Epoch 23/100\n",
      "----------\n",
      "train Loss: 0.0359\n",
      "train MAE: 2817.4970\n",
      "val Loss: 0.0342\n",
      "val MAE: 2681.0390\n",
      "\n",
      "Epoch 24/100\n",
      "----------\n",
      "train Loss: 0.0338\n",
      "train MAE: 2750.9202\n",
      "val Loss: 0.0342\n",
      "val MAE: 2681.9053\n",
      "\n",
      "Epoch 25/100\n",
      "----------\n",
      "train Loss: 0.0350\n",
      "train MAE: 2777.5941\n",
      "val Loss: 0.0341\n",
      "val MAE: 2676.5448\n",
      "\n",
      "Epoch 26/100\n",
      "----------\n",
      "train Loss: 0.0353\n",
      "train MAE: 2789.8928\n",
      "val Loss: 0.0345\n",
      "val MAE: 2694.8794\n",
      "\n",
      "Epoch 27/100\n",
      "----------\n",
      "train Loss: 0.0354\n",
      "train MAE: 2825.3690\n",
      "val Loss: 0.0340\n",
      "val MAE: 2677.2341\n",
      "\n",
      "Epoch 28/100\n",
      "----------\n",
      "train Loss: 0.0352\n",
      "train MAE: 2794.1965\n",
      "val Loss: 0.0343\n",
      "val MAE: 2685.1082\n",
      "\n",
      "Epoch 29/100\n",
      "----------\n",
      "train Loss: 0.0343\n",
      "train MAE: 2766.4975\n",
      "val Loss: 0.0340\n",
      "val MAE: 2677.4888\n",
      "\n",
      "Epoch 30/100\n",
      "----------\n",
      "train Loss: 0.0364\n",
      "train MAE: 2831.1566\n",
      "val Loss: 0.0343\n",
      "val MAE: 2682.2653\n",
      "\n",
      "Epoch 31/100\n",
      "----------\n",
      "train Loss: 0.0326\n",
      "train MAE: 2701.4274\n",
      "val Loss: 0.0338\n",
      "val MAE: 2669.6529\n",
      "\n",
      "Epoch 32/100\n",
      "----------\n",
      "train Loss: 0.0354\n",
      "train MAE: 2781.6131\n",
      "val Loss: 0.0341\n",
      "val MAE: 2680.8679\n",
      "\n",
      "Epoch 33/100\n",
      "----------\n",
      "train Loss: 0.0345\n",
      "train MAE: 2733.5302\n",
      "val Loss: 0.0338\n",
      "val MAE: 2668.5622\n",
      "\n",
      "Epoch 34/100\n",
      "----------\n",
      "train Loss: 0.0340\n",
      "train MAE: 2727.9259\n",
      "val Loss: 0.0348\n",
      "val MAE: 2703.8052\n",
      "\n",
      "Epoch 35/100\n",
      "----------\n",
      "train Loss: 0.0339\n",
      "train MAE: 2743.5055\n",
      "val Loss: 0.0344\n",
      "val MAE: 2685.0288\n",
      "\n",
      "Epoch 36/100\n",
      "----------\n",
      "train Loss: 0.0331\n",
      "train MAE: 2692.1712\n",
      "val Loss: 0.0340\n",
      "val MAE: 2673.2836\n",
      "\n",
      "Epoch 37/100\n",
      "----------\n",
      "train Loss: 0.0341\n",
      "train MAE: 2733.2499\n",
      "val Loss: 0.0344\n",
      "val MAE: 2682.7731\n",
      "\n",
      "Epoch 38/100\n",
      "----------\n",
      "train Loss: 0.0338\n",
      "train MAE: 2749.3868\n",
      "val Loss: 0.0346\n",
      "val MAE: 2697.5031\n",
      "\n",
      "Epoch 39/100\n",
      "----------\n",
      "train Loss: 0.0338\n",
      "train MAE: 2719.3016\n",
      "val Loss: 0.0344\n",
      "val MAE: 2689.2135\n",
      "\n",
      "Epoch 40/100\n",
      "----------\n",
      "train Loss: 0.0340\n",
      "train MAE: 2734.3182\n",
      "val Loss: 0.0353\n",
      "val MAE: 2720.0764\n",
      "\n",
      "Epoch 41/100\n",
      "----------\n",
      "train Loss: 0.0342\n",
      "train MAE: 2755.6601\n",
      "val Loss: 0.0343\n",
      "val MAE: 2683.2241\n",
      "\n",
      "Epoch 42/100\n",
      "----------\n",
      "train Loss: 0.0334\n",
      "train MAE: 2737.0144\n",
      "val Loss: 0.0341\n",
      "val MAE: 2672.5074\n",
      "\n",
      "Epoch 43/100\n",
      "----------\n",
      "train Loss: 0.0344\n",
      "train MAE: 2788.9380\n",
      "val Loss: 0.0338\n",
      "val MAE: 2666.7184\n",
      "\n",
      "Epoch 44/100\n",
      "----------\n",
      "train Loss: 0.0342\n",
      "train MAE: 2740.5028\n",
      "val Loss: 0.0342\n",
      "val MAE: 2675.2947\n",
      "\n",
      "Epoch 45/100\n",
      "----------\n",
      "train Loss: 0.0335\n",
      "train MAE: 2727.4323\n",
      "val Loss: 0.0345\n",
      "val MAE: 2691.4321\n",
      "\n",
      "Epoch 46/100\n",
      "----------\n",
      "train Loss: 0.0331\n",
      "train MAE: 2697.7076\n",
      "val Loss: 0.0349\n",
      "val MAE: 2705.8336\n",
      "\n",
      "Epoch 47/100\n",
      "----------\n",
      "train Loss: 0.0336\n",
      "train MAE: 2732.0927\n",
      "val Loss: 0.0345\n",
      "val MAE: 2691.5217\n",
      "\n",
      "Epoch 48/100\n",
      "----------\n",
      "train Loss: 0.0331\n",
      "train MAE: 2699.5142\n",
      "val Loss: 0.0339\n",
      "val MAE: 2676.3162\n",
      "\n",
      "Epoch 49/100\n",
      "----------\n",
      "train Loss: 0.0338\n",
      "train MAE: 2750.5784\n",
      "val Loss: 0.0345\n",
      "val MAE: 2691.0175\n",
      "\n",
      "Epoch 50/100\n",
      "----------\n",
      "train Loss: 0.0332\n",
      "train MAE: 2728.1984\n",
      "val Loss: 0.0347\n",
      "val MAE: 2697.0807\n",
      "\n",
      "Epoch 51/100\n",
      "----------\n",
      "train Loss: 0.0325\n",
      "train MAE: 2684.7237\n",
      "val Loss: 0.0341\n",
      "val MAE: 2681.6925\n",
      "\n",
      "Epoch 52/100\n",
      "----------\n",
      "train Loss: 0.0333\n",
      "train MAE: 2710.1133\n",
      "val Loss: 0.0349\n",
      "val MAE: 2704.4339\n",
      "\n",
      "Epoch 53/100\n",
      "----------\n",
      "train Loss: 0.0338\n",
      "train MAE: 2744.2395\n",
      "val Loss: 0.0344\n",
      "val MAE: 2680.6157\n",
      "\n",
      "Epoch 54/100\n",
      "----------\n",
      "train Loss: 0.0327\n",
      "train MAE: 2686.9018\n",
      "val Loss: 0.0338\n",
      "val MAE: 2665.4602\n",
      "\n",
      "Epoch 55/100\n",
      "----------\n",
      "train Loss: 0.0339\n",
      "train MAE: 2726.5733\n",
      "val Loss: 0.0346\n",
      "val MAE: 2691.2270\n",
      "\n",
      "Epoch 56/100\n",
      "----------\n",
      "train Loss: 0.0341\n",
      "train MAE: 2757.3023\n",
      "val Loss: 0.0342\n",
      "val MAE: 2677.0310\n",
      "\n",
      "Epoch 57/100\n",
      "----------\n",
      "train Loss: 0.0346\n",
      "train MAE: 2752.2957\n",
      "val Loss: 0.0339\n",
      "val MAE: 2673.6994\n",
      "\n",
      "Epoch 58/100\n",
      "----------\n",
      "train Loss: 0.0334\n",
      "train MAE: 2705.2754\n",
      "val Loss: 0.0348\n",
      "val MAE: 2707.6548\n",
      "\n",
      "Epoch 59/100\n",
      "----------\n",
      "train Loss: 0.0334\n",
      "train MAE: 2696.5528\n",
      "val Loss: 0.0336\n",
      "val MAE: 2657.5620\n",
      "\n",
      "Epoch 60/100\n",
      "----------\n",
      "train Loss: 0.0333\n",
      "train MAE: 2691.9847\n",
      "val Loss: 0.0340\n",
      "val MAE: 2678.7804\n",
      "\n",
      "Epoch 61/100\n",
      "----------\n",
      "train Loss: 0.0331\n",
      "train MAE: 2690.0513\n",
      "val Loss: 0.0351\n",
      "val MAE: 2715.2412\n",
      "\n",
      "Epoch 62/100\n",
      "----------\n",
      "train Loss: 0.0327\n",
      "train MAE: 2696.6225\n",
      "val Loss: 0.0340\n",
      "val MAE: 2669.4119\n",
      "\n",
      "Epoch 63/100\n",
      "----------\n",
      "train Loss: 0.0341\n",
      "train MAE: 2745.2464\n",
      "val Loss: 0.0349\n",
      "val MAE: 2703.8841\n",
      "\n",
      "Epoch 64/100\n",
      "----------\n",
      "train Loss: 0.0336\n",
      "train MAE: 2722.4672\n",
      "val Loss: 0.0343\n",
      "val MAE: 2684.9634\n",
      "\n",
      "Epoch 65/100\n",
      "----------\n",
      "train Loss: 0.0354\n",
      "train MAE: 2790.3523\n",
      "val Loss: 0.0355\n",
      "val MAE: 2725.8216\n",
      "\n",
      "Epoch 66/100\n",
      "----------\n",
      "train Loss: 0.0338\n",
      "train MAE: 2727.4434\n",
      "val Loss: 0.0346\n",
      "val MAE: 2694.4732\n",
      "\n",
      "Epoch 67/100\n",
      "----------\n",
      "train Loss: 0.0335\n",
      "train MAE: 2708.3721\n",
      "val Loss: 0.0340\n",
      "val MAE: 2675.3511\n",
      "\n",
      "Epoch 68/100\n",
      "----------\n",
      "train Loss: 0.0324\n",
      "train MAE: 2661.4858\n",
      "val Loss: 0.0341\n",
      "val MAE: 2676.1949\n",
      "\n",
      "Epoch 69/100\n",
      "----------\n",
      "train Loss: 0.0330\n",
      "train MAE: 2694.8795\n",
      "val Loss: 0.0351\n",
      "val MAE: 2711.8197\n",
      "\n",
      "Epoch 70/100\n",
      "----------\n",
      "train Loss: 0.0331\n",
      "train MAE: 2713.3302\n",
      "val Loss: 0.0341\n",
      "val MAE: 2674.1217\n",
      "\n",
      "Epoch 71/100\n",
      "----------\n",
      "train Loss: 0.0333\n",
      "train MAE: 2710.2524\n",
      "val Loss: 0.0346\n",
      "val MAE: 2695.3403\n",
      "\n",
      "Epoch 72/100\n",
      "----------\n",
      "train Loss: 0.0328\n",
      "train MAE: 2690.0320\n",
      "val Loss: 0.0340\n",
      "val MAE: 2668.2654\n",
      "\n",
      "Epoch 73/100\n",
      "----------\n",
      "train Loss: 0.0322\n",
      "train MAE: 2678.4776\n",
      "val Loss: 0.0345\n",
      "val MAE: 2693.5819\n",
      "\n",
      "Epoch 74/100\n",
      "----------\n",
      "train Loss: 0.0335\n",
      "train MAE: 2707.4608\n",
      "val Loss: 0.0342\n",
      "val MAE: 2688.0737\n",
      "\n",
      "Epoch 75/100\n",
      "----------\n",
      "train Loss: 0.0343\n",
      "train MAE: 2710.0589\n",
      "val Loss: 0.0342\n",
      "val MAE: 2690.0996\n",
      "\n",
      "Epoch 76/100\n",
      "----------\n",
      "train Loss: 0.0326\n",
      "train MAE: 2677.7182\n",
      "val Loss: 0.0341\n",
      "val MAE: 2677.4045\n",
      "\n",
      "Epoch 77/100\n",
      "----------\n",
      "train Loss: 0.0335\n",
      "train MAE: 2712.8276\n",
      "val Loss: 0.0342\n",
      "val MAE: 2680.8056\n",
      "\n",
      "Epoch 78/100\n",
      "----------\n",
      "train Loss: 0.0338\n",
      "train MAE: 2720.4266\n",
      "val Loss: 0.0343\n",
      "val MAE: 2677.9183\n",
      "\n",
      "Epoch 79/100\n",
      "----------\n",
      "train Loss: 0.0329\n",
      "train MAE: 2699.0069\n",
      "val Loss: 0.0342\n",
      "val MAE: 2681.7300\n",
      "\n",
      "Epoch 80/100\n",
      "----------\n",
      "train Loss: 0.0342\n",
      "train MAE: 2753.3639\n",
      "val Loss: 0.0349\n",
      "val MAE: 2704.1825\n",
      "\n",
      "Epoch 81/100\n",
      "----------\n",
      "train Loss: 0.0337\n",
      "train MAE: 2718.1313\n",
      "val Loss: 0.0339\n",
      "val MAE: 2679.8621\n",
      "\n",
      "Epoch 82/100\n",
      "----------\n",
      "train Loss: 0.0341\n",
      "train MAE: 2730.2403\n",
      "val Loss: 0.0338\n",
      "val MAE: 2662.9639\n",
      "\n",
      "Epoch 83/100\n",
      "----------\n",
      "train Loss: 0.0330\n",
      "train MAE: 2691.5213\n",
      "val Loss: 0.0342\n",
      "val MAE: 2682.8058\n",
      "\n",
      "Epoch 84/100\n",
      "----------\n",
      "train Loss: 0.0337\n",
      "train MAE: 2747.5930\n",
      "val Loss: 0.0341\n",
      "val MAE: 2678.0502\n",
      "\n",
      "Epoch 85/100\n",
      "----------\n",
      "train Loss: 0.0336\n",
      "train MAE: 2747.3829\n",
      "val Loss: 0.0342\n",
      "val MAE: 2683.7197\n",
      "\n",
      "Epoch 86/100\n",
      "----------\n",
      "train Loss: 0.0328\n",
      "train MAE: 2696.8676\n",
      "val Loss: 0.0355\n",
      "val MAE: 2723.8736\n",
      "\n",
      "Epoch 87/100\n",
      "----------\n",
      "train Loss: 0.0335\n",
      "train MAE: 2706.1010\n",
      "val Loss: 0.0339\n",
      "val MAE: 2668.7176\n",
      "\n",
      "Epoch 88/100\n",
      "----------\n",
      "train Loss: 0.0338\n",
      "train MAE: 2734.8241\n",
      "val Loss: 0.0342\n",
      "val MAE: 2681.1997\n",
      "\n",
      "Epoch 89/100\n",
      "----------\n",
      "train Loss: 0.0324\n",
      "train MAE: 2692.9180\n",
      "val Loss: 0.0350\n",
      "val MAE: 2705.8641\n",
      "\n",
      "Epoch 90/100\n",
      "----------\n",
      "train Loss: 0.0333\n",
      "train MAE: 2730.8629\n",
      "val Loss: 0.0348\n",
      "val MAE: 2701.5738\n",
      "\n",
      "Epoch 91/100\n",
      "----------\n",
      "train Loss: 0.0322\n",
      "train MAE: 2651.1398\n",
      "val Loss: 0.0346\n",
      "val MAE: 2693.6469\n",
      "\n",
      "Epoch 92/100\n",
      "----------\n",
      "train Loss: 0.0331\n",
      "train MAE: 2715.5480\n",
      "val Loss: 0.0340\n",
      "val MAE: 2671.0466\n",
      "\n",
      "Epoch 93/100\n",
      "----------\n",
      "train Loss: 0.0326\n",
      "train MAE: 2686.2419\n",
      "val Loss: 0.0339\n",
      "val MAE: 2664.4012\n",
      "\n",
      "Epoch 94/100\n",
      "----------\n",
      "train Loss: 0.0336\n",
      "train MAE: 2721.5364\n",
      "val Loss: 0.0339\n",
      "val MAE: 2667.5843\n",
      "\n",
      "Epoch 95/100\n",
      "----------\n",
      "train Loss: 0.0337\n",
      "train MAE: 2723.7968\n",
      "val Loss: 0.0340\n",
      "val MAE: 2673.8552\n",
      "\n",
      "Epoch 96/100\n",
      "----------\n",
      "train Loss: 0.0320\n",
      "train MAE: 2641.6305\n",
      "val Loss: 0.0341\n",
      "val MAE: 2678.4032\n",
      "\n",
      "Epoch 97/100\n",
      "----------\n",
      "train Loss: 0.0343\n",
      "train MAE: 2746.3677\n",
      "val Loss: 0.0346\n",
      "val MAE: 2689.5152\n",
      "\n",
      "Epoch 98/100\n",
      "----------\n",
      "train Loss: 0.0339\n",
      "train MAE: 2725.6579\n",
      "val Loss: 0.0340\n",
      "val MAE: 2667.7464\n",
      "\n",
      "Epoch 99/100\n",
      "----------\n",
      "train Loss: 0.0335\n",
      "train MAE: 2712.6966\n",
      "val Loss: 0.0341\n",
      "val MAE: 2669.1642\n",
      "\n",
      "Epoch 100/100\n",
      "----------\n",
      "train Loss: 0.0340\n",
      "train MAE: 2744.9760\n",
      "val Loss: 0.0338\n",
      "val MAE: 2663.0738\n",
      "\n",
      "Training complete in 127m 17s\n",
      "Best val Loss: 0.033578 at epoch 59\n",
      "Best val MAE: 2657.562038 at epoch 59\n",
      "\n",
      "Load the model weights at the best epoch\n"
     ]
    }
   ],
   "source": [
    "model_res152, mae_list_1, all_loss_1, all_mae_1 = train_model(model_ft, model_LU, criterion, optimizer_ft, exp_lr_scheduler, num_epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(mae_list_0, open(\"mae_list_0\", \"wb\"))\n",
    "pickle.dump(all_loss_0, open(\"all_loss_0\", \"wb\"))\n",
    "pickle.dump(all_mae_0, open(\"all_mae_0\", \"wb\"))\n",
    "pickle.dump(mae_list_1, open(\"mae_list_1\", \"wb\"))\n",
    "pickle.dump(all_loss_1, open(\"all_loss_1\", \"wb\"))\n",
    "pickle.dump(all_mae_1, open(\"all_mae_1\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. (2053, 32, 1) + Tanh + scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "### ResNet18\n",
    "model_ft = models.resnet152(pretrained=True)\n",
    "num_ftrs = model_ft.fc.in_features\n",
    "model_ft.fc = nn.Identity()\n",
    "\n",
    "### Freeze and Fine Tuning\n",
    "for param in model_ft.parameters():\n",
    "    param.requires_grad = False\n",
    "for param in model_ft.layer3.parameters():\n",
    "    param.requires_grad = True\n",
    "for param in model_ft.layer4.parameters():\n",
    "    param.requires_grad = True\n",
    "assert [param.requires_grad for param in model_ft.parameters()][-1]\n",
    "\n",
    "### LU\n",
    "model_LU = nn.Sequential(\n",
    "    nn.Linear(num_ftrs + num_tabular_features, 32),\n",
    "    nn.Tanh(),\n",
    "    nn.Linear(32, 1)\n",
    ")\n",
    "\n",
    "### model setup\n",
    "model_ft = model_ft.to(device)\n",
    "model_LU = model_LU.to(device)\n",
    "criterion = nn.MSELoss()\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.SGD(list(model_ft.parameters())+list(model_LU.parameters()), lr=0.001, momentum=0.9)\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = lr_scheduler.ReduceLROnPlateau(optimizer_ft, factor=0.1, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "----------\n",
      "train Loss: 0.0920\n",
      "train MAE: 4535.2175\n",
      "val Loss: 0.0523\n",
      "val MAE: 3356.4244\n",
      "\n",
      "Epoch 2/100\n",
      "----------\n",
      "train Loss: 0.0679\n",
      "train MAE: 3891.6452\n",
      "val Loss: 0.0478\n",
      "val MAE: 3215.2317\n",
      "\n",
      "Epoch 3/100\n",
      "----------\n",
      "train Loss: 0.0594\n",
      "train MAE: 3630.3096\n",
      "val Loss: 0.0431\n",
      "val MAE: 3053.4651\n",
      "\n",
      "Epoch 4/100\n",
      "----------\n",
      "train Loss: 0.0560\n",
      "train MAE: 3548.2751\n",
      "val Loss: 0.0595\n",
      "val MAE: 3655.6614\n",
      "\n",
      "Epoch 5/100\n",
      "----------\n",
      "train Loss: 0.0537\n",
      "train MAE: 3471.3711\n",
      "val Loss: 0.0413\n",
      "val MAE: 2975.7702\n",
      "\n",
      "Epoch 6/100\n",
      "----------\n",
      "train Loss: 0.0490\n",
      "train MAE: 3300.9433\n",
      "val Loss: 0.0453\n",
      "val MAE: 3132.5130\n",
      "\n",
      "Epoch 7/100\n",
      "----------\n",
      "train Loss: 0.0492\n",
      "train MAE: 3296.1072\n",
      "val Loss: 0.0727\n",
      "val MAE: 4224.1736\n",
      "\n",
      "Epoch 8/100\n",
      "----------\n",
      "train Loss: 0.0473\n",
      "train MAE: 3263.1697\n",
      "val Loss: 0.0402\n",
      "val MAE: 2901.1215\n",
      "\n",
      "Epoch 9/100\n",
      "----------\n",
      "train Loss: 0.0467\n",
      "train MAE: 3228.9887\n",
      "val Loss: 0.0455\n",
      "val MAE: 3137.2490\n",
      "\n",
      "Epoch 10/100\n",
      "----------\n",
      "train Loss: 0.0453\n",
      "train MAE: 3166.0073\n",
      "val Loss: 0.0379\n",
      "val MAE: 2834.8794\n",
      "\n",
      "Epoch 11/100\n",
      "----------\n",
      "train Loss: 0.0447\n",
      "train MAE: 3141.0130\n",
      "val Loss: 0.0367\n",
      "val MAE: 2793.5956\n",
      "\n",
      "Epoch 12/100\n",
      "----------\n",
      "train Loss: 0.0431\n",
      "train MAE: 3103.0216\n",
      "val Loss: 0.0370\n",
      "val MAE: 2794.6269\n",
      "\n",
      "Epoch 13/100\n",
      "----------\n",
      "train Loss: 0.0428\n",
      "train MAE: 3084.4347\n",
      "val Loss: 0.0383\n",
      "val MAE: 2868.1926\n",
      "\n",
      "Epoch 14/100\n",
      "----------\n",
      "train Loss: 0.0410\n",
      "train MAE: 3047.5385\n",
      "val Loss: 0.0365\n",
      "val MAE: 2774.2925\n",
      "\n",
      "Epoch 15/100\n",
      "----------\n",
      "train Loss: 0.0389\n",
      "train MAE: 2912.6642\n",
      "val Loss: 0.0370\n",
      "val MAE: 2808.3287\n",
      "\n",
      "Epoch 16/100\n",
      "----------\n",
      "train Loss: 0.0401\n",
      "train MAE: 2988.3554\n",
      "val Loss: 0.0377\n",
      "val MAE: 2818.7417\n",
      "\n",
      "Epoch 17/100\n",
      "----------\n",
      "train Loss: 0.0383\n",
      "train MAE: 2906.1429\n",
      "val Loss: 0.0354\n",
      "val MAE: 2727.7607\n",
      "\n",
      "Epoch 18/100\n",
      "----------\n",
      "train Loss: 0.0370\n",
      "train MAE: 2875.7423\n",
      "val Loss: 0.0361\n",
      "val MAE: 2744.9774\n",
      "\n",
      "Epoch 19/100\n",
      "----------\n",
      "train Loss: 0.0379\n",
      "train MAE: 2907.3378\n",
      "val Loss: 0.0378\n",
      "val MAE: 2839.5023\n",
      "\n",
      "Epoch 20/100\n",
      "----------\n",
      "train Loss: 0.0371\n",
      "train MAE: 2858.5168\n",
      "val Loss: 0.0382\n",
      "val MAE: 2831.8703\n",
      "\n",
      "Epoch 21/100\n",
      "----------\n",
      "train Loss: 0.0375\n",
      "train MAE: 2891.0236\n",
      "val Loss: 0.0344\n",
      "val MAE: 2687.0768\n",
      "\n",
      "Epoch 22/100\n",
      "----------\n",
      "train Loss: 0.0346\n",
      "train MAE: 2767.8909\n",
      "val Loss: 0.0355\n",
      "val MAE: 2734.8277\n",
      "\n",
      "Epoch 23/100\n",
      "----------\n",
      "train Loss: 0.0360\n",
      "train MAE: 2823.4850\n",
      "val Loss: 0.0348\n",
      "val MAE: 2691.8563\n",
      "\n",
      "Epoch 24/100\n",
      "----------\n",
      "train Loss: 0.0336\n",
      "train MAE: 2737.2083\n",
      "val Loss: 0.0341\n",
      "val MAE: 2698.7918\n",
      "\n",
      "Epoch 25/100\n",
      "----------\n",
      "train Loss: 0.0337\n",
      "train MAE: 2708.4738\n",
      "val Loss: 0.0341\n",
      "val MAE: 2672.4233\n",
      "\n",
      "Epoch 26/100\n",
      "----------\n",
      "train Loss: 0.0326\n",
      "train MAE: 2679.6325\n",
      "val Loss: 0.0339\n",
      "val MAE: 2671.7638\n",
      "\n",
      "Epoch 27/100\n",
      "----------\n",
      "train Loss: 0.0347\n",
      "train MAE: 2788.9269\n",
      "val Loss: 0.0343\n",
      "val MAE: 2695.1231\n",
      "\n",
      "Epoch 28/100\n",
      "----------\n",
      "train Loss: 0.0333\n",
      "train MAE: 2718.6633\n",
      "val Loss: 0.0345\n",
      "val MAE: 2677.3660\n",
      "\n",
      "Epoch 29/100\n",
      "----------\n",
      "train Loss: 0.0328\n",
      "train MAE: 2686.6608\n",
      "val Loss: 0.0457\n",
      "val MAE: 3132.8492\n",
      "\n",
      "Epoch 30/100\n",
      "----------\n",
      "train Loss: 0.0341\n",
      "train MAE: 2721.0449\n",
      "val Loss: 0.0350\n",
      "val MAE: 2688.6211\n",
      "\n",
      "Epoch 31/100\n",
      "----------\n",
      "train Loss: 0.0298\n",
      "train MAE: 2558.0761\n",
      "val Loss: 0.0363\n",
      "val MAE: 2783.1623\n",
      "\n",
      "Epoch 32/100\n",
      "----------\n",
      "train Loss: 0.0318\n",
      "train MAE: 2620.3626\n",
      "val Loss: 0.0363\n",
      "val MAE: 2783.9992\n",
      "\n",
      "Epoch 33/100\n",
      "----------\n",
      "train Loss: 0.0310\n",
      "train MAE: 2577.8721\n",
      "val Loss: 0.0342\n",
      "val MAE: 2675.6938\n",
      "\n",
      "Epoch 34/100\n",
      "----------\n",
      "train Loss: 0.0303\n",
      "train MAE: 2569.8930\n",
      "val Loss: 0.0350\n",
      "val MAE: 2712.2740\n",
      "\n",
      "Epoch 35/100\n",
      "----------\n",
      "train Loss: 0.0300\n",
      "train MAE: 2567.9552\n",
      "val Loss: 0.0347\n",
      "val MAE: 2685.4536\n",
      "\n",
      "Epoch 36/100\n",
      "----------\n",
      "train Loss: 0.0282\n",
      "train MAE: 2465.0581\n",
      "val Loss: 0.0344\n",
      "val MAE: 2679.4599\n",
      "\n",
      "Epoch 37/100\n",
      "----------\n",
      "train Loss: 0.0295\n",
      "train MAE: 2544.6271\n",
      "val Loss: 0.0338\n",
      "val MAE: 2659.6155\n",
      "\n",
      "Epoch 38/100\n",
      "----------\n",
      "train Loss: 0.0290\n",
      "train MAE: 2522.1334\n",
      "val Loss: 0.0348\n",
      "val MAE: 2677.0697\n",
      "\n",
      "Epoch 39/100\n",
      "----------\n",
      "train Loss: 0.0292\n",
      "train MAE: 2524.7572\n",
      "val Loss: 0.0341\n",
      "val MAE: 2673.0000\n",
      "\n",
      "Epoch 40/100\n",
      "----------\n",
      "train Loss: 0.0278\n",
      "train MAE: 2468.9914\n",
      "val Loss: 0.0334\n",
      "val MAE: 2643.3703\n",
      "\n",
      "Epoch 41/100\n",
      "----------\n",
      "train Loss: 0.0301\n",
      "train MAE: 2583.7762\n",
      "val Loss: 0.0331\n",
      "val MAE: 2636.7283\n",
      "\n",
      "Epoch 42/100\n",
      "----------\n",
      "train Loss: 0.0275\n",
      "train MAE: 2486.2041\n",
      "val Loss: 0.0358\n",
      "val MAE: 2724.1146\n",
      "\n",
      "Epoch 43/100\n",
      "----------\n",
      "train Loss: 0.0274\n",
      "train MAE: 2464.3929\n",
      "val Loss: 0.0371\n",
      "val MAE: 2754.6189\n",
      "\n",
      "Epoch 44/100\n",
      "----------\n",
      "train Loss: 0.0274\n",
      "train MAE: 2448.7857\n",
      "val Loss: 0.0350\n",
      "val MAE: 2696.9364\n",
      "\n",
      "Epoch 45/100\n",
      "----------\n",
      "train Loss: 0.0260\n",
      "train MAE: 2377.6847\n",
      "val Loss: 0.0345\n",
      "val MAE: 2692.6416\n",
      "\n",
      "Epoch 46/100\n",
      "----------\n",
      "train Loss: 0.0262\n",
      "train MAE: 2412.9874\n",
      "val Loss: 0.0367\n",
      "val MAE: 2793.1494\n",
      "\n",
      "Epoch 47/100\n",
      "----------\n",
      "train Loss: 0.0261\n",
      "train MAE: 2401.4655\n",
      "val Loss: 0.0336\n",
      "val MAE: 2650.2304\n",
      "\n",
      "Epoch 48/100\n",
      "----------\n",
      "train Loss: 0.0259\n",
      "train MAE: 2381.1879\n",
      "val Loss: 0.0358\n",
      "val MAE: 2732.4908\n",
      "\n",
      "Epoch 49/100\n",
      "----------\n",
      "train Loss: 0.0272\n",
      "train MAE: 2448.5621\n",
      "val Loss: 0.0424\n",
      "val MAE: 3002.2060\n",
      "\n",
      "Epoch 50/100\n",
      "----------\n",
      "train Loss: 0.0261\n",
      "train MAE: 2389.3764\n",
      "val Loss: 0.0362\n",
      "val MAE: 2750.3849\n",
      "\n",
      "Epoch 51/100\n",
      "----------\n",
      "train Loss: 0.0242\n",
      "train MAE: 2297.2427\n",
      "val Loss: 0.0337\n",
      "val MAE: 2637.8767\n",
      "\n",
      "Epoch 52/100\n",
      "----------\n",
      "train Loss: 0.0247\n",
      "train MAE: 2338.9183\n",
      "val Loss: 0.0335\n",
      "val MAE: 2645.5192\n",
      "\n",
      "Epoch 53/100\n",
      "----------\n",
      "train Loss: 0.0264\n",
      "train MAE: 2408.8233\n",
      "val Loss: 0.0340\n",
      "val MAE: 2651.9630\n",
      "\n",
      "Epoch 54/100\n",
      "----------\n",
      "train Loss: 0.0248\n",
      "train MAE: 2314.1901\n",
      "val Loss: 0.0335\n",
      "val MAE: 2622.0024\n",
      "\n",
      "Epoch 55/100\n",
      "----------\n",
      "train Loss: 0.0265\n",
      "train MAE: 2365.2220\n",
      "val Loss: 0.0338\n",
      "val MAE: 2661.7550\n",
      "\n",
      "Epoch 56/100\n",
      "----------\n",
      "train Loss: 0.0263\n",
      "train MAE: 2379.1824\n",
      "val Loss: 0.0349\n",
      "val MAE: 2675.8439\n",
      "\n",
      "Epoch 57/100\n",
      "----------\n",
      "train Loss: 0.0246\n",
      "train MAE: 2300.4277\n",
      "val Loss: 0.0338\n",
      "val MAE: 2654.2581\n",
      "\n",
      "Epoch 58/100\n",
      "----------\n",
      "train Loss: 0.0232\n",
      "train MAE: 2234.9198\n",
      "val Loss: 0.0391\n",
      "val MAE: 2869.0476\n",
      "\n",
      "Epoch 59/100\n",
      "----------\n",
      "train Loss: 0.0230\n",
      "train MAE: 2224.9505\n",
      "val Loss: 0.0369\n",
      "val MAE: 2783.9198\n",
      "\n",
      "Epoch 60/100\n",
      "----------\n",
      "train Loss: 0.0242\n",
      "train MAE: 2295.5699\n",
      "val Loss: 0.0340\n",
      "val MAE: 2633.3554\n",
      "\n",
      "Epoch 61/100\n",
      "----------\n",
      "train Loss: 0.0243\n",
      "train MAE: 2297.9399\n",
      "val Loss: 0.0344\n",
      "val MAE: 2635.0004\n",
      "\n",
      "Epoch 62/100\n",
      "----------\n",
      "train Loss: 0.0226\n",
      "train MAE: 2206.1096\n",
      "val Loss: 0.0362\n",
      "val MAE: 2706.5257\n",
      "\n",
      "Epoch 63/100\n",
      "----------\n",
      "train Loss: 0.0255\n",
      "train MAE: 2368.6076\n",
      "val Loss: 0.0363\n",
      "val MAE: 2721.8558\n",
      "\n",
      "Epoch 64/100\n",
      "----------\n",
      "train Loss: 0.0242\n",
      "train MAE: 2284.5325\n",
      "val Loss: 0.0335\n",
      "val MAE: 2628.3311\n",
      "\n",
      "Epoch 65/100\n",
      "----------\n",
      "train Loss: 0.0238\n",
      "train MAE: 2278.6550\n",
      "val Loss: 0.0356\n",
      "val MAE: 2682.2857\n",
      "\n",
      "Epoch 66/100\n",
      "----------\n",
      "train Loss: 0.0231\n",
      "train MAE: 2231.0578\n",
      "val Loss: 0.0348\n",
      "val MAE: 2687.7868\n",
      "\n",
      "Epoch 67/100\n",
      "----------\n",
      "train Loss: 0.0231\n",
      "train MAE: 2222.8810\n",
      "val Loss: 0.0387\n",
      "val MAE: 2820.9360\n",
      "\n",
      "Epoch 68/100\n",
      "----------\n",
      "train Loss: 0.0212\n",
      "train MAE: 2113.0018\n",
      "val Loss: 0.0349\n",
      "val MAE: 2674.7473\n",
      "\n",
      "Epoch 69/100\n",
      "----------\n",
      "train Loss: 0.0216\n",
      "train MAE: 2159.8036\n",
      "val Loss: 0.0356\n",
      "val MAE: 2721.0420\n",
      "\n",
      "Epoch 70/100\n",
      "----------\n",
      "train Loss: 0.0215\n",
      "train MAE: 2155.2609\n",
      "val Loss: 0.0359\n",
      "val MAE: 2731.9969\n",
      "\n",
      "Epoch 71/100\n",
      "----------\n",
      "train Loss: 0.0222\n",
      "train MAE: 2177.9133\n",
      "val Loss: 0.0342\n",
      "val MAE: 2640.3364\n",
      "\n",
      "Epoch 72/100\n",
      "----------\n",
      "train Loss: 0.0203\n",
      "train MAE: 2080.7185\n",
      "val Loss: 0.0374\n",
      "val MAE: 2793.5843\n",
      "\n",
      "Epoch 73/100\n",
      "----------\n",
      "train Loss: 0.0202\n",
      "train MAE: 2087.8095\n",
      "val Loss: 0.0341\n",
      "val MAE: 2628.6109\n",
      "\n",
      "Epoch 74/100\n",
      "----------\n",
      "train Loss: 0.0205\n",
      "train MAE: 2108.7139\n",
      "val Loss: 0.0355\n",
      "val MAE: 2692.6055\n",
      "\n",
      "Epoch 75/100\n",
      "----------\n",
      "train Loss: 0.0215\n",
      "train MAE: 2137.3983\n",
      "val Loss: 0.0339\n",
      "val MAE: 2650.9656\n",
      "\n",
      "Epoch 76/100\n",
      "----------\n",
      "train Loss: 0.0193\n",
      "train MAE: 2030.1961\n",
      "val Loss: 0.0370\n",
      "val MAE: 2779.5771\n",
      "\n",
      "Epoch 77/100\n",
      "----------\n",
      "train Loss: 0.0207\n",
      "train MAE: 2105.0208\n",
      "val Loss: 0.0349\n",
      "val MAE: 2667.7491\n",
      "\n",
      "Epoch 78/100\n",
      "----------\n",
      "train Loss: 0.0203\n",
      "train MAE: 2093.1830\n",
      "val Loss: 0.0351\n",
      "val MAE: 2666.6490\n",
      "\n",
      "Epoch 79/100\n",
      "----------\n",
      "train Loss: 0.0194\n",
      "train MAE: 2019.9081\n",
      "val Loss: 0.0350\n",
      "val MAE: 2654.4963\n",
      "\n",
      "Epoch 80/100\n",
      "----------\n",
      "train Loss: 0.0207\n",
      "train MAE: 2091.6245\n",
      "val Loss: 0.0334\n",
      "val MAE: 2606.4671\n",
      "\n",
      "Epoch 81/100\n",
      "----------\n",
      "train Loss: 0.0203\n",
      "train MAE: 2088.2380\n",
      "val Loss: 0.0362\n",
      "val MAE: 2741.9325\n",
      "\n",
      "Epoch 82/100\n",
      "----------\n",
      "train Loss: 0.0211\n",
      "train MAE: 2119.7478\n",
      "val Loss: 0.0372\n",
      "val MAE: 2788.0358\n",
      "\n",
      "Epoch 83/100\n",
      "----------\n",
      "train Loss: 0.0205\n",
      "train MAE: 2099.4066\n",
      "val Loss: 0.0335\n",
      "val MAE: 2605.3692\n",
      "\n",
      "Epoch 84/100\n",
      "----------\n",
      "train Loss: 0.0198\n",
      "train MAE: 2071.1536\n",
      "val Loss: 0.0331\n",
      "val MAE: 2589.2258\n",
      "\n",
      "Epoch 85/100\n",
      "----------\n",
      "train Loss: 0.0189\n",
      "train MAE: 2021.1512\n",
      "val Loss: 0.0352\n",
      "val MAE: 2687.8546\n",
      "\n",
      "Epoch 86/100\n",
      "----------\n",
      "train Loss: 0.0197\n",
      "train MAE: 2067.1762\n",
      "val Loss: 0.0341\n",
      "val MAE: 2636.9621\n",
      "\n",
      "Epoch 87/100\n",
      "----------\n",
      "train Loss: 0.0197\n",
      "train MAE: 2031.4942\n",
      "val Loss: 0.0354\n",
      "val MAE: 2702.8765\n",
      "\n",
      "Epoch 88/100\n",
      "----------\n",
      "train Loss: 0.0192\n",
      "train MAE: 2024.7732\n",
      "val Loss: 0.0337\n",
      "val MAE: 2622.5125\n",
      "\n",
      "Epoch 89/100\n",
      "----------\n",
      "train Loss: 0.0183\n",
      "train MAE: 1974.6190\n",
      "val Loss: 0.0340\n",
      "val MAE: 2631.6849\n",
      "\n",
      "Epoch 90/100\n",
      "----------\n",
      "train Loss: 0.0179\n",
      "train MAE: 1964.8961\n",
      "val Loss: 0.0339\n",
      "val MAE: 2617.4313\n",
      "\n",
      "Epoch 91/100\n",
      "----------\n",
      "train Loss: 0.0191\n",
      "train MAE: 2015.2003\n",
      "val Loss: 0.0345\n",
      "val MAE: 2679.7525\n",
      "\n",
      "Epoch 92/100\n",
      "----------\n",
      "train Loss: 0.0184\n",
      "train MAE: 1990.3702\n",
      "val Loss: 0.0321\n",
      "val MAE: 2557.1663\n",
      "\n",
      "Epoch 93/100\n",
      "----------\n",
      "train Loss: 0.0176\n",
      "train MAE: 1942.9911\n",
      "val Loss: 0.0342\n",
      "val MAE: 2627.5322\n",
      "\n",
      "Epoch 94/100\n",
      "----------\n",
      "train Loss: 0.0180\n",
      "train MAE: 1951.4083\n",
      "val Loss: 0.0335\n",
      "val MAE: 2613.3381\n",
      "\n",
      "Epoch 95/100\n",
      "----------\n",
      "train Loss: 0.0181\n",
      "train MAE: 1958.1390\n",
      "val Loss: 0.0328\n",
      "val MAE: 2578.0854\n",
      "\n",
      "Epoch 96/100\n",
      "----------\n",
      "train Loss: 0.0177\n",
      "train MAE: 1948.8351\n",
      "val Loss: 0.0326\n",
      "val MAE: 2579.8559\n",
      "\n",
      "Epoch 97/100\n",
      "----------\n",
      "train Loss: 0.0176\n",
      "train MAE: 1903.5524\n",
      "val Loss: 0.0360\n",
      "val MAE: 2734.5057\n",
      "\n",
      "Epoch 98/100\n",
      "----------\n",
      "train Loss: 0.0185\n",
      "train MAE: 1981.6629\n",
      "val Loss: 0.0334\n",
      "val MAE: 2616.8964\n",
      "\n",
      "Epoch 99/100\n",
      "----------\n",
      "train Loss: 0.0170\n",
      "train MAE: 1883.3854\n",
      "val Loss: 0.0331\n",
      "val MAE: 2591.5316\n",
      "\n",
      "Epoch 100/100\n",
      "----------\n",
      "train Loss: 0.0186\n",
      "train MAE: 1972.6151\n",
      "val Loss: 0.0334\n",
      "val MAE: 2602.9485\n",
      "\n",
      "Training complete in 127m 10s\n",
      "Best val Loss: 0.032124 at epoch 92\n",
      "Best val MAE: 2557.166306 at epoch 92\n",
      "\n",
      "Load the model weights at the best epoch\n"
     ]
    }
   ],
   "source": [
    "model_res152, mae_list_2, all_loss_2, all_mae_2 = train_model(model_ft, model_LU, criterion, optimizer_ft, exp_lr_scheduler, num_epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. (2053, 32, 1) + Tanh + scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "### ResNet18\n",
    "model_ft = models.resnet152(pretrained=True)\n",
    "num_ftrs = model_ft.fc.in_features\n",
    "model_ft.fc = nn.Identity()\n",
    "\n",
    "### Freeze and Fine Tuning\n",
    "for param in model_ft.parameters():\n",
    "    param.requires_grad = False\n",
    "for param in model_ft.layer3.parameters():\n",
    "    param.requires_grad = True\n",
    "for param in model_ft.layer4.parameters():\n",
    "    param.requires_grad = True\n",
    "assert [param.requires_grad for param in model_ft.parameters()][-1]\n",
    "\n",
    "### LU\n",
    "model_LU = nn.Sequential(\n",
    "    nn.Linear(num_ftrs + num_tabular_features, 32),\n",
    "    nn.Tanh(),\n",
    "    nn.Linear(32, 1)\n",
    ")\n",
    "\n",
    "### model setup\n",
    "model_ft = model_ft.to(device)\n",
    "model_LU = model_LU.to(device)\n",
    "criterion = nn.MSELoss()\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.SGD(list(model_ft.parameters())+list(model_LU.parameters()), lr=0.001, momentum=0.9)\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = lr_scheduler.ReduceLROnPlateau(optimizer_ft, factor=0.1, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "----------\n",
      "train Loss: 0.0920\n",
      "train MAE: 4535.2421\n",
      "val Loss: 0.0523\n",
      "val MAE: 3356.5317\n",
      "\n",
      "Epoch 2/200\n",
      "----------\n",
      "train Loss: 0.0679\n",
      "train MAE: 3891.7404\n",
      "val Loss: 0.0478\n",
      "val MAE: 3216.1251\n",
      "\n",
      "Epoch 3/200\n",
      "----------\n",
      "train Loss: 0.0594\n",
      "train MAE: 3630.5861\n",
      "val Loss: 0.0431\n",
      "val MAE: 3053.6034\n",
      "\n",
      "Epoch 4/200\n",
      "----------\n",
      "train Loss: 0.0560\n",
      "train MAE: 3548.3931\n",
      "val Loss: 0.0595\n",
      "val MAE: 3654.5785\n",
      "\n",
      "Epoch 5/200\n",
      "----------\n",
      "train Loss: 0.0537\n",
      "train MAE: 3471.4900\n",
      "val Loss: 0.0413\n",
      "val MAE: 2977.3775\n",
      "\n",
      "Epoch 6/200\n",
      "----------\n",
      "train Loss: 0.0490\n",
      "train MAE: 3301.3993\n",
      "val Loss: 0.0452\n",
      "val MAE: 3131.4367\n",
      "\n",
      "Epoch 7/200\n",
      "----------\n",
      "train Loss: 0.0492\n",
      "train MAE: 3296.0732\n",
      "val Loss: 0.0728\n",
      "val MAE: 4225.8910\n",
      "\n",
      "Epoch 8/200\n",
      "----------\n",
      "train Loss: 0.0473\n",
      "train MAE: 3263.1863\n",
      "val Loss: 0.0402\n",
      "val MAE: 2902.3317\n",
      "\n",
      "Epoch 9/200\n",
      "----------\n",
      "train Loss: 0.0468\n",
      "train MAE: 3229.6498\n",
      "val Loss: 0.0455\n",
      "val MAE: 3138.5456\n",
      "\n",
      "Epoch 10/200\n",
      "----------\n",
      "train Loss: 0.0453\n",
      "train MAE: 3165.9938\n",
      "val Loss: 0.0379\n",
      "val MAE: 2833.5303\n",
      "\n",
      "Epoch 11/200\n",
      "----------\n",
      "train Loss: 0.0447\n",
      "train MAE: 3141.4974\n",
      "val Loss: 0.0367\n",
      "val MAE: 2794.2160\n",
      "\n",
      "Epoch 12/200\n",
      "----------\n",
      "train Loss: 0.0431\n",
      "train MAE: 3103.1130\n",
      "val Loss: 0.0370\n",
      "val MAE: 2793.8891\n",
      "\n",
      "Epoch 13/200\n",
      "----------\n",
      "train Loss: 0.0428\n",
      "train MAE: 3084.0248\n",
      "val Loss: 0.0383\n",
      "val MAE: 2866.4532\n",
      "\n",
      "Epoch 14/200\n",
      "----------\n",
      "train Loss: 0.0411\n",
      "train MAE: 3048.4883\n",
      "val Loss: 0.0365\n",
      "val MAE: 2774.5507\n",
      "\n",
      "Epoch 15/200\n",
      "----------\n",
      "train Loss: 0.0389\n",
      "train MAE: 2912.0088\n",
      "val Loss: 0.0369\n",
      "val MAE: 2806.2991\n",
      "\n",
      "Epoch 16/200\n",
      "----------\n",
      "train Loss: 0.0401\n",
      "train MAE: 2987.6964\n",
      "val Loss: 0.0377\n",
      "val MAE: 2817.9862\n",
      "\n",
      "Epoch 17/200\n",
      "----------\n",
      "train Loss: 0.0383\n",
      "train MAE: 2905.2907\n",
      "val Loss: 0.0354\n",
      "val MAE: 2726.3468\n",
      "\n",
      "Epoch 18/200\n",
      "----------\n",
      "train Loss: 0.0370\n",
      "train MAE: 2876.2686\n",
      "val Loss: 0.0360\n",
      "val MAE: 2741.4136\n",
      "\n",
      "Epoch 19/200\n",
      "----------\n",
      "train Loss: 0.0379\n",
      "train MAE: 2908.0970\n",
      "val Loss: 0.0378\n",
      "val MAE: 2839.0845\n",
      "\n",
      "Epoch 20/200\n",
      "----------\n",
      "train Loss: 0.0371\n",
      "train MAE: 2858.0423\n",
      "val Loss: 0.0382\n",
      "val MAE: 2826.9361\n",
      "\n",
      "Epoch 21/200\n",
      "----------\n",
      "train Loss: 0.0375\n",
      "train MAE: 2891.0503\n",
      "val Loss: 0.0344\n",
      "val MAE: 2686.6068\n",
      "\n",
      "Epoch 22/200\n",
      "----------\n",
      "train Loss: 0.0346\n",
      "train MAE: 2766.9504\n",
      "val Loss: 0.0354\n",
      "val MAE: 2730.4396\n",
      "\n",
      "Epoch 23/200\n",
      "----------\n",
      "train Loss: 0.0360\n",
      "train MAE: 2822.1457\n",
      "val Loss: 0.0348\n",
      "val MAE: 2690.7793\n",
      "\n",
      "Epoch 24/200\n",
      "----------\n",
      "train Loss: 0.0336\n",
      "train MAE: 2737.9397\n",
      "val Loss: 0.0340\n",
      "val MAE: 2693.9396\n",
      "\n",
      "Epoch 25/200\n",
      "----------\n",
      "train Loss: 0.0337\n",
      "train MAE: 2709.4253\n",
      "val Loss: 0.0341\n",
      "val MAE: 2668.4661\n",
      "\n",
      "Epoch 26/200\n",
      "----------\n",
      "train Loss: 0.0326\n",
      "train MAE: 2678.9225\n",
      "val Loss: 0.0339\n",
      "val MAE: 2671.1304\n",
      "\n",
      "Epoch 27/200\n",
      "----------\n",
      "train Loss: 0.0347\n",
      "train MAE: 2790.4041\n",
      "val Loss: 0.0343\n",
      "val MAE: 2698.2761\n",
      "\n",
      "Epoch 28/200\n",
      "----------\n",
      "train Loss: 0.0333\n",
      "train MAE: 2719.0339\n",
      "val Loss: 0.0345\n",
      "val MAE: 2677.9349\n",
      "\n",
      "Epoch 29/200\n",
      "----------\n",
      "train Loss: 0.0328\n",
      "train MAE: 2684.4587\n",
      "val Loss: 0.0457\n",
      "val MAE: 3131.3251\n",
      "\n",
      "Epoch 30/200\n",
      "----------\n",
      "train Loss: 0.0341\n",
      "train MAE: 2722.6432\n",
      "val Loss: 0.0349\n",
      "val MAE: 2688.7212\n",
      "\n",
      "Epoch 31/200\n",
      "----------\n",
      "train Loss: 0.0298\n",
      "train MAE: 2559.4885\n",
      "val Loss: 0.0364\n",
      "val MAE: 2791.4843\n",
      "\n",
      "Epoch 32/200\n",
      "----------\n",
      "train Loss: 0.0319\n",
      "train MAE: 2620.4590\n",
      "val Loss: 0.0364\n",
      "val MAE: 2784.6195\n",
      "\n",
      "Epoch 33/200\n",
      "----------\n",
      "train Loss: 0.0310\n",
      "train MAE: 2575.6924\n",
      "val Loss: 0.0342\n",
      "val MAE: 2680.0144\n",
      "\n",
      "Epoch 34/200\n",
      "----------\n",
      "train Loss: 0.0303\n",
      "train MAE: 2570.9976\n",
      "val Loss: 0.0350\n",
      "val MAE: 2710.5532\n",
      "\n",
      "Epoch 35/200\n",
      "----------\n",
      "train Loss: 0.0301\n",
      "train MAE: 2569.2446\n",
      "val Loss: 0.0346\n",
      "val MAE: 2682.5717\n",
      "\n",
      "Epoch 36/200\n",
      "----------\n",
      "train Loss: 0.0282\n",
      "train MAE: 2463.9406\n",
      "val Loss: 0.0344\n",
      "val MAE: 2675.8096\n",
      "\n",
      "Epoch 37/200\n",
      "----------\n",
      "train Loss: 0.0295\n",
      "train MAE: 2545.6535\n",
      "val Loss: 0.0338\n",
      "val MAE: 2657.6297\n",
      "\n",
      "Epoch 38/200\n",
      "----------\n",
      "train Loss: 0.0290\n",
      "train MAE: 2524.1734\n",
      "val Loss: 0.0348\n",
      "val MAE: 2677.5123\n",
      "\n",
      "Epoch 39/200\n",
      "----------\n",
      "train Loss: 0.0292\n",
      "train MAE: 2523.2922\n",
      "val Loss: 0.0341\n",
      "val MAE: 2670.8800\n",
      "\n",
      "Epoch 40/200\n",
      "----------\n",
      "train Loss: 0.0278\n",
      "train MAE: 2469.5144\n",
      "val Loss: 0.0334\n",
      "val MAE: 2643.0682\n",
      "\n",
      "Epoch 41/200\n",
      "----------\n",
      "train Loss: 0.0301\n",
      "train MAE: 2587.6863\n",
      "val Loss: 0.0331\n",
      "val MAE: 2636.8698\n",
      "\n",
      "Epoch 42/200\n",
      "----------\n",
      "train Loss: 0.0275\n",
      "train MAE: 2484.1259\n",
      "val Loss: 0.0359\n",
      "val MAE: 2729.7132\n",
      "\n",
      "Epoch 43/200\n",
      "----------\n",
      "train Loss: 0.0274\n",
      "train MAE: 2465.2749\n",
      "val Loss: 0.0372\n",
      "val MAE: 2753.1992\n",
      "\n",
      "Epoch 44/200\n",
      "----------\n",
      "train Loss: 0.0274\n",
      "train MAE: 2450.5398\n",
      "val Loss: 0.0350\n",
      "val MAE: 2692.4524\n",
      "\n",
      "Epoch 45/200\n",
      "----------\n",
      "train Loss: 0.0260\n",
      "train MAE: 2377.7105\n",
      "val Loss: 0.0344\n",
      "val MAE: 2691.4683\n",
      "\n",
      "Epoch 46/200\n",
      "----------\n",
      "train Loss: 0.0262\n",
      "train MAE: 2412.7788\n",
      "val Loss: 0.0367\n",
      "val MAE: 2794.6190\n",
      "\n",
      "Epoch 47/200\n",
      "----------\n",
      "train Loss: 0.0261\n",
      "train MAE: 2401.2700\n",
      "val Loss: 0.0335\n",
      "val MAE: 2648.1595\n",
      "\n",
      "Epoch 48/200\n",
      "----------\n",
      "train Loss: 0.0259\n",
      "train MAE: 2379.1390\n",
      "val Loss: 0.0358\n",
      "val MAE: 2730.5814\n",
      "\n",
      "Epoch 49/200\n",
      "----------\n",
      "train Loss: 0.0272\n",
      "train MAE: 2447.4025\n",
      "val Loss: 0.0424\n",
      "val MAE: 2996.0730\n",
      "\n",
      "Epoch 50/200\n",
      "----------\n",
      "train Loss: 0.0261\n",
      "train MAE: 2389.7746\n",
      "val Loss: 0.0361\n",
      "val MAE: 2747.7303\n",
      "\n",
      "Epoch 51/200\n",
      "----------\n",
      "train Loss: 0.0241\n",
      "train MAE: 2295.2590\n",
      "val Loss: 0.0336\n",
      "val MAE: 2637.8550\n",
      "\n",
      "Epoch 52/200\n",
      "----------\n",
      "train Loss: 0.0247\n",
      "train MAE: 2339.3956\n",
      "val Loss: 0.0334\n",
      "val MAE: 2644.7888\n",
      "\n",
      "Epoch 53/200\n",
      "----------\n",
      "train Loss: 0.0263\n",
      "train MAE: 2403.7123\n",
      "val Loss: 0.0339\n",
      "val MAE: 2649.7756\n",
      "\n",
      "Epoch 54/200\n",
      "----------\n",
      "train Loss: 0.0248\n",
      "train MAE: 2312.7950\n",
      "val Loss: 0.0335\n",
      "val MAE: 2622.4277\n",
      "\n",
      "Epoch 55/200\n",
      "----------\n",
      "train Loss: 0.0265\n",
      "train MAE: 2367.5985\n",
      "val Loss: 0.0338\n",
      "val MAE: 2658.2616\n",
      "\n",
      "Epoch 56/200\n",
      "----------\n",
      "train Loss: 0.0263\n",
      "train MAE: 2377.6980\n",
      "val Loss: 0.0349\n",
      "val MAE: 2675.6284\n",
      "\n",
      "Epoch 57/200\n",
      "----------\n",
      "train Loss: 0.0246\n",
      "train MAE: 2301.2238\n",
      "val Loss: 0.0338\n",
      "val MAE: 2651.9690\n",
      "\n",
      "Epoch 58/200\n",
      "----------\n",
      "train Loss: 0.0233\n",
      "train MAE: 2237.6202\n",
      "val Loss: 0.0388\n",
      "val MAE: 2857.6735\n",
      "\n",
      "Epoch 59/200\n",
      "----------\n",
      "train Loss: 0.0230\n",
      "train MAE: 2225.6781\n",
      "val Loss: 0.0367\n",
      "val MAE: 2776.9530\n",
      "\n",
      "Epoch 60/200\n",
      "----------\n",
      "train Loss: 0.0242\n",
      "train MAE: 2289.9358\n",
      "val Loss: 0.0339\n",
      "val MAE: 2630.2160\n",
      "\n",
      "Epoch 61/200\n",
      "----------\n",
      "train Loss: 0.0243\n",
      "train MAE: 2300.9563\n",
      "val Loss: 0.0343\n",
      "val MAE: 2632.4008\n",
      "\n",
      "Epoch 62/200\n",
      "----------\n",
      "train Loss: 0.0226\n",
      "train MAE: 2205.8868\n",
      "val Loss: 0.0362\n",
      "val MAE: 2701.6072\n",
      "\n",
      "Epoch 63/200\n",
      "----------\n",
      "train Loss: 0.0255\n",
      "train MAE: 2370.4465\n",
      "val Loss: 0.0363\n",
      "val MAE: 2721.3988\n",
      "\n",
      "Epoch 64/200\n",
      "----------\n",
      "train Loss: 0.0242\n",
      "train MAE: 2281.7822\n",
      "val Loss: 0.0334\n",
      "val MAE: 2626.0727\n",
      "\n",
      "Epoch 65/200\n",
      "----------\n",
      "train Loss: 0.0238\n",
      "train MAE: 2275.3078\n",
      "val Loss: 0.0355\n",
      "val MAE: 2679.5938\n",
      "\n",
      "Epoch 66/200\n",
      "----------\n",
      "train Loss: 0.0231\n",
      "train MAE: 2230.6080\n",
      "val Loss: 0.0349\n",
      "val MAE: 2688.0226\n",
      "\n",
      "Epoch 67/200\n",
      "----------\n",
      "train Loss: 0.0231\n",
      "train MAE: 2222.5960\n",
      "val Loss: 0.0389\n",
      "val MAE: 2829.8490\n",
      "\n",
      "Epoch 68/200\n",
      "----------\n",
      "train Loss: 0.0212\n",
      "train MAE: 2114.3891\n",
      "val Loss: 0.0349\n",
      "val MAE: 2678.6346\n",
      "\n",
      "Epoch 69/200\n",
      "----------\n",
      "train Loss: 0.0215\n",
      "train MAE: 2157.1275\n",
      "val Loss: 0.0354\n",
      "val MAE: 2716.8587\n",
      "\n",
      "Epoch 70/200\n",
      "----------\n",
      "train Loss: 0.0215\n",
      "train MAE: 2158.7370\n",
      "val Loss: 0.0358\n",
      "val MAE: 2731.0678\n",
      "\n",
      "Epoch 71/200\n",
      "----------\n",
      "train Loss: 0.0222\n",
      "train MAE: 2180.6044\n",
      "val Loss: 0.0343\n",
      "val MAE: 2645.9521\n",
      "\n",
      "Epoch 72/200\n",
      "----------\n",
      "train Loss: 0.0204\n",
      "train MAE: 2084.4331\n",
      "val Loss: 0.0375\n",
      "val MAE: 2794.9208\n",
      "\n",
      "Epoch 73/200\n",
      "----------\n",
      "train Loss: 0.0201\n",
      "train MAE: 2087.0050\n",
      "val Loss: 0.0340\n",
      "val MAE: 2629.1363\n",
      "\n",
      "Epoch 74/200\n",
      "----------\n",
      "train Loss: 0.0206\n",
      "train MAE: 2113.4256\n",
      "val Loss: 0.0355\n",
      "val MAE: 2697.2648\n",
      "\n",
      "Epoch 75/200\n",
      "----------\n",
      "train Loss: 0.0215\n",
      "train MAE: 2139.1300\n",
      "val Loss: 0.0337\n",
      "val MAE: 2642.7662\n",
      "\n",
      "Epoch 76/200\n",
      "----------\n",
      "train Loss: 0.0193\n",
      "train MAE: 2027.0276\n",
      "val Loss: 0.0370\n",
      "val MAE: 2783.3083\n",
      "\n",
      "Epoch 77/200\n",
      "----------\n",
      "train Loss: 0.0207\n",
      "train MAE: 2103.8158\n",
      "val Loss: 0.0349\n",
      "val MAE: 2670.7714\n",
      "\n",
      "Epoch 78/200\n",
      "----------\n",
      "train Loss: 0.0203\n",
      "train MAE: 2093.6228\n",
      "val Loss: 0.0350\n",
      "val MAE: 2661.5856\n",
      "\n",
      "Epoch 79/200\n",
      "----------\n",
      "train Loss: 0.0194\n",
      "train MAE: 2017.6518\n",
      "val Loss: 0.0350\n",
      "val MAE: 2655.7093\n",
      "\n",
      "Epoch 80/200\n",
      "----------\n",
      "train Loss: 0.0207\n",
      "train MAE: 2092.8741\n",
      "val Loss: 0.0334\n",
      "val MAE: 2606.8776\n",
      "\n",
      "Epoch 81/200\n",
      "----------\n",
      "train Loss: 0.0203\n",
      "train MAE: 2086.8900\n",
      "val Loss: 0.0362\n",
      "val MAE: 2745.3170\n",
      "\n",
      "Epoch 82/200\n",
      "----------\n",
      "train Loss: 0.0211\n",
      "train MAE: 2119.7583\n",
      "val Loss: 0.0374\n",
      "val MAE: 2797.9869\n",
      "\n",
      "Epoch 83/200\n",
      "----------\n",
      "train Loss: 0.0205\n",
      "train MAE: 2098.6072\n",
      "val Loss: 0.0335\n",
      "val MAE: 2605.8994\n",
      "\n",
      "Epoch 84/200\n",
      "----------\n",
      "train Loss: 0.0198\n",
      "train MAE: 2073.8098\n",
      "val Loss: 0.0333\n",
      "val MAE: 2596.9175\n",
      "\n",
      "Epoch 85/200\n",
      "----------\n",
      "train Loss: 0.0189\n",
      "train MAE: 2026.7907\n",
      "val Loss: 0.0353\n",
      "val MAE: 2690.5087\n",
      "\n",
      "Epoch 86/200\n",
      "----------\n",
      "train Loss: 0.0197\n",
      "train MAE: 2065.2211\n",
      "val Loss: 0.0342\n",
      "val MAE: 2639.0130\n",
      "\n",
      "Epoch 87/200\n",
      "----------\n",
      "train Loss: 0.0197\n",
      "train MAE: 2034.1738\n",
      "val Loss: 0.0353\n",
      "val MAE: 2693.4949\n",
      "\n",
      "Epoch 88/200\n",
      "----------\n",
      "train Loss: 0.0193\n",
      "train MAE: 2026.9381\n",
      "val Loss: 0.0337\n",
      "val MAE: 2624.8005\n",
      "\n",
      "Epoch 89/200\n",
      "----------\n",
      "train Loss: 0.0183\n",
      "train MAE: 1976.2853\n",
      "val Loss: 0.0339\n",
      "val MAE: 2626.9341\n",
      "\n",
      "Epoch 90/200\n",
      "----------\n",
      "train Loss: 0.0179\n",
      "train MAE: 1964.0998\n",
      "val Loss: 0.0340\n",
      "val MAE: 2618.5476\n",
      "\n",
      "Epoch 91/200\n",
      "----------\n",
      "train Loss: 0.0191\n",
      "train MAE: 2015.5395\n",
      "val Loss: 0.0344\n",
      "val MAE: 2676.1342\n",
      "\n",
      "Epoch 92/200\n",
      "----------\n",
      "train Loss: 0.0183\n",
      "train MAE: 1990.2349\n",
      "val Loss: 0.0322\n",
      "val MAE: 2558.8403\n",
      "\n",
      "Epoch 93/200\n",
      "----------\n",
      "train Loss: 0.0176\n",
      "train MAE: 1944.6276\n",
      "val Loss: 0.0342\n",
      "val MAE: 2629.2789\n",
      "\n",
      "Epoch 94/200\n",
      "----------\n",
      "train Loss: 0.0180\n",
      "train MAE: 1952.2149\n",
      "val Loss: 0.0336\n",
      "val MAE: 2616.5109\n",
      "\n",
      "Epoch 95/200\n",
      "----------\n",
      "train Loss: 0.0181\n",
      "train MAE: 1954.7404\n",
      "val Loss: 0.0327\n",
      "val MAE: 2578.6947\n",
      "\n",
      "Epoch 96/200\n",
      "----------\n",
      "train Loss: 0.0177\n",
      "train MAE: 1947.2207\n",
      "val Loss: 0.0326\n",
      "val MAE: 2579.6255\n",
      "\n",
      "Epoch 97/200\n",
      "----------\n",
      "train Loss: 0.0176\n",
      "train MAE: 1906.4696\n",
      "val Loss: 0.0360\n",
      "val MAE: 2733.1002\n",
      "\n",
      "Epoch 98/200\n",
      "----------\n",
      "train Loss: 0.0185\n",
      "train MAE: 1982.6232\n",
      "val Loss: 0.0333\n",
      "val MAE: 2620.9816\n",
      "\n",
      "Epoch 99/200\n",
      "----------\n",
      "train Loss: 0.0170\n",
      "train MAE: 1884.1173\n",
      "val Loss: 0.0331\n",
      "val MAE: 2592.4029\n",
      "\n",
      "Epoch 100/200\n",
      "----------\n",
      "train Loss: 0.0186\n",
      "train MAE: 1972.5100\n",
      "val Loss: 0.0334\n",
      "val MAE: 2605.5570\n",
      "\n",
      "Epoch 101/200\n",
      "----------\n",
      "train Loss: 0.0165\n",
      "train MAE: 1861.5060\n",
      "val Loss: 0.0340\n",
      "val MAE: 2628.5903\n",
      "\n",
      "Epoch 102/200\n",
      "----------\n",
      "train Loss: 0.0179\n",
      "train MAE: 1942.2121\n",
      "val Loss: 0.0325\n",
      "val MAE: 2576.1024\n",
      "\n",
      "Epoch 103/200\n",
      "----------\n",
      "train Loss: 0.0185\n",
      "train MAE: 1977.2012\n",
      "val Loss: 0.0337\n",
      "val MAE: 2609.2970\n",
      "\n",
      "Epoch 104/200\n",
      "----------\n",
      "train Loss: 0.0178\n",
      "train MAE: 1956.8444\n",
      "val Loss: 0.0332\n",
      "val MAE: 2589.4202\n",
      "\n",
      "Epoch 105/200\n",
      "----------\n",
      "train Loss: 0.0176\n",
      "train MAE: 1916.2361\n",
      "val Loss: 0.0335\n",
      "val MAE: 2602.8085\n",
      "\n",
      "Epoch 106/200\n",
      "----------\n",
      "train Loss: 0.0170\n",
      "train MAE: 1906.3088\n",
      "val Loss: 0.0353\n",
      "val MAE: 2679.4598\n",
      "\n",
      "Epoch 107/200\n",
      "----------\n",
      "train Loss: 0.0170\n",
      "train MAE: 1900.9067\n",
      "val Loss: 0.0339\n",
      "val MAE: 2610.7387\n",
      "\n",
      "Epoch 108/200\n",
      "----------\n",
      "train Loss: 0.0165\n",
      "train MAE: 1883.5866\n",
      "val Loss: 0.0345\n",
      "val MAE: 2640.8393\n",
      "\n",
      "Epoch 109/200\n",
      "----------\n",
      "train Loss: 0.0179\n",
      "train MAE: 1940.1840\n",
      "val Loss: 0.0338\n",
      "val MAE: 2626.0692\n",
      "\n",
      "Epoch 110/200\n",
      "----------\n",
      "train Loss: 0.0171\n",
      "train MAE: 1897.6223\n",
      "val Loss: 0.0340\n",
      "val MAE: 2621.7281\n",
      "\n",
      "Epoch 111/200\n",
      "----------\n",
      "train Loss: 0.0171\n",
      "train MAE: 1895.0257\n",
      "val Loss: 0.0340\n",
      "val MAE: 2619.0869\n",
      "\n",
      "Epoch 112/200\n",
      "----------\n",
      "train Loss: 0.0157\n",
      "train MAE: 1809.3821\n",
      "val Loss: 0.0336\n",
      "val MAE: 2598.7003\n",
      "\n",
      "Epoch 113/200\n",
      "----------\n",
      "train Loss: 0.0159\n",
      "train MAE: 1825.7581\n",
      "val Loss: 0.0331\n",
      "val MAE: 2590.2804\n",
      "\n",
      "Epoch 114/200\n",
      "----------\n",
      "train Loss: 0.0158\n",
      "train MAE: 1835.2291\n",
      "val Loss: 0.0334\n",
      "val MAE: 2590.5757\n",
      "\n",
      "Epoch 115/200\n",
      "----------\n",
      "train Loss: 0.0166\n",
      "train MAE: 1885.5462\n",
      "val Loss: 0.0340\n",
      "val MAE: 2612.9974\n",
      "\n",
      "Epoch 116/200\n",
      "----------\n",
      "train Loss: 0.0169\n",
      "train MAE: 1846.9747\n",
      "val Loss: 0.0325\n",
      "val MAE: 2555.2342\n",
      "\n",
      "Epoch 117/200\n",
      "----------\n",
      "train Loss: 0.0157\n",
      "train MAE: 1783.7952\n",
      "val Loss: 0.0337\n",
      "val MAE: 2601.1486\n",
      "\n",
      "Epoch 118/200\n",
      "----------\n",
      "train Loss: 0.0165\n",
      "train MAE: 1853.6223\n",
      "val Loss: 0.0366\n",
      "val MAE: 2776.2714\n",
      "\n",
      "Epoch 119/200\n",
      "----------\n",
      "train Loss: 0.0155\n",
      "train MAE: 1823.4979\n",
      "val Loss: 0.0337\n",
      "val MAE: 2605.8647\n",
      "\n",
      "Epoch 120/200\n",
      "----------\n",
      "train Loss: 0.0167\n",
      "train MAE: 1860.3015\n",
      "val Loss: 0.0327\n",
      "val MAE: 2556.1717\n",
      "\n",
      "Epoch 121/200\n",
      "----------\n",
      "train Loss: 0.0150\n",
      "train MAE: 1774.2144\n",
      "val Loss: 0.0325\n",
      "val MAE: 2570.9235\n",
      "\n",
      "Epoch 122/200\n",
      "----------\n",
      "train Loss: 0.0158\n",
      "train MAE: 1844.9364\n",
      "val Loss: 0.0325\n",
      "val MAE: 2561.0025\n",
      "\n",
      "Epoch 123/200\n",
      "----------\n",
      "train Loss: 0.0162\n",
      "train MAE: 1845.8862\n",
      "val Loss: 0.0332\n",
      "val MAE: 2580.1797\n",
      "\n",
      "Epoch 124/200\n",
      "----------\n",
      "train Loss: 0.0170\n",
      "train MAE: 1855.3857\n",
      "val Loss: 0.0341\n",
      "val MAE: 2622.0382\n",
      "\n",
      "Epoch 125/200\n",
      "----------\n",
      "train Loss: 0.0148\n",
      "train MAE: 1770.6116\n",
      "val Loss: 0.0330\n",
      "val MAE: 2571.9152\n",
      "\n",
      "Epoch 126/200\n",
      "----------\n",
      "train Loss: 0.0153\n",
      "train MAE: 1783.3201\n",
      "val Loss: 0.0360\n",
      "val MAE: 2689.4654\n",
      "\n",
      "Epoch 127/200\n",
      "----------\n",
      "train Loss: 0.0145\n",
      "train MAE: 1738.3844\n",
      "val Loss: 0.0331\n",
      "val MAE: 2561.3311\n",
      "\n",
      "Epoch 128/200\n",
      "----------\n",
      "train Loss: 0.0147\n",
      "train MAE: 1784.4264\n",
      "val Loss: 0.0347\n",
      "val MAE: 2675.6805\n",
      "\n",
      "Epoch 129/200\n",
      "----------\n",
      "train Loss: 0.0151\n",
      "train MAE: 1806.6839\n",
      "val Loss: 0.0359\n",
      "val MAE: 2737.8629\n",
      "\n",
      "Epoch 130/200\n",
      "----------\n",
      "train Loss: 0.0155\n",
      "train MAE: 1834.5076\n",
      "val Loss: 0.0328\n",
      "val MAE: 2563.6449\n",
      "\n",
      "Epoch 131/200\n",
      "----------\n",
      "train Loss: 0.0154\n",
      "train MAE: 1818.1931\n",
      "val Loss: 0.0325\n",
      "val MAE: 2542.6389\n",
      "\n",
      "Epoch 132/200\n",
      "----------\n",
      "train Loss: 0.0152\n",
      "train MAE: 1775.6718\n",
      "val Loss: 0.0332\n",
      "val MAE: 2581.6339\n",
      "\n",
      "Epoch 133/200\n",
      "----------\n",
      "train Loss: 0.0146\n",
      "train MAE: 1758.6303\n",
      "val Loss: 0.0324\n",
      "val MAE: 2547.2008\n",
      "\n",
      "Epoch 134/200\n",
      "----------\n",
      "train Loss: 0.0149\n",
      "train MAE: 1769.0215\n",
      "val Loss: 0.0353\n",
      "val MAE: 2693.7193\n",
      "\n",
      "Epoch 135/200\n",
      "----------\n",
      "train Loss: 0.0145\n",
      "train MAE: 1727.7236\n",
      "val Loss: 0.0322\n",
      "val MAE: 2553.5988\n",
      "\n",
      "Epoch 136/200\n",
      "----------\n",
      "train Loss: 0.0146\n",
      "train MAE: 1745.7777\n",
      "val Loss: 0.0328\n",
      "val MAE: 2579.6772\n",
      "\n",
      "Epoch 137/200\n",
      "----------\n",
      "train Loss: 0.0146\n",
      "train MAE: 1769.4969\n",
      "val Loss: 0.0321\n",
      "val MAE: 2540.0731\n",
      "\n",
      "Epoch 138/200\n",
      "----------\n",
      "train Loss: 0.0139\n",
      "train MAE: 1734.5096\n",
      "val Loss: 0.0330\n",
      "val MAE: 2567.1046\n",
      "\n",
      "Epoch 139/200\n",
      "----------\n",
      "train Loss: 0.0143\n",
      "train MAE: 1755.7698\n",
      "val Loss: 0.0328\n",
      "val MAE: 2559.7245\n",
      "\n",
      "Epoch 140/200\n",
      "----------\n",
      "train Loss: 0.0147\n",
      "train MAE: 1762.9191\n",
      "val Loss: 0.0322\n",
      "val MAE: 2532.0390\n",
      "\n",
      "Epoch 141/200\n",
      "----------\n",
      "train Loss: 0.0147\n",
      "train MAE: 1738.5503\n",
      "val Loss: 0.0327\n",
      "val MAE: 2550.7742\n",
      "\n",
      "Epoch 142/200\n",
      "----------\n",
      "train Loss: 0.0152\n",
      "train MAE: 1780.0208\n",
      "val Loss: 0.0326\n",
      "val MAE: 2564.2015\n",
      "\n",
      "Epoch 143/200\n",
      "----------\n",
      "train Loss: 0.0150\n",
      "train MAE: 1748.8760\n",
      "val Loss: 0.0319\n",
      "val MAE: 2525.6634\n",
      "\n",
      "Epoch 144/200\n",
      "----------\n",
      "train Loss: 0.0148\n",
      "train MAE: 1759.6001\n",
      "val Loss: 0.0338\n",
      "val MAE: 2587.4607\n",
      "\n",
      "Epoch 145/200\n",
      "----------\n",
      "train Loss: 0.0152\n",
      "train MAE: 1793.7201\n",
      "val Loss: 0.0343\n",
      "val MAE: 2620.6259\n",
      "\n",
      "Epoch 146/200\n",
      "----------\n",
      "train Loss: 0.0141\n",
      "train MAE: 1718.5834\n",
      "val Loss: 0.0322\n",
      "val MAE: 2526.0053\n",
      "\n",
      "Epoch 147/200\n",
      "----------\n",
      "train Loss: 0.0140\n",
      "train MAE: 1749.8598\n",
      "val Loss: 0.0325\n",
      "val MAE: 2539.5352\n",
      "\n",
      "Epoch 148/200\n",
      "----------\n",
      "train Loss: 0.0138\n",
      "train MAE: 1681.3821\n",
      "val Loss: 0.0327\n",
      "val MAE: 2560.0891\n",
      "\n",
      "Epoch 149/200\n",
      "----------\n",
      "train Loss: 0.0134\n",
      "train MAE: 1662.1982\n",
      "val Loss: 0.0325\n",
      "val MAE: 2541.7572\n",
      "\n",
      "Epoch 150/200\n",
      "----------\n",
      "train Loss: 0.0142\n",
      "train MAE: 1733.3825\n",
      "val Loss: 0.0326\n",
      "val MAE: 2550.5592\n",
      "\n",
      "Epoch 151/200\n",
      "----------\n",
      "train Loss: 0.0151\n",
      "train MAE: 1780.2871\n",
      "val Loss: 0.0322\n",
      "val MAE: 2524.0699\n",
      "\n",
      "Epoch 152/200\n",
      "----------\n",
      "train Loss: 0.0134\n",
      "train MAE: 1668.2894\n",
      "val Loss: 0.0316\n",
      "val MAE: 2530.0047\n",
      "\n",
      "Epoch 153/200\n",
      "----------\n",
      "train Loss: 0.0130\n",
      "train MAE: 1681.0170\n",
      "val Loss: 0.0317\n",
      "val MAE: 2533.0919\n",
      "\n",
      "Epoch 154/200\n",
      "----------\n",
      "train Loss: 0.0137\n",
      "train MAE: 1685.6891\n",
      "val Loss: 0.0326\n",
      "val MAE: 2535.2898\n",
      "\n",
      "Epoch 155/200\n",
      "----------\n",
      "train Loss: 0.0135\n",
      "train MAE: 1703.3496\n",
      "val Loss: 0.0317\n",
      "val MAE: 2525.5712\n",
      "\n",
      "Epoch 156/200\n",
      "----------\n",
      "train Loss: 0.0131\n",
      "train MAE: 1665.5887\n",
      "val Loss: 0.0320\n",
      "val MAE: 2509.2110\n",
      "\n",
      "Epoch 157/200\n",
      "----------\n",
      "train Loss: 0.0156\n",
      "train MAE: 1821.8197\n",
      "val Loss: 0.0342\n",
      "val MAE: 2589.4663\n",
      "\n",
      "Epoch 158/200\n",
      "----------\n",
      "train Loss: 0.0140\n",
      "train MAE: 1677.7477\n",
      "val Loss: 0.0338\n",
      "val MAE: 2592.9540\n",
      "\n",
      "Epoch 159/200\n",
      "----------\n",
      "train Loss: 0.0137\n",
      "train MAE: 1671.0331\n",
      "val Loss: 0.0338\n",
      "val MAE: 2582.5335\n",
      "\n",
      "Epoch 160/200\n",
      "----------\n",
      "train Loss: 0.0136\n",
      "train MAE: 1652.9409\n",
      "val Loss: 0.0342\n",
      "val MAE: 2597.9757\n",
      "\n",
      "Epoch 161/200\n",
      "----------\n",
      "train Loss: 0.0126\n",
      "train MAE: 1627.2626\n",
      "val Loss: 0.0340\n",
      "val MAE: 2608.1312\n",
      "\n",
      "Epoch 162/200\n",
      "----------\n",
      "train Loss: 0.0126\n",
      "train MAE: 1626.0483\n",
      "val Loss: 0.0336\n",
      "val MAE: 2575.1848\n",
      "\n",
      "Epoch 163/200\n",
      "----------\n",
      "train Loss: 0.0129\n",
      "train MAE: 1654.4479\n",
      "val Loss: 0.0336\n",
      "val MAE: 2602.7560\n",
      "\n",
      "Epoch 164/200\n",
      "----------\n",
      "train Loss: 0.0140\n",
      "train MAE: 1723.9016\n",
      "val Loss: 0.0336\n",
      "val MAE: 2592.6043\n",
      "\n",
      "Epoch 165/200\n",
      "----------\n",
      "train Loss: 0.0131\n",
      "train MAE: 1649.4310\n",
      "val Loss: 0.0335\n",
      "val MAE: 2581.3254\n",
      "\n",
      "Epoch 166/200\n",
      "----------\n",
      "train Loss: 0.0128\n",
      "train MAE: 1645.4238\n",
      "val Loss: 0.0313\n",
      "val MAE: 2487.7311\n",
      "\n",
      "Epoch 167/200\n",
      "----------\n",
      "train Loss: 0.0128\n",
      "train MAE: 1616.1539\n",
      "val Loss: 0.0320\n",
      "val MAE: 2519.8361\n",
      "\n",
      "Epoch 168/200\n",
      "----------\n",
      "train Loss: 0.0122\n",
      "train MAE: 1621.9009\n",
      "val Loss: 0.0318\n",
      "val MAE: 2512.7342\n",
      "\n",
      "Epoch 169/200\n",
      "----------\n",
      "train Loss: 0.0130\n",
      "train MAE: 1649.3467\n",
      "val Loss: 0.0309\n",
      "val MAE: 2477.7983\n",
      "\n",
      "Epoch 170/200\n",
      "----------\n",
      "train Loss: 0.0138\n",
      "train MAE: 1672.3412\n",
      "val Loss: 0.0316\n",
      "val MAE: 2510.2499\n",
      "\n",
      "Epoch 171/200\n",
      "----------\n",
      "train Loss: 0.0130\n",
      "train MAE: 1640.0417\n",
      "val Loss: 0.0334\n",
      "val MAE: 2579.3110\n",
      "\n",
      "Epoch 172/200\n",
      "----------\n",
      "train Loss: 0.0135\n",
      "train MAE: 1687.3080\n",
      "val Loss: 0.0318\n",
      "val MAE: 2499.8221\n",
      "\n",
      "Epoch 173/200\n",
      "----------\n",
      "train Loss: 0.0125\n",
      "train MAE: 1602.9945\n",
      "val Loss: 0.0334\n",
      "val MAE: 2597.4731\n",
      "\n",
      "Epoch 174/200\n",
      "----------\n",
      "train Loss: 0.0128\n",
      "train MAE: 1638.0462\n",
      "val Loss: 0.0363\n",
      "val MAE: 2702.7322\n",
      "\n",
      "Epoch 175/200\n",
      "----------\n",
      "train Loss: 0.0125\n",
      "train MAE: 1615.1209\n",
      "val Loss: 0.0326\n",
      "val MAE: 2510.0376\n",
      "\n",
      "Epoch 176/200\n",
      "----------\n",
      "train Loss: 0.0130\n",
      "train MAE: 1648.9362\n",
      "val Loss: 0.0324\n",
      "val MAE: 2518.5423\n",
      "\n",
      "Epoch 177/200\n",
      "----------\n",
      "train Loss: 0.0130\n",
      "train MAE: 1630.4478\n",
      "val Loss: 0.0310\n",
      "val MAE: 2463.7502\n",
      "\n",
      "Epoch 178/200\n",
      "----------\n",
      "train Loss: 0.0122\n",
      "train MAE: 1570.2667\n",
      "val Loss: 0.0314\n",
      "val MAE: 2477.6131\n",
      "\n",
      "Epoch 179/200\n",
      "----------\n",
      "train Loss: 0.0121\n",
      "train MAE: 1566.0381\n",
      "val Loss: 0.0325\n",
      "val MAE: 2522.6299\n",
      "\n",
      "Epoch 180/200\n",
      "----------\n",
      "train Loss: 0.0124\n",
      "train MAE: 1603.1910\n",
      "val Loss: 0.0321\n",
      "val MAE: 2506.5356\n",
      "\n",
      "Epoch 181/200\n",
      "----------\n",
      "train Loss: 0.0128\n",
      "train MAE: 1621.6777\n",
      "val Loss: 0.0318\n",
      "val MAE: 2505.3441\n",
      "\n",
      "Epoch 182/200\n",
      "----------\n",
      "train Loss: 0.0117\n",
      "train MAE: 1545.0561\n",
      "val Loss: 0.0316\n",
      "val MAE: 2493.4119\n",
      "\n",
      "Epoch 183/200\n",
      "----------\n",
      "train Loss: 0.0123\n",
      "train MAE: 1582.8701\n",
      "val Loss: 0.0352\n",
      "val MAE: 2666.4328\n",
      "\n",
      "Epoch 184/200\n",
      "----------\n",
      "train Loss: 0.0118\n",
      "train MAE: 1542.8140\n",
      "val Loss: 0.0315\n",
      "val MAE: 2488.8177\n",
      "\n",
      "Epoch 185/200\n",
      "----------\n",
      "train Loss: 0.0116\n",
      "train MAE: 1516.5631\n",
      "val Loss: 0.0316\n",
      "val MAE: 2490.2294\n",
      "\n",
      "Epoch 186/200\n",
      "----------\n",
      "train Loss: 0.0125\n",
      "train MAE: 1609.4037\n",
      "val Loss: 0.0332\n",
      "val MAE: 2570.8508\n",
      "\n",
      "Epoch 187/200\n",
      "----------\n",
      "train Loss: 0.0129\n",
      "train MAE: 1628.4936\n",
      "val Loss: 0.0319\n",
      "val MAE: 2510.5135\n",
      "\n",
      "Epoch 188/200\n",
      "----------\n",
      "train Loss: 0.0112\n",
      "train MAE: 1502.5107\n",
      "val Loss: 0.0334\n",
      "val MAE: 2567.1273\n",
      "\n",
      "Epoch 189/200\n",
      "----------\n",
      "train Loss: 0.0115\n",
      "train MAE: 1555.6231\n",
      "val Loss: 0.0312\n",
      "val MAE: 2469.2761\n",
      "\n",
      "Epoch 190/200\n",
      "----------\n",
      "train Loss: 0.0122\n",
      "train MAE: 1572.2582\n",
      "val Loss: 0.0342\n",
      "val MAE: 2610.2799\n",
      "\n",
      "Epoch 191/200\n",
      "----------\n",
      "train Loss: 0.0126\n",
      "train MAE: 1586.7091\n",
      "val Loss: 0.0339\n",
      "val MAE: 2582.0973\n",
      "\n",
      "Epoch 192/200\n",
      "----------\n",
      "train Loss: 0.0124\n",
      "train MAE: 1582.1821\n",
      "val Loss: 0.0315\n",
      "val MAE: 2495.5295\n",
      "\n",
      "Epoch 193/200\n",
      "----------\n",
      "train Loss: 0.0119\n",
      "train MAE: 1567.1837\n",
      "val Loss: 0.0313\n",
      "val MAE: 2488.5493\n",
      "\n",
      "Epoch 194/200\n",
      "----------\n",
      "train Loss: 0.0124\n",
      "train MAE: 1603.2307\n",
      "val Loss: 0.0307\n",
      "val MAE: 2454.5792\n",
      "\n",
      "Epoch 195/200\n",
      "----------\n",
      "train Loss: 0.0124\n",
      "train MAE: 1610.3275\n",
      "val Loss: 0.0313\n",
      "val MAE: 2466.0702\n",
      "\n",
      "Epoch 196/200\n",
      "----------\n",
      "train Loss: 0.0123\n",
      "train MAE: 1601.2926\n",
      "val Loss: 0.0338\n",
      "val MAE: 2562.1967\n",
      "\n",
      "Epoch 197/200\n",
      "----------\n",
      "train Loss: 0.0120\n",
      "train MAE: 1540.4295\n",
      "val Loss: 0.0323\n",
      "val MAE: 2513.0696\n",
      "\n",
      "Epoch 198/200\n",
      "----------\n",
      "train Loss: 0.0113\n",
      "train MAE: 1524.0012\n",
      "val Loss: 0.0308\n",
      "val MAE: 2448.2517\n",
      "\n",
      "Epoch 199/200\n",
      "----------\n",
      "Epoch   198: reducing learning rate of group 0 to 1.0000e-04.\n",
      "train Loss: 0.0110\n",
      "train MAE: 1514.2138\n",
      "val Loss: 0.0320\n",
      "val MAE: 2495.6364\n",
      "\n",
      "Epoch 200/200\n",
      "----------\n",
      "train Loss: 0.0106\n",
      "train MAE: 1468.4653\n",
      "val Loss: 0.0311\n",
      "val MAE: 2462.1505\n",
      "\n",
      "Training complete in 257m 38s\n",
      "Best val Loss: 0.030668 at epoch 194\n",
      "Best val MAE: 2454.579154 at epoch 194\n",
      "\n",
      "Load the model weights at the best epoch\n"
     ]
    }
   ],
   "source": [
    "model_res152, mae_list_3, all_loss_3, all_mae_3 = train_model(model_ft, model_LU, criterion, optimizer_ft, exp_lr_scheduler, num_epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(mae_list_2, open(\"mae_list_2\", \"wb\"))\n",
    "pickle.dump(all_loss_2, open(\"all_loss_2\", \"wb\"))\n",
    "pickle.dump(all_mae_2, open(\"all_mae_2\", \"wb\"))\n",
    "pickle.dump(mae_list_3, open(\"mae_list_3\", \"wb\"))\n",
    "pickle.dump(all_loss_3, open(\"all_loss_3\", \"wb\"))\n",
    "pickle.dump(all_mae_3, open(\"all_mae_3\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_env",
   "language": "python",
   "name": "torch_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
